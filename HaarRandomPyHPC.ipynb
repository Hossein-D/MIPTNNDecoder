{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import time\n",
    "from multiprocessing import Process\n",
    "from timeit import default_timer as timer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import random \n",
    "from random import sample\n",
    "from qiskit import QuantumCircuit\n",
    "import qiskit as qiskit\n",
    "import qiskit.visualization\n",
    "from numpy import divide, matmul, diagonal, floor, copy, zeros, linalg, sqrt, transpose, conj, exp, log\n",
    "import scipy\n",
    "import random as rand\n",
    "import shutil\n",
    "from scipy.linalg import expm, sinm, cosm\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, transpile\n",
    "from qiskit.tools.visualization import plot_histogram, plot_state_city\n",
    "import qiskit.quantum_info as qi\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.providers.basicaer import QasmSimulatorPy\n",
    "from qiskit import Aer\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit.test.reference_circuits import ReferenceCircuits\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.providers.basicaer import QasmSimulatorPy\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "from numpy.random import rand\n",
    "from numpy.linalg import qr\n",
    "\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import matrix_power\n",
    "\n",
    "from qiskit import quantum_info as qinfo\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit import(\n",
    "  QuantumCircuit,\n",
    "  execute,\n",
    "  Aer)\n",
    "#from plot_model import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "#service = QiskitRuntimeService()\n",
    "#program_inputs = {'iterations': 1}\n",
    "#options = {\"backend_name\": \"ibmq_qasm_simulator\"}\n",
    "#job = service.run(program_id=\"hello-world\",\n",
    "#                options=options,\n",
    "#                inputs=program_inputs\n",
    "#                )\n",
    "#print(f\"job id: {job.job_id}\")\n",
    "#result = job.result()\n",
    "#print(result)\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, transpile\n",
    "from qiskit.tools.visualization import circuit_drawer\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "from qiskit import BasicAer\n",
    "\n",
    "from numpy import log, exp, math, pi\n",
    "\n",
    "#from numpy import *\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "#from time import clock     \n",
    "from time import process_time\n",
    "#import qiskit fg\n",
    "import matplotlib\n",
    "from random import randrange\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy, math\n",
    "#from sympy import *\n",
    "import itertools\n",
    "from IPython.display import display\n",
    "#init_printing()\n",
    "from tempfile import TemporaryFile\n",
    "#qiskit.__qiskit_version__\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import os, fnmatch, sys, getopt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, TimeDistributed, SimpleRNN, \\\n",
    "    Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector, BatchNormalization, ReLU, add, \\\n",
    "    GlobalAveragePooling2D, ZeroPadding2D, Add, AveragePooling2D\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD #, AdamW\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import logm\n",
    "from qiskit.compiler import assemble\n",
    "#\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denMatCostDiag(lamSq, sx, sy, sz):\n",
    "    legendre = lamSq[-1];\n",
    "    mu = [[1/2*(1+sz), 1/2*(sx-1j*sy)], [1/2*(sx+1j*sy), 1/2*(1-sz)]]\n",
    "    mueigval, mueigvec = eig(mu)\n",
    "    #a=denVec[0]; b=denVec[1]; c=denVec[2]; d=denVec[3];\n",
    "    print(\"mueigval = \", mueigval)\n",
    "    Lambda = sum(np.multiply(np.multiply(lamSq[:-1], lamSq[:-1])-\\\n",
    "                             mueigval[:], np.multiply(lamSq[:-1], lamSq[:-1])-\\\n",
    "                             mueigval[:]))-legendre*(sum(np.multiply(lamSq[:-1], lamSq[:-1]))-1)\n",
    "    \n",
    "    return Lambda\n",
    "\n",
    "def denMat(denVec):\n",
    "    a=denVec[0]; b=denVec[1]; c=denVec[2]; d=denVec[3];\n",
    "    rho = np.divide([[a**2+b**2+c**2, d*(b-1j*c)], [d*(b+1j*c), d**2]], \\\n",
    "                    (a**2+b**2+c**2+d**2))\n",
    "    return rho\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def denMatCost(denVec, sx, sy, sz):\n",
    "def denMatCost(denVec, sx, sy, sz):\n",
    "    #print(\"denMat = \", denMat(denVec))\n",
    "#    sx=-.1;sy=.5;sz=.5;\n",
    "    a=denVec[0]; b=denVec[1]; c=denVec[2]; d=denVec[3];\n",
    "    #print(\"denVec=\", denVec)\n",
    "    norm=(a**2+b**2+c**2+d**2);\n",
    "    #cost = (1-a)**2+2*a\n",
    "    #(2*b*d-sx)**2+(2*c*d-sy)**2\n",
    "    cost1 = (2*b*d-norm*sx)**2/(norm*(2*b*d)) + \\\n",
    "    (2*c*d-norm*sy)**2/(norm*(2*c*d)) + \\\n",
    "    (a**2+b**2+c**2-d**2-norm*sz)**2/(norm*(a**2+b**2+c**2-d**2))\n",
    "    #derivCost1da = (norm*sx-2*b*d)*(a*norm*sx+2*b*d*a)/(b*d*norm**2)+ \\\n",
    "    #(norm*sx-2*c*d)*(a*norm*sx+2*c*d*a)/(c*d*norm**2)+\\\n",
    "    #2*(2*a-2*a*sz)*(a**2+b**2+c**2-d**2-norm*sz)/(norm*(a**2+b**2+c**2-d**2))+\\\n",
    "    #-2*a*(a**2+b**2+c**2-d**2-norm*sz)**2/(norm**2*(a**2+b**2+c**2-d**2))+\\\n",
    "    #-(a**2+b**2+c**2-d**2-norm*sz)**2/(norm*(a**2+b**2+c**2-d**2)**2)\n",
    "    \n",
    "    \n",
    "    cost2 = (2*b*d-norm*sx)**2/(norm**2*(sx)) + \\\n",
    "    (2*c*d-norm*sy)**2/(norm**2*sy) + \\\n",
    "    (a**2+b**2+c**2-d**2-norm*sz)**2/(norm**2*sz)\n",
    "    #derivCost2da = \n",
    "    \n",
    "    cost=cost1\n",
    "    #derivCost=[derivCost1da, derivCost1db, derivCost1dc, derivCost1dd]\n",
    "    \n",
    "    #derivCost=[derivCost2da, derivCost2db, derivCost2dc, derivCost2dd]\n",
    "    \n",
    "    #print(\"cost = \", cost)\n",
    "    #cost = (2*a**2+2*b**2+2*c**2-1-sz)**2\n",
    "    #return cost1, cost2\n",
    "    return cost\n",
    "\n",
    "def denMatDerCost(denVec, sx, sy, sz):\n",
    "    #print(\"denMat = \", denMat(denVec))\n",
    "#    sx=-.1;sy=.5;sz=.5;\n",
    "    a=denVec[0]; b=denVec[1]; c=denVec[2]; d=denVec[3];\n",
    "    #print(\"denVec=\", denVec)\n",
    "    norm=(a**2+b**2+c**2+d**2);\n",
    "    #cost = (1-a)**2+2*a\n",
    "    #(2*b*d-sx)**2+(2*c*d-sy)**2\n",
    "    derivCost1da=-2*a*sx*(2*b*d-norm*sx)/(b*d*norm) - a*(2*b*d-norm*sx)**2/(b*d*norm**2)\\\n",
    "    -2*a*sx*(2*c*d-norm*sx)/(c*d*norm) - a*(2*c*d-norm*sx)**2/(c*d*norm**2)\\\n",
    "    +2*(2*a-2*a*sz)*(a**2+b**2+c**2-d**2-norm*sz)/((a**2+b**2+c**2-d**2)*norm)\\\n",
    "    -2*a*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2)*(norm**2))\\\n",
    "    -2*a*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2)**2 * norm);\n",
    "    \n",
    "    derivCost1db=(2*d-2*b*sx)*(2*b*d-norm*sx)/(b*d*norm) - (2*b*d-norm*sx)**2/(d*norm**2)\\\n",
    "    -(2*b*d-norm*sx)**2/(2* b**2 *d*norm) - 2*b*sx*(2*c*d-norm*sx)/(c*d*norm)\\\n",
    "    -b*(2*c*d-norm*sx)**2/(c*d*norm**2)\\\n",
    "    +2*(2*b-2*b*sz)*(a**2+b**2+c**2-d**2-norm*sz)/((a**2+b**2+c**2-d**2)*(norm))\\\n",
    "    -2*b*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2) * norm**2)\\\n",
    "    -2*b*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2)**2 * norm);    \n",
    "\n",
    "    derivCost1dc=-2*c*sx*(2*b*d-norm*sx)/(b*d*norm) - c*(2*b*d-norm*sx)**2/(b*d*norm**2)\\\n",
    "    +(2*d-2*c*sx)*(2*c*d-norm*sx)/(c*d*norm) - (2*c*d-norm*sx)**2/(d*norm**2)\\\n",
    "    -(2*c*d-norm*sx)**2/(2*c**2*d*norm)\\\n",
    "    +2*(2*c-2*c*sz)*(a**2+b**2+c**2-d**2-norm*sz)/((a**2+b**2+c**2-d**2)*(norm))\\\n",
    "    -2*c*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2) * norm**2)\\\n",
    "    -2*c*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2)**2 * norm);    \n",
    "\n",
    "    derivCost1dd=(2*b-2*d*sx)*(2*b*d-norm*sx)/(b*d*norm) - (2*b*d-norm*sx)**2/(b*norm**2)\\\n",
    "    -(2*b*d-norm*sx)**2/(2*b*d**2*norm) + (2*c-2*d*sx)*(2*c*d-norm*sx)/(c*d*norm)\\\n",
    "    -(2*c*d-norm*sx)**2/(c*norm**2) - (2*c*d-norm*sx)**2/(2*c*d**2*norm)\\\n",
    "    +2*(-2*d-2*d*sz)*(a**2+b**2+c**2-d**2-norm*sz)/((a**2+b**2+c**2-d**2)*(norm))\\\n",
    "    -2*d*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2) * norm**2)\\\n",
    "    +2*d*(a**2+b**2+c**2-d**2-norm*sz)**2/((a**2+b**2+c**2-d**2)**2 * norm);    \n",
    "\n",
    "    derivCost=[derivCost1da, derivCost1db, derivCost1dc, derivCost1dd]\n",
    "        \n",
    "    return derivCost\n",
    "\n",
    "def maxLikelihoodDen(sx, sy, sz, methodML):\n",
    "    #print(\"[sx, sy, sz] = \", [sx, sy, sz])\n",
    "    #print(\"sx = {}, sy={}, sz={}\".format(sx, sy, sz))\n",
    "    Delta=1/4*(1-sx**2-sy**2-sz**2)\n",
    "    #print(\"Delta = \", Delta)\n",
    "    M11=1/2*(1-sz);\n",
    "    #print(\"M11 = \", M11)    \n",
    "    #print(\"sqrt(Delta/M11) = \", np.sqrt(Delta/M11 + 0.0j))\n",
    "\n",
    "    #print(\"Delta = \", Delta)\n",
    "    #print(\"1-sz = \", 1-sz)\n",
    "    #print(\"D/M = \", Delta/M11)\n",
    "    T0 =np.array([[np.sqrt(Delta/M11+0.0j), 0], \\\n",
    "           [(sx+1j*sy)/(sqrt(2*(1-sz))), \\\n",
    "            sqrt(1/2*(1-sz))]])\n",
    "    #print(\"T0 = \", T0)\n",
    "    #denMat0=np.dot(np.transpose(conj(T0)), T0)\n",
    "    #print(\"denMat0 = \", denMat0)\n",
    "    #print(\"T0[1, 0] = \", np.real(complex(T0[1, 0])))\n",
    "    #print(\"real T0[1, 0] = \", np.real(T0[1, 0]))\n",
    "    denVec0=[np.real(complex(T0[0, 0])), np.real(complex(T0[1, 0])), \\\n",
    "             np.imag(complex(T0[1, 0])), np.real(complex(T0[1, 1]))]\n",
    "\n",
    "    #a0=denMat0[0];    b0=denMat0[1];    c0=denMat0[2];    d0=denMat0[3];\n",
    "    \n",
    "    #denMatParam = [a, b, c, d];\n",
    "    \n",
    "    #res = minimize(fun, (2, 0), method='SLSQP') #, bounds=bnds,\\\n",
    "               #constraints=cons)\n",
    "    #bnds = ((-float('inf'), float('inf')), (0, None))        \n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "    #               method='SLSQP', jac=None)\n",
    "    \n",
    "    res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "                   method=methodML, jac=None)\n",
    "    \n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "    #               method='TNC', jac=None)\n",
    "\n",
    "    physDenMat = denMat(res.x)\n",
    "    \n",
    "    #print(\"density mat from TNC = \", denMat(res.x))\n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "    #method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "    #method='Powell', jac=None)\n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz),\\\n",
    "    #               method='Newton-CG', jac=denMatDerCost) #, hess=None, hessp=None) \n",
    "    #print(\"density mat from Newton = \", denMat(res.x))\n",
    "    #print(\"res Newton = \", res)\n",
    "    return physDenMat, res.x, res\n",
    "\n",
    "\n",
    "def denMat3param(denVec):\n",
    "    \n",
    "    a=denVec[0]; b=denVec[1]; c=denVec[2];\n",
    "    d=sqrt(1-a**2-b**2-c**2);\n",
    "    rho = [[a**2+b**2+c**2, d*(b-1j*c)], [d*(b+1j*c), d**2]]\n",
    "    \n",
    "    return rho\n",
    "\n",
    "def denMat3paramCost(denVec, sx, sy, sz):\n",
    "    a=denVec[0]; b=denVec[1]; c=denVec[2]; \n",
    "    norm=1;d=sqrt(1-a**2-b**2-c**2); print(\"d=\", d);\n",
    "    cost1 = (2*b*d-norm*sx)**2/(norm*(2*b*d)) + \\\n",
    "    (2*c*d-norm*sy)**2/(norm*(2*c*d)) + \\\n",
    "    (a**2+b**2+c**2-d**2-norm*sz)**2/(norm*(a**2+b**2+c**2-d**2))\n",
    "        \n",
    "    cost2 = (2*b*d-norm*sx)**2/(norm**2*(sx)) + \\\n",
    "    (2*c*d-norm*sy)**2/(norm**2*sy) + \\\n",
    "    (a**2+b**2+c**2-d**2-norm*sz)**2/(norm**2*sz)\n",
    "    \n",
    "    cost=cost2\n",
    "    \n",
    "    #return cost1, cost2\n",
    "    return cost\n",
    "\n",
    "\n",
    "def maxLikelihoodDen3Param(sx, sy, sz):\n",
    "    \n",
    "    Delta=1/4*(1-sx**2-sy**2-sz**2)\n",
    "    M11=1/2*(1-sz);\n",
    "    T0 =np.array([[sqrt(Delta/M11), 0], \\\n",
    "           [(sx+1.0j*sy)/(sqrt(2*(1-sz))), \\\n",
    "            sqrt(1/2*(1-sz))]])\n",
    "    print(\"T0=\", T0)\n",
    "    denMat0=np.matmul(np.transpose(conj(T0)), T0)\n",
    "    print(\"denMat0 = \", denMat0)\n",
    "    #print(\"T0[1, 0] = \", np.real(complex(T0[1, 0])))\n",
    "    #print(\"real T0[1, 0] = \", np.real(T0[1, 0]))\n",
    "    denVec0=[np.real(complex(T0[0, 0])), np.real(complex(T0[1, 0])), \\\n",
    "             np.imag(complex(T0[1, 0])), np.real(complex(T0[1, 1]))]\n",
    "    \n",
    "    #a0=denMat0[0];    b0=denMat0[1];    c0=denMat0[2];    d0=denMat0[3];\n",
    "    \n",
    "    #denMatParam = [a, b, c, d];\n",
    "    \n",
    "    #res = minimize(fun, (2, 0), method='SLSQP') #, bounds=bnds,\\\n",
    "               #constraints=cons)\n",
    "    #bnds = ((-float('inf'), float('inf')), (0, None)) \n",
    "    print(\"denVec0 = \", denVec0)\n",
    "    res = minimize(denMat3paramCost, denVec0[0:3], args=(sx, sy, sz), \\\n",
    "                   method='SLSQP', jac=None)\n",
    "    print(\"density mat from SLSQP = \", denMat3param(res.x))\n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "    #method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "    #res = minimize(denMatCost, denVec0, args=(sx, sy, sz), \\\n",
    "    #method='Powell', jac=None)\n",
    "    #res = minimize(denMat3paramCost, denVec0, args=(sx, sy, sz),\\\n",
    "    #               method='Newton-CG', jac=denMatDerCost) #, hess=None, hessp=None) \n",
    "    #print(\"density mat from Newton = \", denMat(res.x))\n",
    "    #print(\"res Newton = \", res)\n",
    "    return res.x, res\n",
    "\n",
    "#def maxLikelihoodDenDiag(sx, sy, sz):\n",
    "#    return res.x, res\n",
    "#A=[1, 2, 3]; A[0:2]; print(\"A = \", A)\n",
    "#sx=0.5; sy=0.2; sz=0.9\n",
    "#res = maxLikelihoodDen3Param(sx, sy, sz)\n",
    "#T0=np.array([[0.707106781186548*1j, 0],\n",
    "# [1.1180339887499 + 0.447213595499958*1j, 0.223606797749979]])\n",
    "#print(\"T0 = \", np.matmul(T0, T0))\n",
    "#A = np.array([[17.+0.j, -3.+0.j],\n",
    "#              [-7.+0.j,  1.+0.j]])\n",
    "\n",
    "#B = np.array([[ 60.+0.j,  -4.+0.j],\n",
    "#              [-12.+0.j,   0.+0.j]])\n",
    "#print(\"T0 = \", np.matmul(A, B))\n",
    "\n",
    "\n",
    "\n",
    "def entanglement(rho):\n",
    "    eigval = eig(rho)[0]\n",
    "    EE = -np.sum(np.dot(np.log2(eigval), eigval))\n",
    "    \n",
    "    return EE\n",
    "\n",
    "\n",
    "\n",
    "def HadamardMidQbit(circ, nqbit):\n",
    "    circ.h(int(np.floor(nqbit-1)/2), nqbit-1)\n",
    "    return circ\n",
    "def CNOTWithLastQbit(circ, nqbit):\n",
    "    circ.cx(int(np.floor(nqbit-1)/2), nqbit-1)\n",
    "    return circ\n",
    "\n",
    "\n",
    "def HaarGen(dim, randseed=[]):\n",
    "    \n",
    "    #print(\"randseed = \", randseed)\n",
    "    if randseed!=[]:\n",
    "        random.seed(randseed);    \n",
    "        \n",
    "    realrand = [[random.random() for e in range(dim)] for e in range(dim)]\n",
    "    imagrand = [[1j*random.random() for e in range(dim)] for e in range(dim)]    \n",
    "\n",
    "    A = np.add(realrand, imagrand);\n",
    "    #print(\"shape A = \", np.shape(A))    \n",
    "    #A = random.random(dim, dim)+1j*rand(dim, dim)\n",
    "    \n",
    "    A = A/np.sqrt(2)    \n",
    "    #print(\"A = \", A)    \n",
    "    Q, R = linalg.qr(A)\n",
    "    #print(\"R = \", R)\n",
    "    D = np.diag(np.diag(R))\n",
    "    #np.diag(np.diag(x))    \n",
    "    #print(\"D = \", D)    \n",
    "    #print(\"np.abs(D) = \", np.abs(D))\n",
    "    #PhaseVec = np.divide(D, np.abs(D))\n",
    "    PhaseVec = divide(diagonal(D), abs(diagonal(D)))    \n",
    "    #print(\"PhaseVec = \", PhaseVec)\n",
    "    PhaseArr = np.diag(PhaseVec)\n",
    "    Rprime = matmul(inv(PhaseArr), R)\n",
    "    #print(\"shape Q = \", np.shape(Q))\n",
    "    #print(\"PhaseArr = \", np.shape(PhaseArr))    \n",
    "    Qprime = matmul(Q, PhaseArr)\n",
    "    eigval, eigvec = eig(Qprime)\n",
    "    #print(\"eigval = \", eigval)\n",
    "    #QprimeCl1 = [[1, 0, 0, 0],[0, 1, 0, 0], [0, 0, 0, 1],[0, 0, 1, 0]] #np.identity(4) \n",
    "    \"\"\"    \n",
    "    if dim==4:   \n",
    "        Qprime = np.zeros((4, 4))\n",
    "        #Qprime[0, 0], Qprime[1, 1], Qprime[2, 3], Qprime[3, 2] = 1, 1, 1, 1        \n",
    "        #Qprime = np.identity(4)    \n",
    "        Qprime[0, 0:4] = 1/2\n",
    "        Qprime[1, 0],  Qprime[1, 2] = 1/2, 1/2\n",
    "        Qprime[1, 1],  Qprime[1, 3] = -1/2, -1/2\n",
    "        Qprime[2, 0],  Qprime[2, 1] = 1/2, 1/2\n",
    "        Qprime[2, 2],  Qprime[2, 3] = -1/2, -1/2\n",
    "        Qprime[3, 0],  Qprime[3, 3] = 1/2, 1/2\n",
    "        Qprime[3, 1],  Qprime[3, 2] = -1/2, -1/2\n",
    "    \"\"\"\n",
    "        #Qprime[2, 2], Qprime[3, 3], Qprime[0, 1], Qprime[1, 0] = 1, 1, 1, 1\n",
    "        \n",
    "    #QprimeCl2 = np.divide([[1, 1, 0, 0], [1, -1, 0, 0], [0, 0, 1, 1], [0, 0, 1, -1]],sqrt(2))\n",
    "    \n",
    "    #if rand()>0.5:\n",
    "    #    Qprime=QprimeCl1\n",
    "    #else:\n",
    "    #    Qprime=QprimeCl2\n",
    "    \n",
    "    return Qprime, A, eigval\n",
    "\n",
    "\n",
    "#QR = LinearAlgebra.QRCompactWY{Float64, Matrix{Float64}}\n",
    "def angHaar(eigvalues):\n",
    "    ang = np.zeros(len(eigvalues), 1)\n",
    "    ang = [np.angle(eigvalues[i]) for i in range(len(eigvalues))]\n",
    "    return ang\n",
    "\n",
    "def traceVecExceptLast(state, nqbit):\n",
    "    stateTr1 = qinfo.partial_trace(state, np.arange(0, nqbit))\n",
    "\n",
    "def statHaar(dim, Nsamp, Nbin):  \n",
    "    min = -1;\n",
    "    max = +1;\n",
    "    binVec = LinRange(min, max, Nbin+1)\n",
    "    deltaBin = (max-min)/Nbin    \n",
    "    prob = zeros(Nbin)\n",
    "    #display(prob)\n",
    "    for n in range(Nsamp):\n",
    "        if n%500==0:\n",
    "            print(\"n = \", n)        \n",
    "        Qprime, A, eig = HaarGen(dim)\n",
    "        ang = angHaar(eig)\n",
    "        #display(\"ang\")        \n",
    "        #display(ang)        \n",
    "        for n in range(dim):\n",
    "            #display(ang[n])\n",
    "            #display((ang[n]-min)/deltaBin)\n",
    "            numBin = Int(floor((ang[n]-min)/deltaBin))+1\n",
    "            #display(\"numBin\")\n",
    "            #display(numBin)\n",
    "            prob[numBin] = prob[numBin]+1\n",
    "        #display(\"prob\")\n",
    "        #display(prob)\n",
    "    return prob\n",
    "\n",
    "\n",
    "def genCircConfig(nqbit, circDepth, p, randseed, ifsave=0):\n",
    "    nNodes=nqbit*circDepth\n",
    "    nUnitary=int(nNodes/2)\n",
    "    #lock = threading.Lock()\n",
    "    \n",
    "    #with lock:\n",
    "    #print(\"randseed = \", randseed)\n",
    "    #random.seed(randseed);\n",
    "    if randseed!=[]:\n",
    "        random.seed(randseed);    \n",
    "    \n",
    "    measureVec=[(random.random()<p)+0 for i in range(nNodes)]        \n",
    "    measureArr=np.zeros((circDepth, nqbit))\n",
    "    #measureVec =  [0, 1, 0, 0];        \n",
    "    #measureVec = np.zeros(nNodes)\n",
    "    #midqbit = int(np.floor(nqbit-1)/2)\n",
    "    #if nqbit==4:\n",
    "    #    measureVec = np.zeros(nNodes)\n",
    "        #midqbit = int(np.floor(nqbit-1)/2)        \n",
    "        #measureVec[midqbit] = 1\n",
    "    #    measureVec[0], measureVec[1] = 1, 1\n",
    "    for t in range(circDepth):\n",
    "        measureArr[t, :]=[measureVec[i+t*nqbit] for i in range(nqbit)]\n",
    "    \n",
    "    #print(\"measureArr = \", measureArr)\n",
    "    unitaryArr=np.zeros((nUnitary, 4, 4))+0j\n",
    "    dim=4;\n",
    "    for i in range(nUnitary):\n",
    "        # Since we want to have different unitaries we change randseed for each i\n",
    "        if randseed!=[]:\n",
    "            Q, A, eig = HaarGen(dim, randseed+i)        \n",
    "            unitaryArr[i, :, :] = np.copy(Q)\n",
    "        else:\n",
    "            Q, A, eig = HaarGen(dim)\n",
    "            unitaryArr[i, :, :] = np.copy(Q)\n",
    "            \n",
    "        #print(\"Q*Q^{\\dagger}=\", matmul(Q, np.conj(np.transpose(Q))))\n",
    "    return measureArr, unitaryArr        \n",
    "    #circ={};circ[0]=measureArr;circ[1]=unitaryArr;\n",
    "    #print(\"circ = \", circ)\n",
    "    #if ifsave==1:\n",
    "    #    df = pd.DataFrame(circ);\n",
    "    #    df.to_csv(\"Circ-nq{}-depth{}-p{}-seed{}.csv\".format(nq, \\\n",
    "    #        circDepth, p, randseed))\n",
    "\n",
    "    #circ = genCircConfig(nq, d, p, seed, 1);\n",
    "    #path = Path('~/Desktop/Hafezi/Codes/measurementPT/Haar/').expanduser()\n",
    "\n",
    "    #print(\"path = \", path)\n",
    "    #path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #lb,ub = -1,1;\n",
    "    #num_samples = 5;\n",
    "    #x = np.random.uniform(low=lb,high=ub,size=(1,num_samples));\n",
    "    #y = x**2 + x + 2;\n",
    "    #if ifsave==1:\n",
    "    #    np.save(path/\"measure-nq{}-depth{}-p{}-seed{}\".format(nqbit, circDepth, p, randseed), measureArr)\n",
    "    #    np.save(path/\"unitary-nq{}-depth{}-p{}-seed{}\".format(nqbit, circDepth, p, randseed), unitaryArr)\n",
    "        \n",
    "\n",
    "    #try:\n",
    "    #    circIndArr = globals()[\"circIndArrL{}P{}\".format(L, Prob)][:, PT]\n",
    "    #    except KeyError:    \n",
    "    \n",
    "    \"\"\"\n",
    "    with open(\"Circ-nq{}-depth{}-p{}-seed{}.csv\".format(nq, \\\n",
    "        circDepth, p, randseed), newline='') as csvfile:\n",
    "                    #spamreader = csv.reader(csvfile, delimiter=',', quotechar=',')\n",
    "        csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "        rowc = 0                \n",
    "        for row in csv_reader: \n",
    "            if rowc==1:\n",
    "                measureArrLoad = row[1][1:-1];\n",
    "                #print(\"measureArr = \", measureArr)\n",
    "                #print(\"np.shape(measureArr) = \", np.shape(measureArr))\n",
    "                arr = measureArrLoad.split(' ')\n",
    "                print(\"arr = \", arr)                \n",
    "            #print(\"rowc = \", rowc)\n",
    "            #print(\"row = \", row)\n",
    "            #print(\"row[1] = \", row[1])\n",
    "            rowc += 1       \n",
    "            \n",
    "        #for i in range(10):\n",
    "        #    circIndArr[i, rowc-1] = int(float(row[i]))\n",
    "        #    rowc+=1       \n",
    "    \"\"\"\n",
    "    #print(\"measureArr = \", measureArr)\n",
    "    #print(\"unitaryArr = \", unitaryArr)    \n",
    "    #return measureArr, unitaryArr\n",
    "#def saveCircConfig():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input = tf.keras.Input(shape=(100,), dtype='int32', name='input')\n",
    "x = tf.keras.layers.Embedding(\n",
    "    output_dim=512, input_dim=10000, input_length=100)(input)\n",
    "x = tf.keras.layers.LSTM(32)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "#dot_img_file = '/tmp/model_1.png'\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorboard\n",
    "print(tensorboard.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "np.random.seed(0)\n",
    "xsize = 600;\n",
    "xtrain = np.random.randint(2, size=xsize)  # Input features\n",
    "ytrain = xtrain;\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(\"x_train = \", np.shape(x_train))\n",
    "#print(\"y_train = \", np.shape(y_train))\n",
    "#print(x_train[0, :, :,])\n",
    "print(y_train[:10])\n",
    "def NeuralNet():\n",
    "    return 1\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Generate some random training data\n",
    "\n",
    "\n",
    "#ytrain = np.random.randint(1, int((xsize)/6))\n",
    "\n",
    "#xtrain # Binary target labels\n",
    "#print(\"xtrain = \", xtrain)\n",
    "#print(\"y_train = \", ytrain)\n",
    "# Create a sequential model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    #tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "#model.fit(xtrain, ytrain, epochs=10, batch_size=32)\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "# Generate some test data\n",
    "X_test = np.random.randint(2, size=20)  # Input features\n",
    "# Predict on the test data\n",
    "print(\"X_test = \", X_test)\n",
    "#y_pred = model.predict(X_test)\n",
    "# Print the predicted values\n",
    "#print(y_pred)\n",
    "\n",
    "def myloss(yind):        \n",
    "    def loss(y_true, y_pred):\n",
    "        #print(\"y_pred = \", (y_pred)[:, yind])\n",
    "        log_y_pred = tf.math.log(y_pred[:, yind])\n",
    "        elements = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true[:, yind])\n",
    "        #print(elements)\n",
    "        #print(tf.reduce_sum(elements,axis=0))\n",
    "        return tf.reduce_mean(tf.reduce_sum(elements,axis=0))\n",
    "    return loss\n",
    "#model.compile(loss=asymmetric_loss(alpha=alpha), optimizer='adam')        \n",
    "a=myloss(2)\n",
    "y_true = tf.constant(tf.keras.utils.to_categorical([4, 1]))\n",
    "#print(y_true)\n",
    "\n",
    "y_pred = tf.constant([[0 , .7 , 0 ,0 ,  .3], [0 , .6 , .3 ,0 ,  .1]])    \n",
    "#print('Tensorflow CE : ',tf.keras.losses.CategoricalCrossentropy()\n",
    "#      (y_true, y_pred).numpy())\n",
    "#print('My CE : ', myloss(1)(y_true, y_pred).numpy())\n",
    "\n",
    "def myloss(yind):        \n",
    "    def loss(y_true, y_pred):\n",
    "        #print(\"y_pred = \", (y_pred)[:, yind])\n",
    "        log_y_pred = tf.math.log(y_pred[:, yind])\n",
    "        elements = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true[:, yind])\n",
    "        #print(elements)\n",
    "        #print(tf.reduce_sum(elements,axis=0))\n",
    "        return tf.reduce_mean(tf.reduce_sum(elements,axis=0))\n",
    "    return loss\n",
    "#model.compile(loss=asymmetric_loss(alpha=alpha), optimizer='adam')        \n",
    "a=myloss(2)\n",
    "y_true = tf.constant(tf.keras.utils.to_categorical([4, 1]))\n",
    "#print(y_true)\n",
    "\n",
    "y_pred = tf.constant([[0 , .7 , 0 ,0 ,  .3], [0 , .6 , .3 ,0 ,  .1]])    \n",
    "#print('Tensorflow CE : ',tf.keras.losses.CategoricalCrossentropy()\n",
    "#      (y_true, y_pred).numpy())\n",
    "#print('My CE : ', myloss(1)(y_true, y_pred).numpy());\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "xsize = 5000;\n",
    "xtrain = np.random.randint(2, size=xsize)  # Input features\n",
    "ytrain = np.zeros((xsize, 3))\n",
    "\n",
    "ytrain[:, 0] = np.random.randint(0, 2, size=(int(xsize)), dtype=int)\n",
    "ytrain[:, 1] = np.random.randint(0, 2, size=(int(xsize)), dtype=int)\n",
    "ytrain[:, 2] = xtrain[:]\n",
    "\n",
    "#ytrain[int(2*xsize/3):int(3*xsize/3)] = np.random.randint(2, 4, size=(int(xsize/3)), dtype=int)\n",
    "#ytrain[int(3*xsize/6):int(4*xsize/6)] = np.random.randint(2, 4, size=(int(xsize/6)), dtype=int)\n",
    "#ytrain[int(4*xsize/6):int(6*xsize/6)] = np.add(xtrain[int(4*xsize/6):int(6*xsize/6)], 4)\n",
    "#ytrain = tf.one_hot(\n",
    "#    ytrain, 3, on_value = 1.0, off_value = 0.0, axis =-1)\n",
    "\n",
    "print(\"ytrain = \", ytrain[:10, :])\n",
    "print(\"xtrain = \", xtrain[:10])\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(1,)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    #tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n",
    "    #tf.keras.layers.Dense(6, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "    #tf.keras.layers.Dense(6, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(loss='CategoricalCrossentropy', optimizer=optimizer, metrics=['accuracy']);\n",
    "#binary_crossentropy\n",
    "                #softmax_cross_entropy_with_logits\n",
    "\n",
    "def myloss(yind, lamRhoSq):\n",
    "    def loss(y_true, y_pred):\n",
    "        #print(\"y_pred = \", (y_pred)[:, yind])\n",
    "        log_y_pred = tf.math.log(y_pred[:, yind])\n",
    "        oneminuslog_y_pred = tf.math.log(1-y_pred[:, yind])\n",
    "        print(\"y_pred = \", y_pred)\n",
    "        cost1 = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true[:, yind])+\\\n",
    "            -tf.math.multiply_no_nan(x=oneminuslog_y_pred, y=1-y_true[:, yind])\n",
    "        \n",
    "        print(\"cost1 = \", cost1)\n",
    "        sxpred = 2*y_pred[:, 0]-1\n",
    "        sypred = 2*y_pred[:, 1]-1\n",
    "        szpred = 2*y_pred[:, 2]-1\n",
    "\n",
    "        cost2vec = tf.math.square(sxpred)+tf.math.square(sypred)+\\\n",
    "            tf.math.square(szpred)\n",
    "        \n",
    "        #cost2 = tf.math.square(y_pred[:, 0])+tf.math.square(y_pred[:, 1])+\\\n",
    "        #    tf.math.square(y_pred[:, 2])\n",
    "        \n",
    "        cost2 = lamRhoSq*tf.reduce_sum(tf.nn.relu(cost2vec-1),axis=0)\n",
    "        cost = cost1+cost2\n",
    "        #print(elements)\n",
    "        #print(tf.reduce_sum(elements,axis=0))\n",
    "        return tf.reduce_mean(tf.reduce_sum(cost,axis=0))\n",
    "    return loss\n",
    "\n",
    "    \n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam', loss=myloss(0, 0.1), metrics=['accuracy'])\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=32)\n",
    "model.compile(optimizer='adam', loss=myloss(1, 0.1), metrics=['accuracy'])\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=32)\n",
    "model.compile(optimizer='adam', loss=myloss(2, 0.1), metrics=['accuracy'])\n",
    "model.fit(xtrain, ytrain, epochs=10, batch_size=32)\n",
    "\n",
    "X_test = np.random.randint(0, 2, size=20)  # Input features\n",
    "y_pred = model.predict(X_test);\n",
    "print(\"X_test = \", X_test)\n",
    "print(\"y_pred = \", y_pred)\n",
    "\n",
    "sxpred = 2*y_pred[:, 0]-1\n",
    "sypred = 2*y_pred[:, 1]-1\n",
    "szpred = 2*y_pred[:, 2]-1\n",
    "\n",
    "cost2vec = tf.math.square(sxpred)+tf.math.square(sypred)+\\\n",
    "            tf.math.square(szpred)\n",
    "print(cost2vec)\n",
    "print(tf.nn.relu(cost2vec-1))\n",
    "\n",
    "cost2 = tf.reduce_sum(tf.nn.relu(cost2vec-1),axis=0)\n",
    "print(\"cost2vec = \", cost2vec)\n",
    "print(\"cost2 = \", cost2)\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(yind, lamRhoSq):    \n",
    "    def loss(y_true, y_pred):\n",
    "        #print(\"y_pred[ind] = \", (y_pred)[:, yind])\n",
    "        #print(\"y_true[ind] = \", (y_true)[:, yind])\n",
    "        log_y_pred = tf.math.log(y_pred[:, yind])\n",
    "        #print(\"log_y_pred = \", log_y_pred)\n",
    "        #print(\"y_pred[:, yind] = \", y_pred[:, yind])\n",
    "        #print(\"1.0-y_pred[:, yind] = \", 1.0-y_pred[:, yind])\n",
    "        oneminuslog_y_pred = tf.math.log(1.0-y_pred[:, yind])\n",
    "        #print(\"oneminuslog_y_pred = \", oneminuslog_y_pred)        \n",
    "        #print(\"y_pred = \", y_pred)\n",
    "        cost1 = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true[:, yind])+\\\n",
    "            -tf.math.multiply_no_nan(x=oneminuslog_y_pred, y=1-y_true[:, yind])\n",
    "        \n",
    "        #print(\"cost1 = \", cost1)\n",
    "        sxpred = 2*y_pred[:, 0]-1\n",
    "        sypred = 2*y_pred[:, 1]-1\n",
    "        szpred = 2*y_pred[:, 2]-1\n",
    "\n",
    "        cost2vec = tf.math.square(sxpred)+tf.math.square(sypred)+\\\n",
    "            tf.math.square(szpred)\n",
    "        \n",
    "        #cost2 = tf.math.square(y_pred[:, 0])+tf.math.square(y_pred[:, 1])+\\\n",
    "        #    tf.math.square(y_pred[:, 2])\n",
    "        \n",
    "        cost2 = lamRhoSq*tf.reduce_sum(tf.nn.relu(cost2vec-1),axis=0)\n",
    "        #cost = cost1+cost2\n",
    "        cost = cost1/len(y_pred[0, :])\n",
    "        #print(elements)\n",
    "        #print(tf.reduce_sum(elements,axis=0))\n",
    "        return tf.reduce_mean(tf.reduce_mean(cost,axis=0))\n",
    "    return loss\n",
    "\n",
    "#log_y_pred = tf.math.log(y_pred[:, yind])\n",
    "\n",
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "\n",
    "#s = np.random.normal(mu, sigma, 1000);\n",
    "#x = BatchNormalization()(x)\n",
    "#np.random.seed(0) ; np.random.rand(4)\n",
    "#randseed=.3\n",
    "#np.random.seed(int(floor(randseed)));\n",
    "#errVec = np.random.normal(0,0.5,(4*2))\n",
    "#print(errVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningAllSpin(nqbit, depth, p, measureArr, convKXYZ, NofNTR, nshots,\n",
    "             delNNT, nnt1, lightCone, deltaLDim, NTest = [], testConvMeasure = [],\n",
    "                    convKNon0=[], testConvMeasureNon0=[], new=[]):\n",
    "    # In this function we design a neural network with three output to learn all the \n",
    "    # three spins at the same time. \n",
    "    # nqbit: number of qubits\n",
    "    # depth: circuit depth = time duration\n",
    "    # p: measurement rate\n",
    "    # measureArr: Array of mid circuit measurements. \n",
    "    # convKXYZ: measurement results of the spin of the reference qubit along X, Y and Z. \n",
    "    \n",
    "    # nshots: Number of circuit shots.\n",
    "    # errRate: random single-qubit Pauli noise error rate.     \n",
    "    #delNNT: jump in the number of training samples\n",
    "    # nnt1: first training samples number.\n",
    "    # lightCone: is a bitwise number determining whether we only use the light cone data or not.\n",
    "    #measureArr: Array of measured qubits\n",
    "    #countDic: Dictionary of measured outcomes with the repetition of a classical string.\n",
    "    #delNNT: delta in the increase in the number of training samples\n",
    "    #NofNTR: number of delNNT such that the total number of training samples is NofNTR*delNNT. \n",
    "    #We fix NofNTR to be 1.  \n",
    "    #convKVec: measurement results of the ancilla qubit. \n",
    "    # NTest: Number of test samples. \n",
    "    # Dim convKNon0: 3*nshots*(lenNon0+1)\n",
    "    nshotVec = range(nshots)\n",
    "    measureRes = np.zeros((3*nshots, depth, nqbit))\n",
    "    measureRes2 = np.zeros((3*nshots, depth, nqbit))\n",
    "    if convKNon0!=[]:\n",
    "        lenNon0 = np.shape(convKNon0)[2]\n",
    "        measureResNon0 = np.zeros((3*nshots, lenNon0-1))\n",
    "    \n",
    "    ancilla = np.zeros((nshots, 3))\n",
    "    ancilla2 = np.zeros((nshots, 3))\n",
    "    \n",
    "    #DecimalP = (str(p).replace('0.',''))\n",
    "    #Prob = \"0p{}\".format(DecimalP)\n",
    "    \n",
    "    #Training data:\n",
    "    # creating the measure array:\n",
    "    #convKVecRemoveZero = np.trim_zeros(convKVec)\n",
    "    \n",
    "    print(\"np.shape(convKXYZ) = \", np.shape(convKXYZ))\n",
    "    print(\"np.shape(measureRes) = \", np.shape(measureRes))\n",
    "    \n",
    "    for xyzcnt in range(3):\n",
    "        for nsh in range(nshots):\n",
    "            for t in range(depth):           \n",
    "                measureRes[nshots*xyzcnt+nsh, t, 0:nqbit] = 0.5*np.copy(convKXYZ[xyzcnt, nsh*(nqbit*depth+1)+t*nqbit:\n",
    "                                                     nsh*(nqbit*depth+1)+(t+1)*nqbit])+0.5*np.ones((1, nqbit))\n",
    "                if convKNon0!=[]:\n",
    "                    measureResNon0[nshots*xyzcnt+nsh, :] = np.add(0.5*convKNon0[nsh, xyzcnt, 0:-1], 0.5);\n",
    "                                        \n",
    "            ancilla[nsh, xyzcnt] = convKXYZ[xyzcnt, (nsh+1)*(nqbit*depth+1)-1]\n",
    "    print(\"measureResNon0 = \", np.transpose(measureResNon0))\n",
    "    #print(\"ancilla = \", np.transpose(ancilla))\n",
    "    #ancillaOnehot = tf.one_hot(\n",
    "    #    ancilla, 3, on_value = 1.0, off_value = 0.0, axis =-1)\n",
    "\n",
    "\n",
    "    nnt = nnt1 + int(np.floor(delNNT*(NofNTR)))\n",
    "    print(\"nnt={}, nnt1 = {}, delNNT={}, NofNTR={}\".format(nnt, nnt1, delNNT, NofNTR))\n",
    "    NSampVec = np.arange(nnt1, nnt, delNNT)\n",
    "    if NTest==[]:\n",
    "        NTest = int(min(abs(nshots-max(NSampVec)), 400));\n",
    "        print(\"NTest = \", NTest)\n",
    "    sigmaPredict = np.zeros((NofNTR, NTest))\n",
    "    sigmaPredictNon0 = np.zeros((NofNTR, NTest))\n",
    "    \n",
    "    NRepLearn = 1;            \n",
    "    Ncircuit=1;\n",
    "    n = 0;\n",
    "    realT = depth\n",
    "    if lightCone:\n",
    "        if nqbit/2-1<depth+1:\n",
    "            LDimOfArrays = nqbit;\n",
    "        else:\n",
    "            LDimOfArrays = 2*(depth+1)+2*deltaLDim;\n",
    "    else:\n",
    "        LDimOfArrays = nqbit;\n",
    "        \n",
    "    refInd = nqbit+1;\n",
    "    #middleInd = 2*L; #In the new version of the time evolution code for ancillas, reference qubit is entangled to the middle qubit which is at the \"end\" of the chain\n",
    "    middleInd = int(floor(nqbit/2)); #In the old version of the time evolution code for ancillas, reference qubit is entangled to the middle qubit which is at the \"middle\" of the chain                        \n",
    "    halfLDim = int(float(LDimOfArrays/2))\n",
    "    \n",
    "    #print(\"NofNTR = \", NofNTR)\n",
    "    scoresArr = np.zeros(NofNTR);\n",
    "    scoresArrNon0 = np.zeros(NofNTR);\n",
    "    \n",
    "    sigmaPredict = np.zeros((NofNTR, NTest))\n",
    "    sigmaPredictNon0 = np.zeros((NofNTR, 3, NTest))\n",
    "    lamRhoSq = 1;\n",
    "    \n",
    "    for ntr in range(NofNTR):        \n",
    "        NSamples = int(NSampVec[ntr]);        \n",
    "        print(\"NSamples = \", NSamples)\n",
    "        if NTest==[]:\n",
    "            NTest = int(min(abs(nshots-NSamples), 400));    \n",
    "        \n",
    "        nnn = 512*(1 + 2*int(NSamples//1000));        \n",
    "        vecSamples = sample(nshotVec, NSamples);        \n",
    "        trainInd = vecSamples;\n",
    "        testInd = [i for i in nshotVec if i not in trainInd]\n",
    "        \n",
    "        for xyzcnt in range(0, 3):            \n",
    "            ancillaTrain = np.zeros((NSamples, 3));\n",
    "            ancillaTest = np.zeros((NTest, 3));  \n",
    "            \n",
    "            model = Sequential()\n",
    "            #model.add(Conv2D(L, (4, 4), activation='relu', kernel_initializer='he_uniform', padding='same', \n",
    "            model.add(Conv2D(int(float(LDimOfArrays/2)), (4, 4), activation='relu', kernel_initializer='he_uniform', padding='same',\n",
    "            input_shape=(depth, LDimOfArrays, 1)))\n",
    "            #model.add(Conv2D(2*L, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "            model.add(Conv2D(LDimOfArrays, (3, 3), activation='relu',\n",
    "                             kernel_initializer='he_uniform', padding='same'))\n",
    "            \n",
    "            if depth>=1:\n",
    "                if depth>1:\n",
    "                    model.add(MaxPooling2D((2, 2)))\n",
    "                model.add(Dropout(0.2))\n",
    "\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(nnn, activation='relu'))\n",
    "                model.add(Dropout(0.2))\n",
    "                model.add(Dense(3, activation='sigmoid'))\n",
    "                \n",
    "                lrate = 0.001; #decay = .9\n",
    "                optimizer = tf.keras.optimizers.Adam(lrate);\n",
    "                kwargs = 'clipnorm';\n",
    "                #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, \\nesterov=False, name=\"adam\")                                                    \n",
    "                #            nesterov=False, name=\"SGD\", **kwargs)                \n",
    "            \n",
    "            NSamples = int(NSampVec[ntr])\n",
    "            if NSamples > 2000:\n",
    "                epoch = 400;\n",
    "            else:\n",
    "                epoch = 200;\n",
    "            \n",
    "            measureResTrain = np.zeros((NSamples, depth, nqbit));\n",
    "            measureResTest = np.zeros((NTest, depth, nqbit));\n",
    "\n",
    "            #if convKNon0!=[]:        \n",
    "            #    measureResNon0Train = np.zeros((NSamples, lenNon0-1));\n",
    "            #    measureResNon0Test = np.zeros((NTest, lenNon0-1));        \n",
    "                \n",
    "            #measureRes[nshots*xyzcnt+nsh, t, 0:nqbit]\n",
    "            for n in range(NSamples):                \n",
    "                measureResTrain[n, :, :] = measureRes[nshots*xyzcnt+trainInd[n], :, :]\n",
    "                ancillaTrain[n, xyzcnt] = ancilla[trainInd[n], xyzcnt]                    \n",
    "                    \n",
    "            for n in range(NTest):\n",
    "                xyzcntTest = 2; # We use the Z measurement data for the test data and making predictions.\n",
    "                measureResTest[n, :, :] = measureRes[nshots*xyzcntTest+testInd[n], :, :]\n",
    "                ancillaTest[n, xyzcntTest] = ancilla[testInd[n], xyzcntTest]\n",
    "                #if convKNon0!=[]:\n",
    "                        \n",
    "            convMeasure = np.zeros((NSamples, depth, LDimOfArrays, 1));\n",
    "            convMeasure[:, :, :, 0] = np.copy(measureResTrain);\n",
    "            convAncilla = np.copy(ancillaTrain);                \n",
    "        \n",
    "            if np.size(testConvMeasure)==0:\n",
    "                testConvMeasure = np.zeros((NTest, depth, LDimOfArrays, 1));\n",
    "                testConvMeasure[:, :, :, 0] = np.copy(measureResTest);            \n",
    "                        \n",
    "            #print(\"testConvMeasure = \", testConvMeasure[:5, :5, :5, 0]);        \n",
    "            #print(\"testConvAncilla[:10] = \", testConvAncilla[:10]);                      \n",
    "            #print(\"vLDimOfArrays = \", LDimOfArrays)\n",
    "                            \n",
    "            #model.compile(loss=myloss(xyzcnt, lamRhoSq), optimizer=optimizer, metrics=['accuracy']);                \n",
    "            model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']);\n",
    "            #softmax_cross_entropy_with_logits, #binary_crossentropy                \n",
    "                \n",
    "            if NSamples > 20000:\n",
    "                    n_epoch = 800\n",
    "            elif NSamples <= 20000 and NSamples > 1000:\n",
    "                    n_epoch = 600\n",
    "            else:\n",
    "                    n_epoch = 400\n",
    "\n",
    "            AccHist = [];\n",
    "            valAccHist = [];\n",
    "            histLen = 100;\n",
    "            histLen1 = 10;\n",
    "            #print(\"shape convMeasure = \", np.shape(convMeasure))\n",
    "            #print(\"shape convAncilla = \", np.shape(convAncilla)) \n",
    "            testConvAncilla = np.zeros((NTest, 3));                \n",
    "            testConvAncilla = np.copy(ancillaTest);     \n",
    "            \"\"\"\n",
    "            for epoch in range(n_epoch):\n",
    "                history = model.fit(convMeasure, convAncilla, epochs = 1, batch_size = 100, validation_split=0.1, verbose=0)                \n",
    "                if epoch%100==0:\n",
    "                    a=1;\n",
    "                    #print(\"acc = \", epoch, history.history['val_accuracy'][-1], history.history['accuracy'][-1])\n",
    "                    \n",
    "                if epoch > histLen1:\n",
    "                    if (history.history['val_accuracy'][-1]<.55 and \n",
    "                        history.history['accuracy'][-1]>.8) or \\\n",
    "                    (history.history['val_accuracy'][-1] > .98 and \n",
    "                        history.history['accuracy'][-1] > .98):\n",
    "                        a=1;\n",
    "                        #break\n",
    "\n",
    "                AccHist.append(history.history['accuracy'][-1])                \n",
    "                valAccHist.append(history.history['val_accuracy'][-1])\n",
    "                if epoch > histLen:\n",
    "                    if np.average(AccHist[-histLen:-1])-AccHist[-histLen]<0.001 :\n",
    "                        a=1;\n",
    "                            #print(np.average(AccHist[-histLen:-1]), AccHist[-histLen])\n",
    "                        #break\n",
    "                    elif np.average(valAccHist[-histLen:-1])-valAccHist[-histLen]<0.001:\n",
    "                            #print(np.average(valAccHist[-histLen:-1]), valAccHist[-histLen])\n",
    "                        a=1;\n",
    "                        #break;\n",
    "            sys.stdout.flush()           \n",
    "            #for n, layer in enumerate(model.layers):\n",
    "            #    print(\"n = \", n)\n",
    "            #    print(\"layer = \", layer)\n",
    "                #print(layer.name, layer)                \n",
    "                #print(\"model.layers[n].weights = \", model.layers[n].weights)\n",
    "                #print(model.layers[n].bias.numpy())                \n",
    "            \n",
    "\n",
    "            scores = model.evaluate(testConvMeasure, testConvAncilla, verbose=0);\n",
    "            scoresArr[ntr] += scores[1]/NRepLearn;                \n",
    "            predict=model.predict(testConvMeasure); \n",
    "            #input1.reshape(1, d, nq, 1))                 \n",
    "            #print(\"testConvMeasure = \", np.transpose(testConvMeasure[:20, :, :, :]))\n",
    "            #print(\"testConvAncilla = \", np.transpose(testConvAncilla[:40, :]))            \n",
    "            #print(\"predict = \", (predict[:40, :]))\n",
    "\n",
    "            classes=np.argmax(predict,axis=1);\n",
    "            tempSigma = 1*(predict)-(np.ones(np.shape(predict))-predict);                \n",
    "            if scores[1]>.96:\n",
    "                a=1;\n",
    "                #print(\"break\");\n",
    "                #break\n",
    "            \n",
    "            #if scoresArr[ntr]>.96:\n",
    "            #    print(\"break\");\n",
    "                #break         \n",
    "            \"\"\"\n",
    "            \n",
    "            if convKNon0!=[]:                \n",
    "                measureResNon0Train = np.zeros((NSamples, lenNon0-1));\n",
    "                measureResNon0Test = np.zeros((NTest, lenNon0-1));        \n",
    "                #convMeasureNon0 = np.zeros((NSamples, lenNon0-1, 1));\n",
    "                #convMeasureNon0[:, :, 0] = np.copy(measureResNon0Train);\n",
    "                #print(\"measureResNon0Train = \", np.transpose(measureResNon0Train))\n",
    "                #print(\"ancillaTrain = \", np.transpose(ancillaTrain))\n",
    "                for n in range(NSamples):                    \n",
    "                    measureResNon0Train[n, :] = measureResNon0[nshots*xyzcnt+trainInd[n], :]\n",
    "                for n in range(NTest):                    \n",
    "                    xyzcntTest = 2; # We use the Z measurement data for making predictions. \n",
    "                    measureResNon0Test[n, :] = measureResNon0[nshots*xyzcntTest+testInd[n], :]\n",
    "                    \n",
    "                #print(\"measureResNon0 = \", np.transpose(measureResNon0[:10, :]))\n",
    "                \n",
    "                #if np.size(testConvMeasureNon0)==0:\n",
    "                    #print(\"if convKNon0!=[]:\")\n",
    "                    #testConvMeasureNon0 = np.zeros((NTest, lenNon0-1, 1));\n",
    "                    #testConvMeasureNon0[:, :, 0] = np.copy(measureResNon0Test);\n",
    "                #print(\"testConvMeasureNon0 = \", np.transpose(testConvMeasureNon0))\n",
    "                \n",
    "                modelNon0 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Flatten(input_shape=(lenNon0-1, 1)),\n",
    "                tf.keras.layers.Dense(50*(lenNon0-1), activation='relu'),\n",
    "                tf.keras.layers.Dense(50*(lenNon0-1), activation='relu'),\n",
    "                tf.keras.layers.Dense(3, activation='sigmoid')]);\n",
    "                input_shape=(realT, LDimOfArrays, 1);\n",
    "                \n",
    "                if realT>=1:\n",
    "                    lrate = 0.001;\n",
    "                    sgd = SGD(learning_rate=lrate, momentum=1, nesterov=False);\n",
    "                    kwargs = 'clipnorm';\n",
    "                    #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, \\\n",
    "                    #        nesterov=False, name=\"SGD\")                                      \n",
    "                    #            nesterov=False, name=\"SGD\", **kwargs)\n",
    "                    #optimizer = tensorflow_addons.keras.optimizers.AdamW(lrate);\n",
    "                    optimizer = tf.keras.optimizers.Adam(lrate);\n",
    "                    \n",
    "                    #modelNon0.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']);\n",
    "                    modelNon0.compile(loss=myloss(xyzcnt, lamRhoSq), optimizer=optimizer, metrics=['accuracy']);\n",
    "                    n_epoch = 10\n",
    "                    AccHist = [];\n",
    "                    valAccHist = [];\n",
    "                    histLen = 100;\n",
    "                    histLen1 = 10;\n",
    "                    #print(\"measureResNon0Train = \", np.transpose(measureResNon0Train))\n",
    "                    #print(\"ancillaTrain = \", np.transpose(ancillaTrain[:60, :]))                                \n",
    "                    \n",
    "                    for epoch in range(n_epoch): #convMeasureNon0\n",
    "                        history = modelNon0.fit(measureResNon0Train, ancillaTrain, epochs = 1, \n",
    "                                                batch_size = 100, validation_split=0.1, verbose=0)\n",
    "                        \n",
    "                        if epoch%100==0:\n",
    "                            a=1;                    \n",
    "                        if epoch > histLen1:\n",
    "                            if (history.history['val_accuracy'][-1]<.55 and \n",
    "                                history.history['accuracy'][-1]>.8) or \\\n",
    "                            (history.history['val_accuracy'][-1] > .98 and \n",
    "                             history.history['accuracy'][-1] > .98):\n",
    "                                break\n",
    "                        AccHist.append(history.history['accuracy'][-1])                \n",
    "                        valAccHist.append(history.history['val_accuracy'][-1])                                                \n",
    "                        if epoch > histLen:\n",
    "                            if np.average(AccHist[-histLen:-1])-AccHist[-histLen]<0.001 :\n",
    "                                a=1;\n",
    "                                break\n",
    "                            elif np.average(valAccHist[-histLen:-1])-valAccHist[-histLen]<0.001:\n",
    "                                a=1;\n",
    "                                break;\n",
    "                                \n",
    "                    sys.stdout.flush()\n",
    "                    scoresNon0 = modelNon0.evaluate(measureResNon0Test, \n",
    "                                                    ancillaTest, verbose=0);\n",
    "                    scoresArrNon0[ntr] += scoresNon0[1]/NRepLearn;\n",
    "                    predictNon0=modelNon0.predict(measureResNon0Test); #input1.reshape(1, d, nq, 1))\n",
    "                    \n",
    "                    #print(\"testConvMeasure = \", np.transpose(testConvMeasure[:20, :, :, :]))\n",
    "                    #print(\"measureResNon0Test = \", np.transpose(measureResNon0Test[:20, :]))\n",
    "                    #print(\"ancillaTest = \", np.transpose(ancillaTest[:20, :]))                     \n",
    "                    print(\"predictNon0 = \", np.transpose(predictNon0[:20]))\n",
    "\n",
    "                    classesNon0=np.argmax(predictNon0,axis=1);\n",
    "                    tempSigmaNon0 = 1*(predictNon0)-(np.ones(np.shape(predictNon0))-predictNon0);\n",
    "                    #print(\"tempSigmaNon0 = \", tempSigmaNon0)\n",
    "                    #if scoresNon0[1]>.96:\n",
    "                        #break            \n",
    "                if scoresArrNon0[ntr]>.96:\n",
    "                    a=1;\n",
    "                    #print(\"score>0.96\");\n",
    "                    #break\n",
    "                #print(\"shape tempSigmaNon0 = \", np.shape(tempSigmaNon0))\n",
    "                #print(\"shape sigmaPredictNon0 = \", np.shape(sigmaPredictNon0))\n",
    "                sigmaPredictNon0[ntr, :, 0:NTest] = np.transpose(np.array(tempSigmaNon0))    \n",
    "        #if convKNon0!=[]:\n",
    "        #    sigmaPredictNon0[ntr, xyzcnt, 0:NTest] = np.copy(np.array(tempSigmaNon0[:, 0]))\n",
    "\n",
    "        sigmaPredict[ntr, 0:NTest] = 0 #np.copy(np.array(tempSigma[:, 0]))\n",
    "        #print(\"scoresArr = \", scoresArr)\n",
    "        #df = pd.DataFrame(scoresArr)\n",
    "        #if TequalsPT == 0:\n",
    "        #    df.to_csv(\"accuracy-L{}-p{}-c1_{}-c2_{}-Nc{}-PT{}-nti{}-ntf{}-delNNT{}-NLrn{}.csv\".format(L, p, c1, c2, Nc, PT, nnt1, nnt2, delNNT, NRepLearn))\n",
    "        #if TequalsPT == 1:\n",
    "        #    df.to_csv(\"accuracy-L{}-p{}-TeqPT-c1_{}-c2_{}-Nc{}-PT{}-nti{}-ntf{}-delNNT{}-NLrn{}.csv\".format(L, p, c1, c2, Nc, PT, nnt1, nnt2, delNNT, NRepLearn))\n",
    "\n",
    "    #print(\"sigmaPredict = \", sigmaPredict)\n",
    "    return model, sigmaPredict, NTest, testConvMeasure, testConvMeasureNon0, sigmaPredictNon0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def learningNon0(nqbit, depth, p, measureArr, convKNon0, NofNTR, nshots, \n",
    "             delNNT, nnt1, lightCone, deltaLDim, NTest = [],\n",
    "             testConvMeasureNon0=[]):   \n",
    "    # In this function we base the learning only on the measured qubits and we remove \n",
    "    # the unmeasured qubits from the input data. \n",
    "    # nqbit: number of qubits\n",
    "    # depth: circuit depth = time duration\n",
    "    # p: measurement rate\n",
    "    # measureArr: Array of mid circuit measurements. \n",
    "    # convKVec: measurement results of the spin of the reference qubit. \n",
    "    \n",
    "    # nshots: Number of circuit shots.\n",
    "    # errRate: random single-qubit Pauli noise error rate.     \n",
    "    #delNNT: jump in the number of training samples\n",
    "    # nnt1: first training samples number.\n",
    "    # lightCone: is a bitwise number determining whether we only use the light cone data or not.\n",
    "    #measureArr: Array of measured qubits\n",
    "    #countDic: Dictionary of measured outcomes with the repetition of a classical string.\n",
    "    #delNNT: delta in the increase in the number of training samples\n",
    "    #NofNTR: number of delNNT such that the total number of training samples is NofNTR*delNNT. \n",
    "    #We fix NofNTR to be 1.  \n",
    "    #convKVec: measurement results of the ancilla qubit. \n",
    "    # NTest: Number of test samples. \n",
    "\n",
    "    nshotVec = range(nshots)\n",
    "    measureRes = np.zeros((nshots, depth, nqbit))\n",
    "    measureRes2 = np.zeros((nshots, depth, nqbit))\n",
    "    if convKNon0!=[]:\n",
    "        #print(\"convKNon0 = \", convKNon0)\n",
    "        lenNon0 = np.shape(convKNon0)[1]\n",
    "        #print(\"lenNon0 = \", lenNon0)\n",
    "        #print(\"np.shape(convKNon0) = \", np.shape(convKNon0))\n",
    "        measureResNon0 = np.zeros((nshots, lenNon0-1))\n",
    "    \n",
    "    ancilla = np.zeros(nshots)\n",
    "    ancilla2 = np.zeros(nshots)\n",
    "    \n",
    "    #DecimalP = (str(p).replace('0.',''))\n",
    "    #Prob = \"0p{}\".format(DecimalP)\n",
    "    \n",
    "    #Training data:\n",
    "    # creating the measure array:\n",
    "    #print(\"shape convKVec = \", np.shape(convKVec))\n",
    "    #print(\"shape measureRes = \", np.shape(measureRes))\n",
    "    #print(\"nsh*(nqbit*depth+1)+t*nqbit: = \", nsh*(nqbit*depth+1)+t*nqbit)\n",
    "    #convKVecRemoveZero = np.trim_zeros(convKVec)\n",
    "    \n",
    "    #print(\"np.shape(convKVec) = \", np.shape(convKVec))\n",
    "    for nsh in range(nshots):\n",
    "        for t in range(depth):            \n",
    "            if convKNon0!=[]:\n",
    "                measureResNon0[nsh, :] = np.add(0.5*convKNon0[nsh, 0:-1], 0.5);\n",
    "\n",
    "        ancilla[nsh] = convKVec[(nsh+1)*(nqbit*depth+1)-1]\n",
    "        \n",
    "        #ancilla2[nsh] = convKArr[nsh, depth*nqbit]\n",
    "        #nsh*(nqbit*depth+1)+(depth)*nqbit+nqbit\n",
    "    #measureRes = np.add(measureRes, 1)\n",
    "    #print(\"measureResNon0 = \", measureResNon0[:10, :])\n",
    "    \n",
    "    nnt = nnt1 + int(np.floor(delNNT*(NofNTR)))\n",
    "    #print(\"NofNTR in learning = \", NofNTR)\n",
    "    #print(\"nnt1 = \", nnt1)\n",
    "    #print(\"nnt = \", nnt)    \n",
    "    NSampVec = np.arange(nnt1, nnt, delNNT)\n",
    "    #fileNameArr = [];\n",
    "    NRepLearn = 1;            \n",
    "    Ncircuit=1;\n",
    "    n = 0;\n",
    "    realT = depth\n",
    "    if lightCone:\n",
    "        if nqbit/2-1<realT+1:\n",
    "            LDimOfArrays = nqbit;\n",
    "        else:\n",
    "            LDimOfArrays = 2*(realT+1)+2*deltaLDim;\n",
    "    else:\n",
    "        LDimOfArrays = nqbit;\n",
    "        \n",
    "    refInd = nqbit+1;\n",
    "    #middleInd = 2*L; #In the new version of the time evolution code for ancillas, reference qubit is entangled to the middle qubit which is at the \"end\" of the chain    \n",
    "    #print(\"NofNTR = \", NofNTR)\n",
    "    scoresArr = np.zeros(NofNTR);\n",
    "    scoresArrNon0 = np.zeros(NofNTR);\n",
    "    \n",
    "    if NTest==[]:\n",
    "        NTest = int(min(abs(nshots-max(NSampVec)), 400));    \n",
    "    \n",
    "    print(\"NTest in learning = \", NTest)\n",
    "    \n",
    "    sigmaPredictNon0 = np.zeros((NofNTR, NTest))\n",
    "    for ntr in range(NofNTR):\n",
    "        NSamples = int(NSampVec[ntr])\n",
    "        if NSamples > 2000:\n",
    "            epoch = 400\n",
    "        else:\n",
    "            epoch = 200\n",
    "        \n",
    "        ancillaTrain = np.zeros((NSamples));\n",
    "        ancillaTest = np.zeros(NTest);\n",
    "        \n",
    "        print(\"shape nshotVec = \", np.shape(nshotVec))\n",
    "        print(\"NSamples = \", NSamples)\n",
    "        vecSamples = sample(nshotVec, NSamples);\n",
    "        \n",
    "        trainInd = vecSamples;\n",
    "        testInd = [i for i in nshotVec if i not in trainInd]\n",
    "                                    \n",
    "        print(\"ancilla = \", ancilla[:10])\n",
    "        #print(\"measureResTest = \", measureResTest[:10, :, :])\n",
    "        #print(\"ancillaTest = \", ancillaTest[:])        \n",
    "               \n",
    "        nnn = 512*(1 + 2*int(NSamples//1000))\n",
    "        print(\"vLDimOfArrays = \", LDimOfArrays)        \n",
    "                \n",
    "        for nl in range(NRepLearn):                \n",
    "            if convKNon0!=[]:        \n",
    "                measureResNon0Train = np.zeros((NSamples, lenNon0-1));\n",
    "                measureResNon0Test = np.zeros((NTest, lenNon0-1));\n",
    "            \n",
    "                for n in range(NSamples):            \n",
    "                    measureResNon0Train[n, :] = measureResNon0[trainInd[n], :]            \n",
    "                for n in range(NTest):                   \n",
    "                    measureResNon0Test[n, :] = measureResNon0[testInd[n], :]\n",
    "                \n",
    "                modelNon0 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Flatten(input_shape=(lenNon0-1, 1)),\n",
    "                tf.keras.layers.Dense(50*(lenNon0-1), activation='relu'),                \n",
    "                #tf.keras.layers.Dropout(0.2),                \n",
    "                tf.keras.layers.Dense(50*(lenNon0-1), activation='relu'),                \n",
    "                tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "                ])            \n",
    "                input_shape=(realT, LDimOfArrays, 1)\n",
    "                if realT>=1:\n",
    "                    lrate = 0.05;\n",
    "                    sgd = SGD(learning_rate=lrate, momentum=1, nesterov=False);\n",
    "                    kwargs = 'clipnorm';\n",
    "                    #optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, \\\n",
    "                    #        nesterov=False, name=\"SGD\")                                                    \n",
    "                    #            nesterov=False, name=\"SGD\", **kwargs)                \n",
    "                    optimizer = tf.keras.optimizers.Adam(0.01);\n",
    "                    modelNon0.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']);\n",
    "                    n_epoch = 10\n",
    "                    AccHist = [];\n",
    "                    valAccHist = [];\n",
    "                    histLen = 100\n",
    "                    histLen1 = 10\n",
    "                    for epoch in range(n_epoch):\n",
    "                        history = modelNon0.fit(measureResNon0Train, convAncilla, epochs = 1, batch_size = 100, validation_split=0.1, \n",
    "                        verbose=0)\n",
    "                        if epoch%100==0:\n",
    "                            a=1;                    \n",
    "                        if epoch > histLen1:\n",
    "                            if (history.history['val_accuracy'][-1]<.55 and \n",
    "                                history.history['accuracy'][-1]>.8) or \\\n",
    "                            (history.history['val_accuracy'][-1] > .98 and \n",
    "                             history.history['accuracy'][-1] > .98):\n",
    "                                break\n",
    "                        AccHist.append(history.history['accuracy'][-1])                \n",
    "                        valAccHist.append(history.history['val_accuracy'][-1])                                                \n",
    "                        if epoch > histLen:\n",
    "                            if np.average(AccHist[-histLen:-1])-AccHist[-histLen]<0.001 :\n",
    "                                a=1;\n",
    "                                break\n",
    "                            elif np.average(valAccHist[-histLen:-1])-valAccHist[-histLen]<0.001:\n",
    "                                a=1;\n",
    "                                break;\n",
    "                    sys.stdout.flush()           \n",
    "                \n",
    "                    scoresNon0 = modelNon0.evaluate(measureResNon0Test, ancillaTest, verbose=0);\n",
    "                    scoresArrNon0[ntr] += scoresNon0[1]/NRepLearn;                                \n",
    "                    predictNon0=modelNon0.predict(measureResNon0Test); #input1.reshape(1, d, nq, 1))                \n",
    "                    classesNon0=np.argmax(predictNon0,axis=1);\n",
    "                    tempSigmaNon0 = 1*(predictNon0)-(np.ones(np.shape(predictNon0))-predictNon0);\n",
    "                    #print(\"tempSigmaNon0 = \", np.transpose(tempSigmaNon0[:20]))\n",
    "                    if scoresNon0[1]>.96:\n",
    "                        break\n",
    "            \n",
    "                if scoresArrNon0[ntr]>.96:\n",
    "                    print(\"break\");\n",
    "                    break\n",
    "        if convKNon0!=[]:\n",
    "            sigmaPredictNon0[ntr, 0:NTest] = np.copy(np.array(tempSigmaNon0[:, 0]))\n",
    "        \n",
    "    return model, sigmaPredictNon0, NTest, measureResTest\n",
    "\n",
    "\n",
    "\n",
    "#from tensorflow import keras\n",
    "nq=4;d=4;hundredp=50;p=hundredp/100;refQbitAxis=\"Z\";\n",
    "nshots=1; errRate=0.1;lightCone=0; deltaLDim=0; ifsave=0;\n",
    "learningT1=1;learnDelT=1;renyiInd=2;trajNum=1;delNNT=[];seed=2.387;\n",
    "if delNNT==[]:\n",
    "    delNNT=int(.05*nshots);nnt1=.9*nshots;\n",
    "NofNTR = 1;\n",
    "\n",
    "#circ = genCircConfig(nq, d, p, seed)\n",
    "\"\"\"\n",
    "marrX, convKX, convKXNon0 = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"X\", nshots, errRate);\n",
    "marrY, convKY, convKYNon0 = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"Y\", nshots, errRate);\n",
    "marrZ, convKZ, convKZNon0 = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"Z\", nshots, errRate);\n",
    "print(\"np.shape(convKXNon0) = \", np.shape(convKXNon0))\n",
    "print(\"np.shape(convKX) = \", np.shape(convKX))\n",
    "print(convKY[:10])\n",
    "convKXYZ = np.zeros((3, np.shape(convKX)[0]))\n",
    "convKXYZ[0, :] = convKX\n",
    "convKXYZ[1, :] = convKY\n",
    "convKXYZ[2, :] = convKZ\n",
    "\n",
    "convKXYZNon0 = np.zeros((nshots, 3, np.shape(convKXNon0)[1]))\n",
    "convKXYZNon0[:, 0, :] = convKXNon0[:, :]\n",
    "convKXYZNon0[:, 1,  :] = convKYNon0[:, :]\n",
    "convKXYZNon0[:, 2, :] = convKZNon0[:, :]\n",
    "\n",
    "A = learningAllSpin(nq, d, p, marrX, convKXYZ, NofNTR, nshots,\n",
    "            delNNT, nnt1, lightCone, deltaLDim, NTest = [],\n",
    "            testConvMeasure = [], convKNon0=convKXYZNon0, testConvMeasureNon0=[], new=[])\n",
    "\"\"\";\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#from qiskit import QuantumCircuit, assemble, Aer\n",
    "#from math import pi, sqrt\n",
    "#from qiskit.visualization import plot_bloch_multivector, plot_histogram\n",
    "sim = Aer.get_backend('aer_simulator')\n",
    "qc = QuantumCircuit(1)\n",
    "qc.u(pi/2, pi/2, pi, 0)\n",
    "qc.draw()\n",
    "qc.save_statevector()\n",
    "qobj = assemble(qc)\n",
    "state = sim.run(qobj).result().get_statevector()\n",
    "print(state)\n",
    "\n",
    "\n",
    "\n",
    "circ = QuantumCircuit(2)\n",
    "circ.h(0)\n",
    "circ.cx(0, 1)\n",
    "circ.measure_all()\n",
    "\n",
    "# Transpile for simulator\n",
    "simulator = Aer.get_backend('aer_simulator')\n",
    "transpiledCirc = transpile(circ, simulator)\n",
    "\n",
    "# Run and get counts\n",
    "result = simulator.run(transpiledCirc).result()\n",
    "counts = result.get_counts(transpiledCirc)\n",
    "print(counts)\n",
    "#plot_histogram(counts, title='Bell-State counts')\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeEvolveAncilla(nqbit, circDep, p, initStateLabel, circConfig, renyiInd, \\\n",
    "                      refQbitAxis, Nshots, errRate=0, readoutErr=0, seed=[]):\n",
    "    nNodes=nqbit*circDep\n",
    "    nUnitary=int(nNodes/2)\n",
    "    measureArr=np.zeros((circDep, nqbit))\n",
    "    measureVec = np.zeros(nNodes)\n",
    "    if circConfig==\"None\":\n",
    "        measureVec=[(rand(1)[0]<p)+0.0 for i in range(nNodes)]\n",
    "        #measureVec=measureVec+np.zeros(nqbit*circDep)                                                                          \n",
    "        #print(\"measureVec = \", measureVec)                                                                                     \n",
    "        for t in range(circDep):\n",
    "            measureArr[t, :]=[measureVec[i+t*nqbit] for i in range(nqbit)]\n",
    "\n",
    "\n",
    "    #print(\"measureArr = \", measureArr)                                                                                         \n",
    "\n",
    "    unitaryArr=np.zeros((nUnitary, 4, 4))+0j\n",
    "    dim=4;\n",
    "    if circConfig!=\"None\":\n",
    "        measureArr=circConfig[0]\n",
    "        unitaryArr=circConfig[1]\n",
    "        for t in range(circDep):\n",
    "            measureVec[t*nqbit:(t+1)*nqbit] = measureArr[t, :]\n",
    "\n",
    "    #print(\"measureArr = \", measureArr)                                                                                         \n",
    "    #print(\"measureVec = \", measureVec)\n",
    "\n",
    "    # The ancilla qubit is put at the  of the string of the qubits. This way we tensor product the states                       \n",
    "    # from left to right. The ancilla qbit is entangled to the qbit at the middle of the string at Ind=floor(nqbit/2)           \n",
    "    dim = 4;\n",
    "    n2qbit = int(floor(nqbit/2))\n",
    "    state = Statevector.from_int(0, 2**(nqbit+1))\n",
    "\n",
    "    A=rand(2, 2)\n",
    "    unitCirc = QuantumCircuit(nqbit+1, 2)\n",
    "    midind = int(floor((nqbit-1)/2))\n",
    "    # Add a H gate on qubit 0                                                                                                   \n",
    "    #circuit.h(n-1)                                                                                                             \n",
    "    #circuit.cx(n-1, midind)                                                                                                    \n",
    "\n",
    "    #U = Operator(circuit)                                                                                                      \n",
    "    #identity = Matrix(one(eltype(A))I, size(A,1), size(A,1))                                                                   \n",
    "    identityMat = np.identity(np.shape(A)[0])\n",
    "    if initStateLabel==\"mixed\":\n",
    "        for t in range(circDep):\n",
    "            if t%2==1:\n",
    "                #U = 1;                                                                                                         \n",
    "                for ngate in range(n2qbit):\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                    #print(\"Qprime = \", Qprime)                                                                                 \n",
    "                    #print(\"2*ngate = \", 2*ngate)                                                                               \n",
    "                    gate2x2 = unitCirc.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "\n",
    "            elif t%2==0:\n",
    "                #U = identityMat                                                                                                \n",
    "                for ngate in range(n2qbit-1):\n",
    "                    print(\"t = \", t)\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)    \n",
    "                    #print(\"Qprime = \", Qprime)                                                                                 \n",
    "                    #print(\"2*ngate = \", 2*ngate)                                                                               \n",
    "                    gate2x2 = unitCirc.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "\n",
    "            elif t%2==0:\n",
    "                #U = identityMat                                                                                                \n",
    "                for ngate in range(n2qbit-1):\n",
    "                    print(\"t = \", t)\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                    #print(\"Qprime = \", Qprime)                                                                                 \n",
    "                    #print(\"2*ngate = \", 2*ngate)                                                                               \n",
    "                    gate2x2 = unitCirc.unitary(Qprime, [2*ngate+1, 2*(ngate+1)])\n",
    "\n",
    "                #U = kron(U, identityMat)                                                                                       \n",
    "\n",
    "    state = state.evolve(unitCirc)\n",
    "    #state.__dir__()                                                                                                            \n",
    "    BellGateCirc = QuantumCircuit(nqbit+1)\n",
    "    #initState = Statevector.from_int(0, 2**(nqbit+1))                                                                          \n",
    "    #q = QuantumRegister(nqbit)                                                                                                 \n",
    "    #cbit = ClassicalRegister(nqbit)                                                                                            \n",
    "    #qc = QuantumCircuit(q, cbit)                                                                                               \n",
    "\n",
    "    #qc.initialize(mixedState, [q[0],q[1]])                                                                                     \n",
    "    BellGateCirc.initialize(state)\n",
    "\n",
    "    hGate = BellGateCirc.h(midind)   # Hadamard gate on the last qubit.                                                         \n",
    "    cnotgate = BellGateCirc.cx(midind, nqbit)  # CNOT between the mid qubit and the last qubit.                                 \n",
    "    state = state.evolve(BellGateCirc)\n",
    "    #backend_sim = Aer.get_backend('qasm_simulator')                                                                            \n",
    "\n",
    "    # Execute the circuit on the qasm simulator.                     \n",
    "    \n",
    "    # We've set the number of repeats of the circuit                                                                            \n",
    "    # to be 1024, which is the default.                                                                                         \n",
    "    #job = backend_sim.run(transpile(qc, backend_sim), shots=1024)                                                              \n",
    "\n",
    "    qreg  = QuantumRegister((nqbit+1)) #                                                                                        \n",
    "    qregX  = QuantumRegister((nqbit+1)) #                                                                                       \n",
    "    qregY  = QuantumRegister((nqbit+1)) #                                                                                       \n",
    "    qregZ  = QuantumRegister((nqbit+1)) #                                                                                       \n",
    "    if refQbitAxis==\"None\": # In this case we measure the state of the reference qubit at the final step.                       \n",
    "        cr  = ClassicalRegister((nqbit)*circDep)\n",
    "        hybCirc = QuantumCircuit(qreg,cr)        \n",
    "    else:\n",
    "        cr = ClassicalRegister((nqbit)*circDep+1)\n",
    "        crX  = ClassicalRegister((nqbit)*circDep+1)\n",
    "        crY  = ClassicalRegister((nqbit)*circDep+1)\n",
    "        crZ  = ClassicalRegister((nqbit)*circDep+1)\n",
    "    hybCircX = QuantumCircuit(qregX,crX)\n",
    "    hybCircY = QuantumCircuit(qregY,crY)\n",
    "    hybCircZ = QuantumCircuit(qregZ,crZ)\n",
    "    hybCirc = QuantumCircuit(qreg,cr)                \n",
    "    hybCirc.initialize(state)                \n",
    "        \n",
    "    if refQbitAxis==\"All\":\n",
    "        hybCircX.initialize(state)\n",
    "        hybCircY.initialize(state)\n",
    "        hybCircZ.initialize(state)\n",
    "    \n",
    "    Qprime=np.zeros((dim, dim))+0.0j\n",
    "    for t in range(circDep):\n",
    "        ### Measurement                                                                                                         \n",
    "        #cntMeasure = np.count_nonzero(measureArr)                                                                              \n",
    "        #qreg  = QuantumRegister(nqbit+1) #                                                                                     \n",
    "        #cr  = ClassicalRegister(nqbit+1)                                                                                       \n",
    "        if t%2==0:\n",
    "            for ngate in range(n2qbit):\n",
    "                if circConfig==\"None\":\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                else:\n",
    "                    #unitInd=ngate+int(t/2)*nqbit                                                                               \n",
    "                    unitInd=ngate+t*n2qbit\n",
    "                    Qprime=np.copy(unitaryArr[unitInd, :, :])\n",
    "                #print(\"unitInd = \", unitInd)                                                                                   \n",
    "                gate2x2=hybCirc.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "                if refQbitAxis==\"All\":\n",
    "                    gate2x2X=hybCircX.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "                    gate2x2Y=hybCircY.unitary(Qprime, [2*ngate, 2*ngate+1])                    \n",
    "                    gate2x2Z=hybCircZ.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "        elif t%2==1:\n",
    "            for ngate in range(1, n2qbit+1):\n",
    "                if circConfig==\"None\":\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                else:\n",
    "                    unitInd=ngate-1+t*n2qbit\n",
    "                #print(\"unitInd = \", unitInd)                                                                                   \n",
    "                if ngate!=n2qbit:\n",
    "                    gate2x2 = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])\n",
    "                    if refQbitAxis==\"All\":\n",
    "                        gate2x2X = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])\n",
    "                        gate2x2Y = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])\n",
    "                        gate2x2Z = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])\n",
    "                else:\n",
    "                    gate2x2 = hybCirc.unitary(Qprime, [2*ngate-1, 0])\n",
    "                    if refQbitAxis==\"All\":\n",
    "                        gate2x2X = hybCirc.unitary(Qprime, [2*ngate-1, 0])\n",
    "                        gate2x2Y = hybCirc.unitary(Qprime, [2*ngate-1, 0])\n",
    "                        gate2x2Z = hybCirc.unitary(Qprime, [2*ngate-1, 0])\n",
    "\n",
    "\n",
    "        for m in range(nqbit):\n",
    "            if measureArr[t, m]:\n",
    "                hybCirc.measure(qreg[m], cr[m+nqbit*t])\n",
    "                if refQbitAxis==\"All\":\n",
    "                    hybCircX.measure(qregX[m], crX[m+nqbit*t])\n",
    "                    hybCircY.measure(qregY[m], crY[m+nqbit*t])\n",
    "                    hybCircZ.measure(qregZ[m], crZ[m+nqbit*t])\n",
    "    if refQbitAxis==\"Z\":\n",
    "        hybCirc.measure(qreg[nqbit], cr[(nqbit)*circDep])\n",
    "        #hybCircZ.measure(qreg[nqbit], cr[(nqbit)*circDep])                                                                     \n",
    "    elif refQbitAxis==\"X\":\n",
    "        hybCirc.h(nqbit)\n",
    "        hybCirc.measure(qreg[nqbit], cr[(nqbit)*circDep])\n",
    "    elif refQbitAxis==\"Y\":\n",
    "        hybCirc.u(np.pi/2, np.pi/2, np.pi, nqbit);\n",
    "        hybCirc.measure(qreg[nqbit], cr[(nqbit)*circDep])\n",
    "    elif refQbitAxis==\"All\":\n",
    "        hybCircZ.measure(qregZ[nqbit], crZ[(nqbit)*circDep])\n",
    "        #hybCircX.u(np.pi/2, np.pi/2, np.pi, nqbit);                                                                            \n",
    "        hybCircX.measure(qregX[nqbit], crX[(nqbit)*circDep])\n",
    "        hybCircY.u(np.pi/2, np.pi/2, np.pi, nqbit);\n",
    "        hybCircY.measure(qregY[nqbit], crY[(nqbit)*circDep])\n",
    "        \n",
    "\n",
    "    #backend_sim = Aer.get_backend('qasm_simulator')                                                                            \n",
    "    backend_sim = Aer.get_backend('statevector_simulator')\n",
    "\n",
    "        # Execute the circuit on the qasm simulator.                                                                            \n",
    "        # We've set the number of repeats of the circuit                                                                        \n",
    "        # to be 1024, which is the default.                                                                                     \n",
    "    if refQbitAxis==\"None\":\n",
    "        job = backend_sim.run(transpile(hybCirc, backend_sim), shots=1)\n",
    "\n",
    "    elif refQbitAxis==\"All\":\n",
    "        jobX = backend_sim.run(transpile(hybCircX, backend_sim), shots=Nshots)\n",
    "        jobY = backend_sim.run(transpile(hybCircY, backend_sim), shots=Nshots)\n",
    "        jobZ = backend_sim.run(transpile(hybCircZ, backend_sim), shots=Nshots)\n",
    "    else:\n",
    "        job = backend_sim.run(transpile(hybCirc, backend_sim), shots=Nshots)\n",
    "        my_qobj = assemble(hybCirc)\n",
    "        #my_qobj = assemble(c)                                                                                                  \n",
    "        #result = simulator.run(my_qobj).result()                                                                               \n",
    "\n",
    "        #backend = BasicAer.get_backend('statevector_simulator')                                                                \n",
    "        #job = backend.run(transpile(qc, backend))                                                                              \n",
    "    #job=qiskit.execute(qc,backend,shots=500)                   \n",
    "        #job = backend.run(transpile(qc, backend))                                                                              \n",
    "        #job=qiskit.execute(qc,backend,shots=500)                                                                               \n",
    "    #my_qobj = assemble(c)                                                                                                      \n",
    "    #result = simulator.run(my_qobj).result()                                                                                   \n",
    "\n",
    "    counts = job.result().get_counts(hybCirc)\n",
    "    if refQbitAxis==\"All\":\n",
    "        countsX = job.result().get_counts(hybCircX)\n",
    "        countsY = job.result().get_counts(hybCircY)\n",
    "        countsZ = job.result().get_counts(hybCircZ)\n",
    "\n",
    "    #print(\"measureArr = \", measureArr)                                                                                         \n",
    "    #convCounts = np.copy(counts);                                                                                              \n",
    "    convCounts = {}\n",
    "    #convKVec = #np.zeros((Nshots, circDep*nqbit+1))                                                                            \n",
    "    convKVec = []\n",
    "\n",
    "    if refQbitAxis!=\"None\" and refQbitAxis!=\"All\":\n",
    "        #print(\"counts = \", counts)                                                                                             \n",
    "        #print(\"countsX = \", countsX)                                                                                           \n",
    "        #print(\"countsY = \", countsY)                                                                                           \n",
    "        #for kx,vx in countsX.items():                                                                                          \n",
    "        #    print(\"kx[::-1] = \", kx[::-1])                                                                                     \n",
    "        #    print(\"vx = \", vx)  \n",
    "        for k,v in counts.items():\n",
    "            #print(\"k[::-1] = \", k[::-1])                                                                                       \n",
    "            #print(\"v = \", v)                                                                                                   \n",
    "            # k inverse of measureVec                                                                                           \n",
    "            # tempInvK inverse of k => tempInvK aligned with measureVec                                                         \n",
    "            tempInvK = k[::-1]\n",
    "            #print(\"tempInvK = \", tempInvK)                                                                                     \n",
    "\n",
    "            tempInvKArr = list(tempInvK)\n",
    "            tempInvKConvArr = [int(i) for i in tempInvKArr]\n",
    "            #print(\"tempInvKConvArr = \", tempInvKConvArr)                                                                       \n",
    "            #print(\"Dtype = \", tempInvK.dtype)                                                                                  \n",
    "            #print(\"tempInvK[:-1] = \", tempInvK[:-1])                                                                           \n",
    "            #print(\"measureVec = \", measureVec)                                                                                 \n",
    "\n",
    "            convK = 2*np.multiply(tempInvKConvArr[:-1], measureVec) - measureVec\n",
    "            #convK = -1*np.multiply(tempInvKConvArr[:-1], measureVec) + 2*measureVec                                            \n",
    "\n",
    "            if tempInvKConvArr[-1]==0:\n",
    "                convK=np.append(convK, [0])\n",
    "                #convK=np.append(convK, [2])                                                                                    \n",
    "            elif tempInvKConvArr[-1]==1:\n",
    "                convK=np.append(convK, [1])\n",
    "            #print(\"convK = \", convK)                                                                                           \n",
    "            for repetition in range(v):\n",
    "                convKVec = np.append(convKVec, convK, axis=0)\n",
    "            #print(\"convKVec = \", convKVec)                                                                                     \n",
    "\n",
    "            #np.append(freqArr, v)                                                                                              \n",
    "\n",
    "            #convK                                                                                                              \n",
    "            #print(\"convK[::-1] = \", convK[:])                                                                                  \n",
    "\n",
    "            convKStr = ''.join(str(int(x)) for x in convK)\n",
    "            #print(\"convKStr = \", convKStr)                                                                                     \n",
    "\n",
    "            #convCounts.update({convK: v})                                                                                      \n",
    "            convCounts.update({convKStr: v})\n",
    "            #print(\"convK[::-1] = \", convK[::-1])             \n",
    "            #print(\"convKStr = \", convKStr)                                                                                     \n",
    "            #convCounts.update({convK: v})                                                                                      \n",
    "            convCounts.update({convKStr: v})\n",
    "            #print(\"convK[::-1] = \", convK[::-1])                                                                               \n",
    "            #print(\"v = \", v)                                                                                                   \n",
    "            #print(\"\\n\")\n",
    "        #print(\"convKVec = \", convKVec)                                                                                         \n",
    "        #plot_histogram(job.result().get_counts(), color='midnightblue', title=\"New Histogram\")                                 \n",
    "        #plt.show()                                                                                                             \n",
    "        #return measureArr, convKVec, counts\n",
    "        convKNon0 = [];convKVecOriginal=[];\n",
    "        return measureArr, convKVec, convKNon0, convKVecOriginal, counts\n",
    "\n",
    "    if refQbitAxis==\"None\":\n",
    "        finalState = job.result().get_statevector(hybCirc)\n",
    "        finStVec = finalState.data;\n",
    "        finStVec = finStVec.reshape(len(finStVec), 1)\n",
    "        finalDMArr = matmul(finStVec, conj(transpose(finStVec)))\n",
    "        rhoFinDM = qinfo.DensityMatrix(finalDMArr)\n",
    "\n",
    "        traceVec = np.arange(0, nqbit)\n",
    "        traceState = rhoFinDM.copy()\n",
    "        for i in range(nqbit):\n",
    "            #traceState = qinfo.partial_trace(traceState, [nqbit-i])                                                            \n",
    "            traceState = qinfo.partial_trace(traceState, [0])\n",
    "\n",
    "        rhoAncilla = np.copy(traceState);\n",
    "        #print(\"rhoAconvKVecncilla = \", rhoAncilla)             \n",
    "        \n",
    "        #print(\"rhoAconvKVecncilla = \", rhoAncilla)                                                                             \n",
    "        #print(\"purity = \", np.trace(matrix_power(rhoAncilla, renyiInd)))                                                       \n",
    "        eigRho, eigVecRho = eig(rhoAncilla)\n",
    "        #print(\"eigRho = \", eigRho)                                                                                             \n",
    "        sigmax=[[0, 1],[1, 0]]; sigmay=[[0, -1j],[1j, 0]]; sigmaz=[[1, 0],[0, -1]];\n",
    "        rx = np.trace(matmul(rhoAncilla, sigmax))\n",
    "        ry = np.trace(matmul(rhoAncilla, sigmay))\n",
    "        rz = np.trace(matmul(rhoAncilla, sigmaz))\n",
    "        rvec=[rx, ry, rz];\n",
    "        rvecNorm = np.linalg.norm(rvec)\n",
    "\n",
    "        eps = (1+1j)*1e-16;\n",
    "        #ancillaDenMat = traceMatExceptLast(rho)+eps*Matrix(I, 2, 2)                                                            \n",
    "        #println(\"ancillaDenMat = \", ancillaDenMat)                                                                             \n",
    "        eigvalsDen = [1/2-rvecNorm/2, 1/2+rvecNorm/2];\n",
    "\n",
    "        if renyiInd==1:\n",
    "            try:\n",
    "                renyiEnt = -np.real(sum([eigvalsDen[i]*np.log2((eigvalsDen[i])) for i in range(2)]))\n",
    "            except y:\n",
    "                if isa(y, DomainError):\n",
    "                    println(\"domainError\")\n",
    "                    println(\"eigvalsDen = \", eigvalsDen)\n",
    "                    println(\"ancillaDenMat = \", ancillaDenMat)\n",
    "                    \n",
    "        else:\n",
    "            renyiEnt = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncilla, renyiInd)))\n",
    "            renyiEnt = np.real(renyiEnt)\n",
    "\n",
    "        print(\"renyiEnt = \", renyiEnt)\n",
    "\n",
    "        return state, rhoAncilla, renyiEnt, measureArr                    \n",
    "    \n",
    "                    \n",
    "        \n",
    "        \n",
    "    \n",
    "\"\"\"\n",
    "def timeEvolveAncilla(nqbit, depth, p, initStateLabel, circConfig, renyiInd, refQbitAxis, Nshots, errRate=0, readoutErr=0, randseed=[]):\n",
    "    \n",
    "    #print(\"errRate = \", errRate)\n",
    "    # nqbit: number of qubits\n",
    "    # depth: circuit depth = time duration\n",
    "    # p: measurement rate\n",
    "    # initStateLabel: what kind of initial state is used. We usually use a product state\n",
    "    # with initStateLabel=\"prod\".\n",
    "    # circConfig: the random Hybrid circuit configuration which is determined by giving \n",
    "    # a random seed. \n",
    "    # renyiInd: reny entropy index\n",
    "    # refQbitAxis: the reference qubit measurement axis of its spin which could be \n",
    "    # \"X\", \"Y\", \"Z\" or \"All\" or \"None\". For learning purposes we use \"X\", \"Y\", \"Z\". \n",
    "    # Nshots: Number of circuit shots.\n",
    "    # errRate: random single-qubit Pauli noise error rate. \n",
    "    # Outputs: \n",
    "    # if refQbitAxis==\"X\", \"Y\", \"Z\" then the output is measureArr, convKVec, counts.\n",
    "    # measureArr: The [depth*nqbit] array of mid circuit measurements.\n",
    "    # convKVec: A vector of size Nshots*nqbit*depth+1\n",
    "    \n",
    "    nNodes=nqbit*depth;\n",
    "    nUnitary=int(nNodes/2);\n",
    "    measureArr=np.zeros((depth, nqbit));\n",
    "    measureVec = np.zeros(nNodes);\n",
    "\n",
    "    if circConfig==\"None\" or circConfig==0:\n",
    "        measureArr, unitaryArr = genCircConfig(nqbit, depth, p, randseed);\n",
    "    measureVec = np.zeros(depth*nqbit)\n",
    "    for t in range(depth):        \n",
    "        #measureArr[t, :]=[measureVec[i+t*nqbit] for i in range(nqbit)];\n",
    "        measureVec[t*nqbit:(t+1)*nqbit] = measureArr[t, :]\n",
    "    \n",
    "    #if circConfig==\"None\":\n",
    "    #    measureVec=[(rand(1)[0]<p)+0.0 for i in range(nNodes)];\n",
    "    #    for t in range(depth):\n",
    "    #        measureArr[t, :]=[measureVec[i+t*nqbit] for i in range(nqbit)];\n",
    "    identity = [[1, 0], [0, 1]]\n",
    "    xpauli = [[0, 1],[1, 0]]\n",
    "    ypauli = [[0, -1j],[1j, 0]]\n",
    "    zpauli = [[1, 0],[0, -1]]\n",
    "    \n",
    "    unitaryArr=np.zeros((nUnitary, 4, 4))+0j;\n",
    "    dim=4;\n",
    "    if circConfig!=\"None\":\n",
    "        measureArr=circConfig[0];\n",
    "        unitaryArr=circConfig[1];\n",
    "        for t in range(depth):\n",
    "            #print(\"measureArr = \", np.shape(measureArr))\n",
    "            #print(\"measureVec = \", np.shape(measureVec))            \n",
    "            measureVec[t*nqbit:(t+1)*nqbit] = measureArr[t, :]            \n",
    "    \n",
    "    lenNon0MeasureVec = np.shape(np.nonzero(measureVec))[1]\n",
    "    #print(\"measureArr in timeevolve after = \", measureArr)\n",
    "    #print(\"lenNon0MeasureVec = \", lenNon0MeasureVec)\n",
    "    # The ancilla qubit is put at the  of the string of the qubits. This way we tensor product the states\n",
    "    # from left to right. The ancilla qbit is entangled to the qbit at the middle of the string at Ind=floor(nqbit/2)\n",
    "    \n",
    "    n2qbit = int(floor(nqbit/2))\n",
    "    state = Statevector.from_int(0, 2**(nqbit+1))\n",
    "    \n",
    "    A=rand(2, 2)\n",
    "    unitCirc = QuantumCircuit(nqbit+1, 2)\n",
    "    midind = int(floor((nqbit-1)/2))\n",
    "    # Add a H gate on qubit 0    \n",
    "    #circuit.h(n-1)\n",
    "    #circuit.cx(n-1, midind)\n",
    "    \n",
    "    identityMat = np.identity(np.shape(A)[0])\n",
    "    \n",
    "    if initStateLabel==\"mixed\":\n",
    "        for t in range(depth):\n",
    "            if t%2==1:                \n",
    "                for ngate in range(n2qbit):\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)                    \n",
    "                    gate2x2 = unitCirc.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "                    \n",
    "            elif t%2==0:\n",
    "                for ngate in range(n2qbit-1):\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                    gate2x2 = unitCirc.unitary(Qprime, [2*ngate+1, 2*(ngate+1)])\n",
    "                    \n",
    "                #U = kron(U, identityMat)   \n",
    "    \n",
    "    state = state.evolve(unitCirc)\n",
    "\n",
    "    #state.__dir__()\n",
    "    BellGateCirc = QuantumCircuit(nqbit+1)\n",
    "    #initState = Statevector.from_int(0, 2**(nqbit+1))        \n",
    "    #q = QuantumRegister(nqbit)\n",
    "    #cbit = ClassicalRegister(nqbit)\n",
    "    #qc = QuantumCircuit(q, cbit)\n",
    "    \n",
    "    #qc.initialize(mixedState, [q[0],q[1]])\n",
    "    BellGateCirc.initialize(state)\n",
    "    \n",
    "    hGate = BellGateCirc.h(midind)   # Hadamard gate on the mid qubit. \n",
    "    cnotgate = BellGateCirc.cx(midind, nqbit)  # CNOT between the mid qubit and the last qubit. \n",
    "    state = state.evolve(BellGateCirc)\n",
    "    #print(\"state = \", state)    \n",
    "    #backend_sim = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "    # Execute the circuit on the qasm simulator.\n",
    "    # We've set the number of repeats of the circuit\n",
    "    # to be 1024, which is the default.\n",
    "    #job = backend_sim.run(transpile(qc, backend_sim), shots=1024)\n",
    "    \n",
    "    qreg  = QuantumRegister((nqbit+1)) #\n",
    "    qregX  = QuantumRegister((nqbit+1)) #\n",
    "    qregY  = QuantumRegister((nqbit+1)) #\n",
    "    qregZ  = QuantumRegister((nqbit+1)) #\n",
    "\n",
    "    #print(\"refQbitAxis = \", refQbitAxis)\n",
    "    if refQbitAxis==\"None\": # In this case we measure the state of the reference qubit at the final step.\n",
    "        cr  = ClassicalRegister((nqbit)*depth)\n",
    "        hybCirc = QuantumCircuit(qreg,cr)        \n",
    "    else:\n",
    "        cr  = ClassicalRegister((nqbit)*depth+1)\n",
    "        crX  = ClassicalRegister((nqbit)*depth+1)\n",
    "        crY  = ClassicalRegister((nqbit)*depth+1)\n",
    "        crZ  = ClassicalRegister((nqbit)*depth+1)\n",
    "        \n",
    "        hybCirc = QuantumCircuit(qreg,cr)\n",
    "        hybCircX = QuantumCircuit(qregX,crX)\n",
    "        hybCircY = QuantumCircuit(qregY,crY)\n",
    "        hybCircZ = QuantumCircuit(qregZ,crZ)   \n",
    "    #print(\"hybCirc = \", hybCirc)    \n",
    "    \n",
    "    hybCirc.initialize(state)\n",
    "    if refQbitAxis==\"All\":\n",
    "        hybCircX.initialize(state)\n",
    "        hybCircY.initialize(state)    \n",
    "        hybCircZ.initialize(state)    \n",
    "    Qprime=np.zeros((dim, dim))+0.0j\n",
    "    errArr = np.zeros((depth, 4*nqbit))\n",
    "    random.seed(); \n",
    "    \n",
    "    #print(\"readoutErr = \", readoutErr)       \n",
    "    mu, sigma = 0, errRate # mean and standard deviation        \n",
    "    for t in range(depth):\n",
    "        #if randseed!=[]:\n",
    "        #    print(\"randseed = \", randseed)\n",
    "            #np.random.seed(int(floor(randseed)));\n",
    "        \n",
    "        ### Measurement\n",
    "        #cntMeasure = np.count_nonzero(measureArr)\n",
    "        #qreg  = QuantumRegister(nqbit+1)\n",
    "        #cr  = ClassicalRegister(nqbit+1)\n",
    "        \n",
    "        if errRate!=0:\n",
    "            #errVec = np.random.uniform(0,errRate,(4*nqbit))            \n",
    "            errVec = np.random.normal(mu, sigma, (4*nqbit))\n",
    "            #print(\"errVec = \", errVec)\n",
    "            errArr[t, :] = errVec[:]            \n",
    "            \n",
    "            for nq in range(nqbit):\n",
    "                randomExpIn = expm(np.dot(-1j*errVec[4*(nq-1)], identity))\n",
    "                randomExpXn = expm(np.dot(-1j*errVec[4*(nq-1)+1], xpauli))\n",
    "                randomExpYn = expm(np.dot(-1j*errVec[4*(nq-1)+2], ypauli))\n",
    "                randomExpZn = expm(np.dot(-1j*errVec[4*(nq-1)+3], zpauli))                    \n",
    "                \n",
    "                gate1x1=hybCirc.unitary(randomExpIn, [nq])\n",
    "                gate1x1=hybCirc.unitary(randomExpXn, [nq])\n",
    "                gate1x1=hybCirc.unitary(randomExpYn, [nq])                \n",
    "                gate1x1=hybCirc.unitary(randomExpZn, [nq])\n",
    "                                \n",
    "                if refQbitAxis==\"All\":                \n",
    "                    gate1x1=hybCircX.unitary(randomExpIn, [nq])                    \n",
    "                    gate1x1=hybCircX.unitary(randomExpXn, [nq])\n",
    "                    gate1x1=hybCircX.unitary(randomExpYn, [nq])\n",
    "                    gate1x1=hybCircX.unitary(randomExpZn, [nq])                \n",
    "\n",
    "                    gate1x1=hybCircY.unitary(randomExpIn, [nq])                                        \n",
    "                    gate1x1=hybCircY.unitary(randomExpXn, [nq])\n",
    "                    gate1x1=hybCircY.unitary(randomExpYn, [nq])                \n",
    "                    gate1x1=hybCircY.unitary(randomExpZn, [nq])                \n",
    "\n",
    "                    gate1x1=hybCircZ.unitary(randomExpIn, [nq])                                        \n",
    "                    gate1x1=hybCircZ.unitary(randomExpXn, [nq])\n",
    "                    gate1x1=hybCircZ.unitary(randomExpYn, [nq])                \n",
    "                    gate1x1=hybCircZ.unitary(randomExpZn, [nq])                                    \n",
    "                    #gate2x2=hybCirc.unitary(Qprime, [2*ngate, 2*ngate+1])                \n",
    "                            \n",
    "        if t%2==0:              \n",
    "            for ngate in range(n2qbit):\n",
    "                if circConfig==\"None\":                \n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                else:\n",
    "                    #unitInd=ngate+int(t/2)*nqbit\n",
    "                    unitInd=ngate+t*n2qbit\n",
    "                    Qprime=np.copy(unitaryArr[unitInd, :, :])\n",
    "                    #print(\"Qprime = \", Qprime)\n",
    "                #print(\"unitInd = \", unitInd)\n",
    "                gate2x2=hybCirc.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "                if refQbitAxis==\"All\":                \n",
    "                    gate2x2X=hybCircX.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "                    gate2x2Y=hybCircY.unitary(Qprime, [2*ngate, 2*ngate+1])\n",
    "                    gate2x2Z=hybCircZ.unitary(Qprime, [2*ngate, 2*ngate+1])                \n",
    "        elif t%2==1:            \n",
    "            for ngate in range(1, n2qbit+1):    \n",
    "                if circConfig==\"None\":\n",
    "                    Qprime, A, qprimEig = HaarGen(dim)\n",
    "                else:\n",
    "                    unitInd=ngate-1+t*n2qbit\n",
    "                #print(\"unitInd = \", unitInd)    \n",
    "                if ngate!=n2qbit:                    \n",
    "                    gate2x2 = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])\n",
    "                    if refQbitAxis==\"All\":                                    \n",
    "                        gate2x2X = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])                    \n",
    "                        gate2x2Y = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])                    \n",
    "                        gate2x2Z = hybCirc.unitary(Qprime, [2*ngate-1, 2*ngate])                                        \n",
    "                else: \n",
    "                    gate2x2 = hybCirc.unitary(Qprime, [2*ngate-1, 0])                    \n",
    "                    if refQbitAxis==\"All\":                                    \n",
    "                        gate2x2X = hybCirc.unitary(Qprime, [2*ngate-1, 0])                    \n",
    "                        gate2x2Y = hybCirc.unitary(Qprime, [2*ngate-1, 0])                    \n",
    "                        gate2x2Z = hybCirc.unitary(Qprime, [2*ngate-1, 0])                                                                                \n",
    "        for m in range(nqbit):\n",
    "            if measureArr[t, m]:\n",
    "                hybCirc.measure(qreg[m], cr[m+nqbit*t])                \n",
    "                if refQbitAxis==\"All\":                                                    \n",
    "                    hybCircX.measure(qregX[m], crX[m+nqbit*t])\n",
    "                    hybCircY.measure(qregY[m], crY[m+nqbit*t])\n",
    "                    hybCircZ.measure(qregZ[m], crZ[m+nqbit*t])\n",
    "    #print(\"after circuit generation\")\n",
    "    #print(\"errArr = \", errArr)                \n",
    "    if refQbitAxis==\"Z\":\n",
    "        hybCirc.measure(qreg[nqbit], cr[(nqbit)*depth])\n",
    "    elif refQbitAxis==\"X\":\n",
    "        hybCirc.h(nqbit)\n",
    "        hybCirc.measure(qreg[nqbit], cr[(nqbit)*depth])\n",
    "    elif refQbitAxis==\"Y\":\n",
    "        hybCirc.u(np.pi/2, 2*np.pi, 3*np.pi/2, nqbit);\n",
    "        #hybCirc.u(np.pi/2, np.pi/2, np.pi, nqbit);\n",
    "        hybCirc.measure(qreg[nqbit], cr[(nqbit)*depth])\n",
    "    elif refQbitAxis==\"All\":\n",
    "        hybCircZ.measure(qregZ[nqbit], crZ[(nqbit)*depth])                \n",
    "        #hybCircX.u(np.pi/2, np.pi/2, np.pi, nqbit);\n",
    "        hybCircX.h(nqbit)\n",
    "        hybCircX.measure(qregX[nqbit], crX[(nqbit)*depth])        \n",
    "        hybCircY.u(np.pi/2, 2*np.pi, 3*np.pi/2, nqbit);\n",
    "        hybCircY.measure(qregY[nqbit], crY[(nqbit)*depth])\n",
    "    \n",
    "    hybCirc.draw()   \n",
    "    #hybCircX.show()\n",
    "    #print(hybCirc)\n",
    "    \n",
    "    #backend_sim = Aer.get_backend(simulator)\n",
    "    \n",
    "    #backend_sim = Aer.get_backend('statevector_simulator')\n",
    "    \n",
    "        # Execute the circuit on the qasm simulator.\n",
    "        # We've set the number of repeats of the circuit\n",
    "        # to be 1024, which is the default.\n",
    "    backend_sim = Aer.get_backend('statevector_simulator')\n",
    "    if refQbitAxis==\"None\":        \n",
    "        job = backend_sim.run(transpile(hybCirc, backend_sim), shots=1)\n",
    "        #print(\"refQbitAxis==None\")\n",
    "    elif refQbitAxis==\"All\":        \n",
    "        jobX = backend_sim.run(transpile(hybCircX, backend_sim), shots=Nshots)\n",
    "        jobY = backend_sim.run(transpile(hybCircY, backend_sim), shots=Nshots)\n",
    "        jobZ = backend_sim.run(transpile(hybCircZ, backend_sim), shots=Nshots)                \n",
    "        countsX = jobX.result().get_counts(hybCircX)\n",
    "        countsY = jobY.result().get_counts(hybCircY)\n",
    "        countsZ = jobZ.result().get_counts(hybCircZ)\n",
    "        \n",
    "    else:\n",
    "        #backend_sim = Aer.get_backend('aer_simulator')\n",
    "        job = backend_sim.run(transpile(hybCirc, backend_sim), shots=Nshots)        \n",
    "        \n",
    "        my_qobj = assemble(hybCirc)\n",
    "        \n",
    "        #my_qobj = assemble(c)\n",
    "        #result = simulator.run(my_qobj).result()\n",
    "        \n",
    "        #backend = BasicAer.get_backend('statevector_simulator')\n",
    "        #job = backend.run(transpile(qc, backend))\n",
    "        #job=qiskit.execute(qc,backend,shots=500)\n",
    "    #my_qobj = assemble(c)\n",
    "    #result = simulator.run(my_qobj).result()\n",
    "    #print(\"after simulation\")\n",
    "    #counts = job.result().get_counts(hybCirc)\n",
    "    #if refQbitAxis==\"All\":            \n",
    "    #    countsX = jobX.result().get_counts(hybCircX)\n",
    "    #    countsY = jobY.result().get_counts(hybCircY)\n",
    "    #    countsZ = jobZ.result().get_counts(hybCircZ)\n",
    "    #print(\"backend_sim = \", backend_sim)\n",
    "    #convCounts = np.copy(counts);\n",
    "    \n",
    "    counts = job.result().get_counts(hybCirc)\n",
    "    \n",
    "    convCounts = {};\n",
    "    #convKVec = #np.zeros((Nshots, depth*nqbit+1))\n",
    "    convKVec = [];\n",
    "    #convKArr = np.zeros((1, (nqbit)*depth+1));\n",
    "    \n",
    "    convKNon0 = np.zeros((1, lenNon0MeasureVec+1)) # size is lenNon0MeasureVec plus 1 to include the ancilla qubit\n",
    "    if refQbitAxis!=\"None\" and refQbitAxis!=\"All\":\n",
    "        #for kx,vx in countsX.items():\n",
    "        #    print(\"kx[::-1] = \", kx[::-1])\n",
    "        #    print(\"vx = \", vx)\n",
    "\n",
    "        #for ky,vy in countsY.items():\n",
    "        #    print(\"ky[::-1] = \", ky[::-1])\n",
    "        #    print(\"vy = \", vy)\n",
    "\n",
    "        countsCnt = 0\n",
    "        for k,v in counts.items():            \n",
    "            #print(\"k[::-1] = \", k[::-1])\n",
    "            #print(\"v = \", v)\n",
    "            \n",
    "            # k inverse of measureVec\n",
    "            # tempInvK inverse of k => tempInvK aligned with measureVec\n",
    "            tempInvK = k[::-1]\n",
    "            #if countsCnt<10:\n",
    "            #    print(\"tempInvK = \", tempInvK, \", v = \", v)\n",
    "            \n",
    "            tempInvKArr = list(tempInvK)\n",
    "            tempInvKConvArr = [int(i) for i in tempInvKArr]\n",
    "            #print(\"tempInvKConvArr = \", tempInvKConvArr)\n",
    "            #print(\"Dtype = \", tempInvK.dtype)\n",
    "            #print(\"tempInvK[:-1] = \", tempInvK[:-1])\n",
    "            \n",
    "            convK = 2*np.multiply(tempInvKConvArr[:-1], measureVec) - measureVec\n",
    "            #convK = -1*np.multiply(tempInvKConvArr[:-1], measureVec) + 2*measureVec\n",
    "            #print(\"tempInvKConvArr[:-1] = \", tempInvKConvArr[:-1])\n",
    "            #print(\"measureVec = \", measureVec)\n",
    "            #print(\"convK = \", convK)\n",
    "            #Here we remove the zero elements from convK:\n",
    "            tempConvKNon0 = convK[convK!=0]\n",
    "            \n",
    "            #print(\"tempConvKNon0 = \", tempConvKNon0)\n",
    "            #print(\"np.shape(convKNon0) = \", np.shape(convKNon0))\n",
    "            \n",
    "            if tempInvKConvArr[-1]==0:\n",
    "                convK=np.append(convK, [0]);\n",
    "                tempConvKNon0=np.append(tempConvKNon0, [0]);\n",
    "            elif tempInvKConvArr[-1]==1:\n",
    "                convK=np.append(convK, [1]);\n",
    "                tempConvKNon0=np.append(tempConvKNon0, [1]);        \n",
    "                \n",
    "            for repetition in range(v):\n",
    "                convKVec = np.append(convKVec, convK, axis=0);\n",
    "                convKNon0 = np.append(convKNon0, [tempConvKNon0], axis=0);\n",
    "                #convKArr = np.append(convKArr, [convK], axis=0);\n",
    "            \n",
    "            convKStr = ''.join(str(int(x)) for x in convK);\n",
    "            \n",
    "            convCounts.update({convKStr: v});\n",
    "            countsCnt+=1;\n",
    "        \n",
    "        convKVecAncilla = [convKVec[int(nqbit*depth*i)] for i in range(1, Nshots)]            \n",
    "        readerrArr = np.random.uniform(0, 1, len(convKVec))\n",
    "        #print(\"readerrArr = \", readerrArr)\n",
    "        ref = readoutErr*np.ones(len(convKVec))\n",
    "        flip = (readerrArr < ref)+0\n",
    "        #print(\"flip = \", flip)\n",
    "        #convKVecAncilla = [convKVec[int(nqbit*depth+1)*i-1] for i in range(1, Nshots)]\n",
    "        convKVecOriginal = np.copy(convKVec)\n",
    "        for i in range(len(flip)):\n",
    "            if i%(nqbit*depth+1)!=nqbit*depth:\n",
    "                #print(\"convKVec[i] = {}, (-1)**flip[i] = {}\".format(convKVec[i], int((-1)**flip[i]*convKVec[i])))\n",
    "                convKVec[i] = int((-1)**flip[i]*convKVec[i])                \n",
    "            else:                \n",
    "                if flip[i]:\n",
    "                    convKVec[i] = int(not(convKVec[i]))            \n",
    "        convKVecAncilla = [convKVec[int(nqbit*depth+1)*i-1] for i in range(1, Nshots)]\n",
    "        #print(\"convKVec = \", convKVec[:10])\n",
    "        #print(\"convKVecOriginal = \", convKVecOriginal[:10])\n",
    "        convKNon0 = np.delete(convKNon0, 0, 0)  \n",
    "        #print(\"convKArr = \", convKArr)\n",
    "        #print(\"shape convKNon0 = \", np.shape(convKNon0))        \n",
    "        return measureArr, convKVec, convKNon0, convKVecOriginal, counts\n",
    "    \n",
    "    if refQbitAxis==\"None\":\n",
    "        finalState = job.result().get_statevector(hybCirc);\n",
    "        finStVec = np.array(finalState.data);\n",
    "        \n",
    "        finStVec = finStVec.reshape(len(finStVec), 1);\n",
    "        finalDMArr = matmul(finStVec, conj(np.transpose(finStVec)));\n",
    "        rhoFinDM = qinfo.DensityMatrix(finalDMArr);\n",
    "        \n",
    "        traceVec = np.arange(0, nqbit);\n",
    "        traceState = rhoFinDM.copy();\n",
    "        for i in range(nqbit):\n",
    "            #traceState = qinfo.partial_trace(traceState, [nqbit-i])\n",
    "            traceState = qinfo.partial_trace(traceState, [0]);\n",
    "        \n",
    "        rhoAncilla = np.copy(traceState);        \n",
    "        #print(\"purity = \", np.trace(matrix_power(rhoAncilla, renyiInd)))\n",
    "        eigRho, eigVecRho = eig(rhoAncilla);\n",
    "        #print(\"eigRho = \", eigRho)\n",
    "        sigmax=[[0, 1],[1, 0]]; sigmay=[[0, -1j],[1j, 0]]; sigmaz=[[1, 0],[0, -1]]; \n",
    "        rx = np.trace(matmul(rhoAncilla, sigmax));\n",
    "        ry = np.trace(matmul(rhoAncilla, sigmay));\n",
    "        rz = np.trace(matmul(rhoAncilla, sigmaz));        \n",
    "        rhoAncillaZ = [[1/2*(1+rz), 0], [0, 1/2*(1-rz)]]\n",
    "        \n",
    "        rvec=[rx, ry, rz];        \n",
    "        rvecNorm = np.linalg.norm(rvec);\n",
    "        rvecNormZ = np.linalg.norm(rz);\n",
    "        \n",
    "        eps = (1+1j)*1e-16;\n",
    "        #ancillaDenMat = traceMatExceptLast(rho)+eps*Matrix(I, 2, 2)\n",
    "        #println(\"ancillaDenMat = \", ancillaDenMat)\n",
    "        eigvalsDen = [1/2-rvecNorm/2, 1/2+rvecNorm/2];        \n",
    "        eigvalsDenZ = [1/2-rvecNormZ/2, 1/2+rvecNormZ/2];        \n",
    "        \n",
    "        if renyiInd==1:\n",
    "            try:\n",
    "                renyiEnt = -np.real(sum([eigvalsDen[i]*np.log2((eigvalsDen[i])) for i in range(2)]))                \n",
    "                renyiEntZ = -np.real(sum([eigvalsDenZ[i]*np.log2((eigvalsDenZ[i])) for i in range(2)]))                \n",
    "            except y:\n",
    "                if isa(y, DomainError):\n",
    "                    println(\"domainError\")\n",
    "                    println(\"eigvalsDen = \", eigvalsDen)\n",
    "                    println(\"ancillaDenMat = \", ancillaDenMat)                    \n",
    "        else:\n",
    "            renyiEnt = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncilla, renyiInd)))\n",
    "            renyiEnt = np.real(renyiEnt)\n",
    "\n",
    "            renyiEntZ = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncillaZ, renyiInd)))\n",
    "            renyiEntZ = np.real(renyiEntZ)\n",
    "            \n",
    "        #print(\"renyiEnt = \", renyiEnt)\n",
    "        if renyiEnt==1:\n",
    "            renyiEnt=1-1e-8;\n",
    "        if renyiEntZ==1:\n",
    "            renyiEntZ=1-1e-8;            \n",
    "        return state, rhoAncilla, renyiEnt, measureArr, renyiEntZ\n",
    "#\"\"\";#\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "pvec = np.arange(0.1, .4, .1);pvec=[np.round(p, 4) for p in pvec]\n",
    "errvec = np.arange(0.0, 1, .2);errvec=[np.round(e, 4) for e in errvec]\n",
    "nqvec = np.arange(4, 5, 2);\n",
    "tvec = np.arange(0, 2);\n",
    "nsamples = 20; eefuncerr = np.zeros((len(errvec), len(tvec)))\n",
    "\n",
    "nq=4;renyiInd=2;refQbitAxis=\"X\";Nshots=1;p =0.3\n",
    "eefuncerr = np.zeros((nsamples, len(errvec), len(tvec)))\n",
    "eefuncp = np.zeros((nsamples, len(pvec), len(tvec)))\n",
    "for tnum, t in enumerate(tvec):\n",
    "    for enum, e in enumerate(errvec):\n",
    "        #print(e, \" \", enum)\n",
    "        for n in range(nsamples):\n",
    "            if n>0 and n%500==0:\n",
    "                print(n)\n",
    "            #_, _, tempee, m, _ \n",
    "            #measureArr, convKVecX, eefuncerr[n, enum, tnum], _, _ = timeEvolveAncilla(nq, t, p, \"prod\", \"None\", \\\n",
    "            #                                       renyiInd, \"None\", Nshots, errRate=0, readoutErr=e);\n",
    "            #measureArr, convKVecX, convKVecNon0X, _, _ = timeEvolveAncilla(nq, t, p, \"prod\", \"None\", \\\n",
    "            #                                       renyiInd, \"X\", Nshots, errRate=0, readoutErr=e);\n",
    "            \n",
    "            #nqbit, depth, p, initStateLabel, circConfig, renyiInd, refQbitAxis, Nshots, errRate=0, readoutErr=0, \n",
    "            #          randseed=[]            \n",
    "            #print(\"measureArr = \", measureArr)\n",
    "            #nqbit, depth, p, initStateLabel, circConfig, renyiInd, refQbitAxis, Nshots, randseed=[], \\\n",
    "            #                      errRate=0, readoutErr=0\n",
    "            \n",
    "            #print(\"tempee = \", tempee)\n",
    "            #eefuncerr[n, enum, tnum] = ee[enum, tnum] + tempee/nsamples\n",
    "#df = pd.DataFrame(convKVecX);\n",
    "\n",
    "#print(\"ee = \", measureArr)\n",
    "\n",
    "#with open(\"MeasureResX{}.csv\".format(nq), 'w') as f:\n",
    "#        csv.writer(f, delimiter=' ').writerows([convKVecX])\n",
    "\n",
    "#for enum, e in enumerate(errvec):\n",
    "    #print(\"eefuncerr[pnum, :] = \", eefuncerr[pnum, :])\n",
    "#    matplotlib.pyplot.errorbar(tvec, np.mean(eefuncerr[:, enum, :], axis=0), \\\n",
    "#                               np.std(eefuncerr[:, enum, :]/np.sqrt(nsamples), axis=0), label=e);\n",
    "    #matplotlib.pyplot.errorbar(x, y, yerr=None, xerr=None,\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "#\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrajArgsv2(argv):\n",
    "#python HaarRandomPyHPC.py 4 6 0.1 1 1 5 0 5000 0 1 10\n",
    "#genTrajLearnPred(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, seed, \\\n",
    "#                     lightCone=0, deltaLDim=0, ifsave=0, nnt1=[], NTest=[]):\n",
    "    print(\"GeneratingData\")    \n",
    "    print('Argument List:', str(argv))\n",
    "    opts, args = getopt.getopt(argv, \"hi:o:\")\n",
    "\n",
    "    nq = int(args[0]); d = int(args[1]); p = float(args[2]);\n",
    "    evolveT = int(args[3]); \n",
    "    learnT = np.arange(1, evolveT)\n",
    "    circ = int(args[4]);\n",
    "    if circ==0:\n",
    "        circ = \"None\";        \n",
    "    nshots=int(args[5]);    \n",
    "    eeVec = np.zeros(len(learnT));\n",
    "    randseed = float(args[6]); errRate = float(args[7]); \n",
    "    readoutErr = float(args[8]);\n",
    "    #gate = float(args[9]);\n",
    "    \n",
    "    print(\"{}, {}, {}, {}, {}, {}, {}, {} = \".format(nq, d, p, evolveT, nshots, \\\n",
    "                                                     randseed, errRate, readoutErr))\n",
    "    if circ==\"None\":\n",
    "        if randseed==0:\n",
    "            randseed = random.random();\n",
    "            randseed = round(randseed, 5);\n",
    "            print(\"generated randseed in args = \", randseed);\n",
    "        circ = genCircConfig(nq, d, p, randseed, ifsave);\n",
    "    print(\"randseed = \", randseed)\n",
    "    print(\"circ = \", circ)    \n",
    "    lightCone=0; deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    svec=[0, 0, 0];\n",
    "    exactEE = np.zeros(len(learnT));\n",
    "    exactEEZ = np.zeros(len(learnT));\n",
    "    \n",
    "    EERes = np.zeros((1, len(learnT)));       \n",
    "    EEZRes = np.zeros((1, len(learnT)));      \n",
    "    eeVec = np.zeros((trajNum, len(learnT))); \n",
    "    eeZVec = np.zeros((trajNum, len(learnT)));\n",
    "    \n",
    "    #for trj in range(trajNum):   \n",
    "    if True:\n",
    "        print(\"True\")\n",
    "        for t in range(len(learnT)):\n",
    "\n",
    "            timel = learnT[t];            \n",
    "            print(\"timel = \", timel)            \n",
    "            convKX = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKY = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKZ = np.zeros((nshots, learnT[t]*nq+1))\n",
    "\n",
    "            convKOriginalX = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKOriginalY = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKOriginalZ = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            \n",
    "            convKVecX = []\n",
    "            convKVecY = []\n",
    "            convKVecZ = []\n",
    "            print(\"before 1st time evolution\")\n",
    "            #state, rhoAncilla, exactEE[t], measureArr, exactEEZ[t] = timeEvolveAncilla(nq, timel, p, \\\n",
    "            #                                                        \"prod\", circ, 2, \"None\", nshots, errRate, readoutErr, seed);          \n",
    "            print(\"after 1st time evolution\")\n",
    "            print(\"errRate = \", errRate)\n",
    "            if errRate!=0:\n",
    "                print(\"errRate not zero!\")\n",
    "                for noisyshot in range(nshots):\n",
    "                    if noisyshot%10==0:\n",
    "                        print(\"shot = \", noisyshot)\n",
    "                    nshot=1;        \n",
    "                    #measureArr, convKVecX, convKVecNon0X, _, _ = timeEvolveAncilla(nq, t, p, \"prod\", \"None\", \\\n",
    "                    #                               renyiInd, \"X\", Nshots, errRate=0, readoutErr=e);\n",
    "                    print(\"{}, {}, {} = \".format(nq, timel, p))\n",
    "                    print(\"before measureArr\")\n",
    "                    A = timeEvolveAncilla(nq, timel, p, \"prod\", \\\n",
    "                                                                    \"None\", 2, \"None\", 1, 0, 0);                                        \n",
    "                    measureArr, convKVecX, eefuncerr[n, enum, tnum], _, _ = timeEvolveAncilla(nq, t, p, \"prod\", \"None\", \\\n",
    "                                                   renyiInd, refQbitAxis, Nshots, errRate=0, readoutErr=e);\n",
    "                    \n",
    "                    print(\"tempConvKOriginalX = \", tempConvKOriginalX)\n",
    "                    marrY, tempconvKY, _, tempConvKOriginalY, _ = timeEvolveAncilla(nq, timel, p, \"prod\", \\\n",
    "                                                                circ, 2, \"Y\", nshot, errRate, readoutErr, randseed);\n",
    "                    marrZ, tempconvKZ, _, tempConvKOriginalZ, _ = timeEvolveAncilla(nq, timel, p, \"prod\", \\\n",
    "                                                                circ, 2, \"Z\", nshot, errRate, readoutErr, randseed);\n",
    "                    convKX=np.append(convKX, [tempconvKX], axis=0)\n",
    "                    convKY=np.append(convKY, [tempconvKY], axis=0)\n",
    "                    convKZ=np.append(convKZ, [tempconvKZ], axis=0)\n",
    "\n",
    "                    convKOriginalX=np.append(convKX, [tempConvKOriginalX], axis=0)\n",
    "                    convKOriginalY=np.append(convKY, [tempConvKOriginalY], axis=0)\n",
    "                    convKOriginalZ=np.append(convKZ, [tempConvKOriginalZ], axis=0)\n",
    "\n",
    "                    convKVecX=np.append(convKVecX, tempconvKX, axis=0)\n",
    "                    convKVecY=np.append(convKVecY, tempconvKY, axis=0)\n",
    "                    convKVecZ=np.append(convKVecZ, tempconvKZ, axis=0)\n",
    "                    \n",
    "            elif errRate==0 and readoutErr==0:\n",
    "                print(\"evolving X\")\n",
    "                marrX, convKVecX, convKXNon0, _, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"X\", nshots, errRate, readoutErr, randseed);\n",
    "                print(\"evolving Y\")            \n",
    "                marrY, convKVecY, convKYNon0, _, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Y\", nshots, errRate, readoutErr, randseed);\n",
    "                print(\"evolving Z\")                        \n",
    "                marrZ, convKVecZ, convKZNon0, _, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Z\", nshots, errRate, readoutErr, randseed);\n",
    "                            \n",
    "    print(\"exact EE = \", np.real(exactEE));\n",
    "                    \n",
    "    exactEE = [\"{:.8e}\".format(exactEE[i]) for i in range(len(exactEE))]\n",
    "    exactEEZ = [\"{:.8e}\".format(exactEEZ[i]) for i in range(len(exactEEZ))]    \n",
    "    \n",
    "    print(\"exact EE = \", np.real(exactEE))\n",
    "    \n",
    "    EERes[0, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    \n",
    "    #df = pd.DataFrame(convKVecX);\n",
    "    print(convKVecX[:10])\n",
    "    with open(\"MeasureResX-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}-seed{}.csv\".format(nq, p, evolveT, nshots, errRate, readoutErr, randseed), 'w') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows([convKVecX])\n",
    "    #df = pd.DataFrame(convKVecY);\n",
    "    with open(\"MeasureResY-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}-seed{}.csv\".format(nq, \\\n",
    "        p, evolveT, nshots, errRate, readoutErr, randseed), 'w') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows([convKVecY])\n",
    "    #df = pd.DataFrame(convKVecZ);                    \n",
    "    with open(\"MeasureResZ-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}-seed{}.csv\".format(nq, \\\n",
    "        p, evolveT, nshots, errRate, readoutErr, randseed), 'w') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows([convKVecZ])\n",
    "                \n",
    "    with open(\"HaarAveEE-nq{}-p{}-ti{}-nshots{}-errRate{}-seed{}.csv\".format(nq, \\\n",
    "        p, evolveT, nshots, errRate, randseed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)   \n",
    "\n",
    "    #df = pd.DataFrame(EEZRes);\n",
    "    #with open(\"HaarEEZRes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "    #    csv.writer(f, delimiter=' ').writerows(EEZRes)\n",
    "\n",
    "    return circ, svec, eeVec, eeZVec\n",
    "\n",
    "#eefuncerrUnitaryErr # = eefuncerr\n",
    "#print(eefuncerrUnitaryErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for enum, e in enumerate(errvec):\n",
    "    #print(\"eefuncerr[pnum, :] = \", eefuncerr[pnum, :])\n",
    "    matplotlib.pyplot.errorbar(tvec, np.mean(eefuncerr[:, enum, :], axis=0), \\\n",
    "                               np.std(eefuncerr[:, enum, :]/np.sqrt(nsamples), axis=0), label=\"error = {}\".format(e));\n",
    "    #matplotlib.pyplot.errorbar(x, y, yerr=None, xerr=None,\n",
    "plt.legend()\n",
    "plt.ylabel(r'$S_Q(t)$', fontsize= 16)\n",
    "plt.xlabel(r'$t$', fontsize= 16)\n",
    "#plt.savefig('EntangleFuncTimeDiffError.png', dpi=300)\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "plt.show()\n",
    "errVec = (np.random.normal(0, 2, (4*2)))\n",
    "print(errVec)\n",
    "\"\"\";\n",
    "\n",
    "def res_identity(x, filters): \n",
    "    #renet block where dimension doesnot change.\n",
    "    #The skip connection is just simple identity conncection\n",
    "    #we will have 3 blocks and then input will be added\n",
    "\n",
    "    x_skip = x # this will be used for addition with the residual block \n",
    "    f1, f2 = filters\n",
    "\n",
    "    #first block \n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_regularizer=regularizers.L2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    #x = Conv2D(f1, kernel_size=(4, 4), strides=(1, 1), padding='same', kernel_regularizer=regularizers.L2(0.001))(x)\n",
    "    x = Conv2D(f1, kernel_size=(4, 4), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_regularizer=regularizers.L2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation(activations.relu)(x)\n",
    "\n",
    "    # add the input \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def res_conv(x, s, filters):\n",
    "    '''\n",
    "    here the input size changes''' \n",
    "    \n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='same', kernel_regularizer=regularizers.L2(0.001))(x)\n",
    "      # when s = 2 then it is like downsizing the feature map\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(4, 4), strides=(1, 1), padding='same', kernel_regularizer=regularizers.L2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_regularizer=regularizers.L2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # shortcut \n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='same', kernel_regularizer=regularizers.L2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add \n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def Resnet50(NSamples, nqbit, depth):\n",
    "    channel=1;\n",
    "    nnn = 512*(1 + 2*int(NSamples//1000))    \n",
    "    \n",
    "    input_shape = [depth, nqbit, channel]\n",
    "    #        tf.keras.layers.Flatten(input_shape=(realT, LDimOfArrays, 1)),\n",
    "    #        tf.keras.layers.Dense(int(LDimOfArrays/2), activation='relu'),\n",
    "    \n",
    "    input = Input(shape=(input_shape[0], input_shape[1], input_shape[2]))\n",
    "    \n",
    "    #input_im = Input(shape=(train_im.shape[1], train_im.shape[2], train_im.shape[3])) # cifar 10 images size\n",
    "    #input_im = Input(shape=(train_im.shape[1], train_im.shape[2])) # cifar 10 images size\n",
    "    #x = ZeroPadding2D(padding=(3, 3))(input)\n",
    "\n",
    "  # 1st stage\n",
    "  # here we perform maxpooling, see the figure above\n",
    "\n",
    "    out = Conv2D(int(nqbit/2), kernel_size=(4, 4), strides=(1, 1), padding = 'same')(input)\n",
    "    #print(out.shape.dims)\n",
    "    out = BatchNormalization()(out)\n",
    "    #print(out.shape.dims)    \n",
    "    out = Activation(activations.relu)(out)\n",
    "    out = MaxPooling2D((1, 2), strides=(1, 1))(out)\n",
    "    \n",
    "  #2nd stage\n",
    "  # from here on only conv block and identity block, no pooling\n",
    "    \n",
    "    out = res_conv(out, s=1, filters=(32, 64))\n",
    "    out = res_identity(out, filters=(32, 64))\n",
    "    out = res_identity(out, filters=(32, 64))\n",
    "    \n",
    "    #out = res_identity(out, filters=(64, 256))\n",
    "    \n",
    "  # 3rd stage\n",
    "    \"\"\"\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "  # 4th stage\n",
    "    \n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    \n",
    "  # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    b1_drop = Dropout(0.2)(b1_add)\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    b1_flat = Flatten()(b1_drop)\n",
    "    b1_dense1 = Dense(nnn, activation='relu')(b1_flat)\n",
    "    \n",
    "    b1_drop2 = Dropout(0.2)(b1_dense1)\n",
    "    #b1_avg = GlobalAveragePooling2D()(b1_drop2)\n",
    "    \n",
    "    \n",
    "    output = Dense(1, name='model_output', activation='sigmoid')(b1_drop2)\n",
    "    \n",
    "    #output = Dense(output_shape, name='model_output', activation='softmax',\n",
    "    #           kernel_initializer='he_uniform')(b4_avg_p)\n",
    "\n",
    "    model = Model(input, output)    \n",
    "    \"\"\"\n",
    "    \n",
    "    # ends with average pooling and dense connection\n",
    "    #\n",
    "    #out = AveragePooling2D((2, 2), padding='same')(out)\n",
    "    out = MaxPooling2D((2, 2), padding='same')(out)\n",
    "    out = Dropout(0.2)(out)    \n",
    "    out = Dense(nnn, activation='relu')(out)    \n",
    "    out = Dropout(0.2)(out)    \n",
    "    out = Flatten()(out)\n",
    "    class_types=1\n",
    "    #x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
    "    out = Dense(class_types, activation='sigmoid', kernel_initializer='he_normal')(out) #multi-class\n",
    "    \n",
    "    # define the model\n",
    "    \n",
    "    model = Model(inputs=input, outputs=out, name='Resnet50')\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def MLP(NSamples, L, depth, nonZero=0, NnonZero=0):\n",
    "    \n",
    "    channel=1;\n",
    "    nnn = 512*(1 + 2*int(NSamples//1000))        \n",
    "    if not nonZero:\n",
    "        nmeasure = L*depth\n",
    "        input_shape = [depth, L, channel]\n",
    "        input = Input(shape=(input_shape[0], input_shape[1], input_shape[2]))\n",
    "        input = Input(shape=(input_shape[0], int(input_shape[1]), input_shape[2]))    \n",
    "        out = Flatten(input_shape=(depth, L, 1))(input)        \n",
    "    else:\n",
    "        nmeasure = NnonZero        \n",
    "        input_shape = [NnonZero]\n",
    "        input = Input(shape=(input_shape[0]))\n",
    "        out = input\n",
    "        \n",
    "    out = BatchNormalization()(out)                \n",
    "    out = Dense(int(16*nmeasure), activation='gelu', kernel_regularizer=regularizers.L2(0.001))(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    outskip1 = out\n",
    "    out = BatchNormalization()(out)            \n",
    "    out = Dense(int(16*nmeasure), activation='gelu', kernel_regularizer=regularizers.L2(0.001))(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Add()([out, outskip1])\n",
    "    outskip2 = out\n",
    "    out = BatchNormalization()(out)                \n",
    "    out = Dense(int(16*nmeasure), activation='gelu', kernel_regularizer=regularizers.L2(0.001))(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Add()([out, outskip2])\n",
    "    out = BatchNormalization()(out)                \n",
    "    out = Dense(1, activation='sigmoid')(out)  \n",
    "    \n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(depth, L, 1)),\n",
    "            tf.keras.layers.Dense(int(L), activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),                \n",
    "            tf.keras.layers.Dense(int(L*depth), activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),                \n",
    "            tf.keras.layers.Dense(int(L*depth), activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),                            \n",
    "            tf.keras.layers.Dense(int(L), activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),                        \n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')])        \n",
    "    \"\"\"\n",
    "    model = Model(inputs=input, outputs=out)    \n",
    "    return model \n",
    "    \n",
    "def CNN(NSamples, L, depth):\n",
    "    channel=1;\n",
    "    nnn = 512*(1 + 2*int(NSamples//1000))    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(int(float(L/2)), (4, 4), activation='relu', \\\n",
    "                            kernel_initializer='he_uniform', padding='same',             \n",
    "                            input_shape=(depth, L, 1)))\n",
    "    model.add(BatchNormalization())            \n",
    "    model.add(Conv2D(L, (3, 3), activation='relu', \\\n",
    "                             kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(L, (2, 2), activation='relu', \\\n",
    "                             kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    if depth>1:\n",
    "        model.add(MaxPooling2D((2, 2)))            \n",
    "    else:\n",
    "        model.add(MaxPooling2D((1, 2)))            \n",
    "    \n",
    "    model.add(Dropout(0.2))    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nnn, activation='relu'))                \n",
    "    model.add(Dropout(0.2))                \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    return model            \n",
    "    \n",
    "    \n",
    "    \n",
    "def MyResnet(NSamples, L, depth):\n",
    "    channel=1;\n",
    "    nnn = 128*(1 + 2*int(NSamples//1000))\n",
    "    nqbit = L;\n",
    "    input_shape = [depth, L, channel]\n",
    "    #        tf.keras.layers.Flatten(input_shape=(realT, LDimOfArrays, 1)),\n",
    "    #        tf.keras.layers.Dense(int(LDimOfArrays/2), activation='relu'),\n",
    "    input = Input(shape=(input_shape[0], input_shape[1], input_shape[2]))\n",
    "\n",
    "    '''block_1'''\n",
    "    out = Conv2D(filters=int(float(nqbit/2)), kernel_size=(4, 4), strides=(1, 1),\n",
    "                        padding='same', use_bias=False, name='b1_cnv2d_1', kernel_initializer='normal',\n",
    "                        kernel_regularizer=regularizers.L2(0.001))(input)\n",
    "    out = BatchNormalization(epsilon=1e-3, momentum=0.5, name='b1_bn_1')(out)  # size: 14*14\n",
    "    out = ReLU(name='b1_relu_1')(out)\n",
    "    #outskip = out    \n",
    "    out = MaxPooling2D((1, 2), strides=(1, 1), padding='same')(out)\n",
    "    \n",
    "    \n",
    "    out = Conv2D(filters=nqbit, kernel_size=(2, 2), strides=(1, 1), padding='same',\n",
    "                    use_bias=False, name='b1_cnv2d_2', kernel_initializer='normal',\n",
    "                    kernel_regularizer=regularizers.L2(0.001))(out)\n",
    "    out = BatchNormalization(epsilon=1e-3, momentum=0.5, name='b1_bn_2')(out)  # size: 14*14\n",
    "    out = ReLU(name='b1_relu_2')(out)\n",
    "    out = MaxPooling2D((1, 2), strides=(1, 1), padding='same')(out)\n",
    "    \n",
    "\n",
    "    out = Conv2D(nqbit, kernel_size=(3, 3), strides=(1, 1), padding='same',  # padding='valid',\n",
    "               kernel_regularizer=regularizers.L2(0.001))(out)\n",
    "    \n",
    "    out = BatchNormalization(epsilon=1e-3, momentum=0.5, name='b1_bn_3')(out)\n",
    "    out = ReLU(name='b1_relu_3')(out)\n",
    "    \n",
    "    \n",
    "    #if realT>1:\n",
    "    #    out = MaxPooling2D((2, 2), padding='same')(out)\n",
    "    #else:\n",
    "    #    out = MaxPooling2D((1, 2), padding='same')(out)\n",
    "        \n",
    "    out = Add()([out, input])\n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    \"\"\" \n",
    "    out = Conv2D(filters=nqbit, kernel_size=(2, 2), strides=(1, 1), padding='same',\n",
    "                    use_bias=False, kernel_initializer='normal', \n",
    "                    kernel_regularizer=regularizers.L2(0.001))(out)\n",
    "    out = BatchNormalization(epsilon=1e-3, momentum=0.5)(out)  # size: 14*14\n",
    "    out = ReLU()(out)\n",
    "    \"\"\"\n",
    "    \n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(nnn, activation='relu')(out)\n",
    "    \n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    #out = Dense(int(nnn/4), activation='relu')(out)\n",
    "    \n",
    "    #out = Dropout(0.2)(out)\n",
    "    \n",
    "    #b1_avg = GlobalAveragePooling2D()(b1_drop2)\n",
    "        \n",
    "    output = Dense(1, name='model_output', activation='sigmoid')(out)\n",
    "    \n",
    "    #output = Dense(output_shape, name='model_output', activation='softmax',\n",
    "    #           kernel_initializer='he_uniform')(b4_avg_p)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    #model_json = model.to_json()\n",
    "\n",
    "    #with open(\"sample_res_net_v0.json\", \"w\") as json_file:\n",
    "    #    json_file.write(model_json)\n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(nnn, activation='relu'))                \n",
    "    \n",
    "    #model.add(Dropout(0.2))\n",
    "                \n",
    "    #model.add(Dense(1, activation='sigmoid'))            \n",
    "\n",
    "    #'''block 2'''\n",
    "    #b2_cnv2d_1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "    #                use_bias=False, name='b2_cnv2d_1', kernel_initializer='normal')(b1_out)\n",
    "    #b2_relu_1 = ReLU(name='b2_relu_1')(b2_cnv2d_1)\n",
    "    #b2_bn_1 = BatchNormalization(epsilon=1e-3, momentum=0.999, name='b2_bn_1')(b2_relu_1)  # size: 14*14\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#image_size = 12  # We'll resize input images to this size\n",
    "#image_size = 72  # We'll resize input images to this size\n",
    "#image_size1 = image_size\n",
    "#image_size2 = image_size\n",
    "\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "#data_augmentation.layers[0].adapt(x_train)\n",
    "\n",
    "\n",
    "def RNN(NSamples, L, depth, allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    channel = 1; units = 64;\n",
    "    nnn = 128*(1 + 2*int(NSamples//1000))\n",
    "    nqbit = L;\n",
    "    input_shape = [depth, L, 1]\n",
    "    input = Input(shape=(input_shape[0], int(input_shape[1]), input_shape[2]))    \n",
    "    out = tf.reshape(input, [NSamples, depth, L])\n",
    "    #out = Flatten(input_shape=(depth, L, 1))(input)        \n",
    "    \n",
    "    #        tf.keras.layers.Flatten(input_shape=(realT, LDimOfArrays, 1)),\n",
    "    #        tf.keras.layers.Dense(int(LDimOfArrays/2), activation='relu'),\n",
    "    #input = Input(shape=(input_shape[0], input_shape[1]))\n",
    "    \n",
    "    #out = Conv2D(filters=int(float(nqbit/2)), kernel_size=(4, 4), strides=(1, 1),\n",
    "    #                    padding='same', use_bias=False, name='b1_cnv2d_1', kernel_initializer='normal',\n",
    "    #                    kernel_regularizer=regularizers.L2(0.001))(input)\n",
    "    #out = BatchNormalization(epsilon=1e-3, momentum=0.5, name='b1_bn_1')(out)  # size: 14*14\n",
    "\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        #lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(depth, L))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(depth, L))\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(64, input_shape=(depth, L), return_sequences=True))    \n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.LSTM(64))    \n",
    "    model.add(keras.layers.Dense(int(nnn/4), activation='relu'))    \n",
    "    model.add(keras.layers.Dropout(0.2))    \n",
    "    model.add(keras.layers.Dense(1, name='model_output', activation='sigmoid'))    \n",
    "    #b1_avg = GlobalAveragePooling2D()(b1_drop2)        \n",
    "    #model.add.lstm_layer\n",
    "    #model.add.layers.BatchNormalization()\n",
    "        \n",
    "    #out = Sequential()\n",
    "    #out = Masking(mask_value=0., input_shape=(depth, L))(out)\n",
    "    #out = LSTM((units), input_shape=input_shape[:2])(out)\n",
    "    #model.add(Dense(output_size))\n",
    "    #out = Dropout(0.2)(out)  \n",
    "    #print(f\"out shape = {out.shape}\")\n",
    "    #out = LSTM((2*units)), input_shape=(time_steps, input_dim))(out)\n",
    "    #out = LSTM(units)(out)\n",
    "    #out = Flatten()(out)\n",
    "    #out = Dense(nnn, activation='relu')(out)    \n",
    "    #out = Dropout(0.2)(out)    \n",
    "    #out = Dense(int(nnn/4), activation='relu')(out)    \n",
    "    #out = Dropout(0.2)(out) \n",
    "    #b1_avg = GlobalAveragePooling2D()(b1_drop2)        \n",
    "    #output = Dense(1, name='model_output', activation='sigmoid')(out)\n",
    "    \n",
    "    #output = Dense(output_shape, name='model_output', activation='softmax',\n",
    "    #           kernel_initializer='he_uniform')(b4_avg_p)\n",
    "    #model = Model(input, output)\n",
    "\n",
    "    #model_json = model.to_json()\n",
    "    #with open(\"sample_res_net_v0.json\", \"w\") as json_file:\n",
    "    #    json_file.write(model_json)\n",
    "    #print(\"model.summary() = \", model.summary())\n",
    "    #plot_model(model)\n",
    "    \n",
    "    #[\n",
    "    #        lstm_layer,\n",
    "    #        keras.layers.BatchNormalization(),\n",
    "    #        keras.layers.Dense(output_size),]        \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class PatchesOld(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patchesOld = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            #    input_shape = [depth, nqbit, 1]\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        print(\"patchesOld.shape = \", patchesOld.shape)\n",
    "        patch_dims = patchesOld.shape[-1]\n",
    "        print(\"patchOld_dims = \", patch_dims)\n",
    "        print(f\"patchesOld shape before = {tf.shape(patchesOld)}\")\n",
    "        patchesOld = tf.reshape(patchesOld, [batch_size, -1, patch_dims])\n",
    "        print(f\"patchesOld shape after = {tf.shape(patchesOld)}\")        \n",
    "        return patchesOld\n",
    "    \n",
    "mnist = tf.keras.datasets.mnist   \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_trainNew = np.zeros((np.shape(x_train)[0], np.shape(x_train)[1], np.shape(x_train)[2], 1))\n",
    "x_trainNew[:, :, :, 0] = x_train[:, :, :]\n",
    "image = x_trainNew[np.random.choice(range(x_trainNew.shape[0]))]    \n",
    "image_size1, image_size2 = 28, 28\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size1, image_size2))\n",
    "#patches = PatchesOld(patch_size=4)(resized_image)\n",
    "    \n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size1, patch_size2):\n",
    "        super().__init__()\n",
    "        self.patch_size1 = patch_size1\n",
    "        self.patch_size2 = patch_size2\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            #    input_shape = [depth, nqbit, 1]\n",
    "            sizes=[1, self.patch_size1, self.patch_size2, 1],\n",
    "            strides=[1, self.patch_size1, self.patch_size2, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",)\n",
    "        patch_dims = patches.shape[-1]        \n",
    "        #print(\"patches.shape = \", patches.shape)\n",
    "        #print(\"batch_size = \", batch_size)\n",
    "        #print(\"patch_dims = \", patch_dims)        \n",
    "        #print(f\"[batch_size, -1, patch_dims] = [{batch_size}, {-1}, {patch_dims}]\")\n",
    "        #print(f\"patches shape before = {tf.shape(patches)}\")\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        #print(f\"patches shape after = {tf.shape(patches)}\")        \n",
    "        return patches\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size1, image_size2)\n",
    ")\n",
    "#print(\"resized_image = \", resized_image)\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size1} X {image_size2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "#print(\"patches = \", patches)\n",
    "n = int(np.sqrt(patches.shape[1])+1)\n",
    "plt.figure(figsize=(4, 4))\n",
    "print(\"patches[0]=\", patches[0])\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    print(\"i = \", i)\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\"\"\"    \n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    \n",
    "    \n",
    "def VisionTransformer(nqbit, depth):\n",
    "    image_size1 = nqbit\n",
    "    image_size2 = depth\n",
    "    input_shape = [depth, nqbit, 1]\n",
    "    num_classes = 2\n",
    "    if depth%2==1:\n",
    "        patch_size2 = 1 # = 6; # Size of the patches to be extract from the input images\n",
    "    elif depth%2==0:\n",
    "        patch_size2 = 2 # = 6; # Size of the patches to be extract from the input images        \n",
    "    patch_size1 = 2;\n",
    "    #num_patches = (image_size // patch_size) ** 2\n",
    "    num_patches = image_size1*image_size2 // (patch_size1*patch_size2)\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,]  # Size of the transformer layers\n",
    "    transformer_layers = 8\n",
    "    mlp_head_units = [1024, 512]  # Size of the dense layers of the final classifier\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size1, image_size2),\n",
    "        #layers.RandomFlip(\"horizontal\"),\n",
    "        #layers.RandomRotation(factor=0.02),\n",
    "        #layers.RandomZoom(\n",
    "        #    height_factor=0.2, width_factor=0.2\n",
    "        #),\n",
    "    ],name=\"data_augmentation\",)    \n",
    "    \n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size1, patch_size2)(augmented)\n",
    "    #patches = PatchesOld(patch_size1)(augmented)    \n",
    "    #print(\"patches = \", patches)\n",
    "    #patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    #logits = layers.Dense(num_classes)(features)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(features)\n",
    "    \n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "    \n",
    "    \"\"\"\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(nnn, activation='relu')(out)    \n",
    "    out = Dropout(0.2)(out)    \n",
    "    #out = Dense(int(nnn/4), activation='relu')(out)    \n",
    "    #out = Dropout(0.2)(out)    \n",
    "    #b1_avg = GlobalAveragePooling2D()(b1_drop2)        \n",
    "    output = Dense(1, name='model_output', activation='sigmoid')(out)    \n",
    "    model = Model(input, output)\n",
    "    \"\"\";\n",
    "    \n",
    "def run_vit(model, x_train, y_train):\n",
    "    \n",
    "    learning_rate = 0.005\n",
    "    weight_decay = 0.0002\n",
    "    batch_size = 256\n",
    "    num_epochs = 100\n",
    "    \n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            #keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    print(\"shape x_train = \", np.shape(x_train))\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "#vit_classifier = VisionTransformer(8, 1)\n",
    "#history = run_experiment(vit_classifier, x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    _, height, width, channels = x.shape\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n",
    "    )\n",
    "    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n",
    "    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, height, width, channels):\n",
    "    patch_num_y = height // window_size\n",
    "    patch_num_x = width // window_size\n",
    "    x = tf.reshape(\n",
    "        windows,\n",
    "        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n",
    "    )\n",
    "    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n",
    "    x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DropPath(layers.Layer):\n",
    "    def __init__(self, drop_prob=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x):\n",
    "        input_shape = tf.shape(x)\n",
    "        batch_size = input_shape[0]\n",
    "        rank = x.shape.rank\n",
    "        shape = (batch_size,) + (1,) * (rank - 1)\n",
    "        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n",
    "        path_mask = tf.floor(random_tensor)\n",
    "        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n",
    "        return output\n",
    "\n",
    "    \n",
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(\n",
    "        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.proj = layers.Dense(dim)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_window_elements = (2 * self.window_size[0] - 1) * (\n",
    "            2 * self.window_size[1] - 1\n",
    "        )\n",
    "        self.relative_position_bias_table = self.add_weight(\n",
    "            shape=(num_window_elements, self.num_heads),\n",
    "            initializer=tf.initializers.Zeros(),\n",
    "            trainable=True,\n",
    "        )\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n",
    "        coords = np.stack(coords_matrix)\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "\n",
    "        self.relative_position_index = tf.Variable(\n",
    "            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n",
    "        )\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        _, size, channels = x.shape\n",
    "        head_dim = channels // self.num_heads\n",
    "        x_qkv = self.qkv(x)\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n",
    "        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n",
    "        q = q * self.scale\n",
    "        k = tf.transpose(k, perm=(0, 1, 3, 2))\n",
    "        attn = q @ k\n",
    "\n",
    "        num_window_elements = self.window_size[0] * self.window_size[1]\n",
    "        relative_position_index_flat = tf.reshape(\n",
    "            self.relative_position_index, shape=(-1,)\n",
    "        )\n",
    "        relative_position_bias = tf.gather(\n",
    "            self.relative_position_bias_table, relative_position_index_flat\n",
    "        )\n",
    "        relative_position_bias = tf.reshape(\n",
    "            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n",
    "        )\n",
    "        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]\n",
    "            mask_float = tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n",
    "            )\n",
    "            attn = (\n",
    "                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n",
    "                + mask_float\n",
    "            )\n",
    "            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = keras.activations.softmax(attn, axis=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        x_qkv = attn @ v\n",
    "        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n",
    "        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n",
    "        x_qkv = self.proj(x_qkv)\n",
    "        x_qkv = self.dropout(x_qkv)\n",
    "        return x_qkv\n",
    "    \n",
    "    \n",
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        validation_split = 0.1, \n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim  # number of input dimensions\n",
    "        self.num_patch = num_patch  # number of embedded patches\n",
    "        self.num_heads = num_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.num_mlp = num_mlp  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size=(self.window_size, self.window_size),\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.drop_path = DropPath(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
    "            )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
    "                mask_windows, axis=2\n",
    "            )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
    "        )\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
    "        )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "        )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x\n",
    "    \n",
    "class PatchExtract(layers.Layer):\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size_x = patch_size[0]\n",
    "        self.patch_size_y = patch_size[0]\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n",
    "            rates=(1, 1, 1, 1),\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dim = patches.shape[-1]\n",
    "        patch_num = patches.shape[1]\n",
    "        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_patch = num_patch\n",
    "        self.proj = layers.Dense(embed_dim)\n",
    "        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, patch):\n",
    "        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n",
    "        return self.proj(patch) + self.pos_embed(pos)\n",
    "\n",
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_patch, embed_dim):\n",
    "        super().__init__()\n",
    "        self.num_patch = num_patch\n",
    "        self.embed_dim = embed_dim\n",
    "        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, _, C = x.get_shape().as_list()\n",
    "        x = tf.reshape(x, shape=(-1, height, width, C))\n",
    "        x0 = x[:, 0::2, 0::2, :]\n",
    "        x1 = x[:, 1::2, 0::2, :]\n",
    "        x2 = x[:, 0::2, 1::2, :]\n",
    "        x3 = x[:, 1::2, 1::2, :]\n",
    "        x = tf.concat((x0, x1, x2, x3), axis=-1)\n",
    "        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n",
    "        return self.linear_trans(x)\n",
    "    \n",
    "def SwinTransformerNN(nqbit, depth):\n",
    "    num_classes = 2;\n",
    "    if depth%2==1:\n",
    "        patch_size = (2, 1)  # 2-by-2 sized patches\n",
    "    elif depth%2==0:\n",
    "        patch_size = (2, 2)  # 2-by-2 sized patches        \n",
    "    dropout_rate = 0.03  # Dropout rate\n",
    "    num_heads = 8  # Attention heads\n",
    "    embed_dim = 64  # Embedding dimension\n",
    "    num_mlp = 256  # MLP layer size\n",
    "    qkv_bias = True  # Convert embedded patches to query, \\\n",
    "    #key, and values with a learnable additive value\n",
    "    window_size = 2  # Size of attention window\n",
    "    shift_size = 1  # Size of shifting window\n",
    "    image_dimension = nqbit  # Initial image size\n",
    "    validation_split = 0.1\n",
    "    input_shape = [nqbit, depth, 1]\n",
    "    num_patch_x = input_shape[0] // patch_size[0]\n",
    "    num_patch_y = input_shape[1] // patch_size[1]\n",
    "\n",
    "    #learning_rate = 1e-3\n",
    "    #batch_size = 128\n",
    "    num_epochs = 5 \n",
    "    #validation_split = 0.1\n",
    "    #weight_decay = 0.0001\n",
    "    #label_smoothing = 0.1    \n",
    "    print(\"input_shape = \", input_shape)\n",
    "    input = layers.Input(input_shape)\n",
    "    #x = layers.RandomCrop(image_dimension, image_dimension)(input)\n",
    "    #x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    x = PatchExtract(patch_size)(input)\n",
    "    #x = PatchExtract(patch_size)(x)\n",
    "    x = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\n",
    "    x = SwinTransformer(\n",
    "    dim=embed_dim,\n",
    "    num_patch=(num_patch_x, num_patch_y),\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=0,\n",
    "    num_mlp=num_mlp,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,)(x)\n",
    "    x = SwinTransformer(\n",
    "    dim=embed_dim,\n",
    "    num_patch=(num_patch_x, num_patch_y),\n",
    "    num_heads=num_heads,\n",
    "    window_size=window_size,\n",
    "    shift_size=shift_size,\n",
    "    num_mlp=num_mlp,\n",
    "    qkv_bias=qkv_bias,\n",
    "    dropout_rate=dropout_rate,)(x)\n",
    "    x = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    logits = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input, outputs=logits)\n",
    "    return model #''';\n",
    "    \n",
    "def NNModel(modelname, NSamples, nqbit, depth, nonZero=0, NnonZero=0):\n",
    "    print(\"modelname in NNModel = \", modelname)\n",
    "    if modelname==\"MyResnet\" or modelname==0:\n",
    "        model = MyResnet(NSamples, nqbit, depth)\n",
    "    elif modelname==\"VIT\" or modelname==1: # VisionTransformer\n",
    "        model = VisionTransformer(nqbit, depth)\n",
    "    elif modelname==\"Swin\" or modelname==2:\n",
    "        model = SwinTransformerNN(nqbit, depth)\n",
    "    elif modelname==\"MLP\" or modelname==3:\n",
    "        model = MLP(NSamples, nqbit, depth, nonZero, NnonZero)\n",
    "    elif modelname==\"Resnet50\":  # modelname==1:\n",
    "        model = Resnet(NSamples, nqbit, depth)\n",
    "    elif modelname==\"CNN\" or modelname==4:\n",
    "        model = CNN(NSamples, nqbit, depth)\n",
    "    elif modelname==\"RNN\" or modelname==5:\n",
    "        model = RNN(NSamples, nqbit, depth)\n",
    "        \n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')\n",
    "input_data = np.array([1., 2., 3.], dtype='float32')\n",
    "layer = tf.keras.layers.Normalization(axis=None)\n",
    "#layer.adapt(adapt_data)\n",
    "#layer(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(nqbit, depth, p, measureArr, convKVec, NofNTR, nshots, \n",
    "             nnt1, realT, learnT1=0, lightCone=0, deltaLDim=0, NTest = [], testConvMeasure = [], \\\n",
    "             modelname = \"MyResnet\", ifremove0=0): \n",
    "    \n",
    "    print(\"shape testConvMeasure = \", np.shape(testConvMeasure))\n",
    "    # nqbit: number of qubits\n",
    "    # depth: circuit depth = time duration\n",
    "    # p: measurement rate\n",
    "    # measureArr: Array of mid-circuit measurements.\n",
    "    # convKVec: measurement results of the spin of the reference qubit. \n",
    "    \n",
    "    # nshots: Number of circuit shots.\n",
    "    # errRate: random single-qubit Pauli noise error rate.    \n",
    "    #delNNT: jump in the number of training samples\n",
    "    # nnt1: first training samples number.\n",
    "    # lightCone: is a bitwise number determining whether we only use the light cone data or not.\n",
    "    #measureArr: Array of measured qubits\n",
    "    #countDic: Dictionary of measured outcomes with the repetition of a classical string.\n",
    "    #delNNT: delta in the increase in the number of training samples\n",
    "    #NofNTR: number of delNNT such that the total number of training samples is NofNTR*delNNT. \n",
    "    #We fix NofNTR to be 1.  \n",
    "    #convKVec: measurement results of the ancilla qubit. \n",
    "    # NTest: Number of test samples. \n",
    "\n",
    "    nNodes=nqbit*depth\n",
    "    if lightCone:\n",
    "        if nqbit/2-1<realT+1:\n",
    "            LDimOfArrays = nqbit;\n",
    "        else:\n",
    "            LDimOfArrays = 2*(realT+1)+2*deltaLDim;\n",
    "    else:\n",
    "        LDimOfArrays = nqbit;\n",
    "        \n",
    "    refInd = nqbit+1;\n",
    "    middleInd = int(floor((nqbit-1)/2)); #In the old version of the time evolution code for ancillas, reference qubit is entangled to the middle qubit which is at the \"middle\" of the chain                        \n",
    "    halfLDim = int(float(LDimOfArrays/2))\n",
    "\n",
    "    \n",
    "    measureVec = np.zeros(nNodes)    \n",
    "    if measureArr==[]:\n",
    "        convKVecFirstShot = convKVec[:nNodes]\n",
    "        measureArr = np.reshape(convKVecFirstShot, (depth, nqbit))\n",
    "    for t in range(depth):\n",
    "        measureVec[t*nqbit:(t+1)*nqbit] = abs(measureArr[t, :])\n",
    "    \n",
    "    nshotVec = range(nshots)\n",
    "    measureRes = np.zeros((nshots, depth, nqbit))    \n",
    "    ancilla = np.zeros(nshots)\n",
    "    \n",
    "    #Training data:\n",
    "    # creating the measure array    \n",
    "\n",
    "    NnonZero = len(np.where(np.array(convKVec[:depth*nqbit]) != 0.0)[0])\n",
    "    \n",
    "    print(\"np.where(np.array(convKVec[:depth*nqbit]) != 0.0) = \", \\\n",
    "          np.where(np.array(convKVec[:depth*nqbit]) != 0.0)[0])\n",
    "    #print(\"NnonZero = \", NnonZero)\n",
    "    #print(\"convKVec[0:10] = \", convKVec[0:10])\n",
    "    NnonZeroLightCone = 0\n",
    "    \n",
    "    for nsh in range(nshots):\n",
    "        for t in range(depth):\n",
    "            if not ifremove0:\n",
    "                measureRes[nsh, t, 0:nqbit] = np.copy(convKVec[nsh*(nqbit*depth+1)+t*nqbit:\n",
    "                    nsh*(nqbit*depth+1)+(t+1)*nqbit])\n",
    "                if nsh==0:\n",
    "                    print(f\"measureRes[0, t, :10] = {measureRes[0, :, :10]}\")\n",
    "                \n",
    "                #measureRes[nsh, t, 0:nqbit] = 0.5*np.copy(convKVec[nsh*(nqbit*depth+1)+t*nqbit:\n",
    "                #    nsh*(nqbit*depth+1)+(t+1)*nqbit])+0.5*np.ones((1, nqbit))\n",
    "                #if nsh==0:\n",
    "                #    print(f\"measureRes[0, t, :10] after = {measureRes[0, :, :10]}\")\n",
    "                    \n",
    "            else:\n",
    "                if not lightCone:\n",
    "                    measureRes[nsh, t, 0:nqbit] = np.copy(convKVec[nsh*(nqbit*depth+1)+t*nqbit:\n",
    "                        nsh*(nqbit*depth+1)+(t+1)*nqbit])\n",
    "                else:\n",
    "                    minInd = max(0, middleInd-(t+1))\n",
    "                    maxInd = min(middleInd+(t+1), nqbit)\n",
    "                    measureRes[nsh, t, minInd:maxInd] = np.copy(convKVec[nsh*(nqbit*depth+1)+t*nqbit+minInd:\n",
    "                        nsh*(nqbit*depth+1)+t*nqbit+maxInd])\n",
    "                    if nsh==0:\n",
    "                        print(\"convKVec[t*nqbit+minInd:t*nqbit+maxInd] = \", convKVec[t*nqbit+minInd:t*nqbit+maxInd])\n",
    "                        NnonZeroLightCone += len(np.where(np.array(convKVec[t*nqbit+minInd:t*nqbit+maxInd])\\\n",
    "                                                          != 0.0)[0])\n",
    "        ancilla[nsh] = convKVec[(nsh+1)*(nqbit*depth+1)-1]\n",
    "    \n",
    "    print(\"NnonZeroLightCone = \", NnonZeroLightCone)\n",
    "    if lightCone:\n",
    "        NnonZero = NnonZeroLightCone\n",
    "        \n",
    "    print(\"measureRes = \", measureRes[:2, :, :])\n",
    "    nnt = int(nnt1) #int(np.floor(delNNT*(NofNTR)))    \n",
    "    NSampVec = [nnt1] #np.arange(nnt1, nnt, delNNT)\n",
    "    #print(\"NSampVec = \", NSampVec)\n",
    "    NRepLearn = 1;            \n",
    "    Ncircuit=1;\n",
    "    n = 0;\n",
    "    #print(\"convKVec in learning = \", convKVec[:20])\n",
    "    #realT = 4; #depth\n",
    "    #print(\"realT before = \", realT)\n",
    "    realT = min(realT, depth)\n",
    "\n",
    "    scoresArr = np.zeros(NofNTR);\n",
    "    if NTest==[]:\n",
    "        NTest = int(min(abs(nshots-max(NSampVec)), 400));    \n",
    "    \n",
    "    sigmaPredict = np.zeros((NofNTR, NTest))\n",
    "    print(\"NSampVec = \", NSampVec)\n",
    "    \n",
    "    #print(\"NofNTR = \", NofNTR)\n",
    "    if learnT1!=0:\n",
    "        if depth>=realT:\n",
    "            learnT1 = min(depth-realT, learnT1)\n",
    "        else: \n",
    "            learnT1 = 0\n",
    "    print(\"learnT1 in learning= \", learnT1)\n",
    "    \n",
    "    for ntr in range(NofNTR):\n",
    "        NSamples = int(NSampVec[ntr])\n",
    "        if NSamples > 2000:\n",
    "            epoch = 400\n",
    "        else:\n",
    "            epoch = 200\n",
    "        if not ifremove0:                         \n",
    "            measureResTrain = np.zeros((NSamples, realT, nqbit));\n",
    "            measureResTest = np.zeros((NTest, realT, nqbit));\n",
    "        else:\n",
    "            measureResTrain = np.zeros((NSamples, NnonZero));\n",
    "            measureResTest = np.zeros((NTest, NnonZero));\n",
    "            \n",
    "        ancillaTrain = np.zeros((NSamples));\n",
    "        ancillaTest = np.zeros(NTest);\n",
    "        print(f\"nshotVec, NSamples = {nshotVec}, {NSamples}\")\n",
    "        vecSamples = sample(nshotVec, NSamples);        \n",
    "        trainInd = vecSamples;\n",
    "        print(f\"trainInd = {trainInd[:50]}\")\n",
    "        print(f\"shape trainInd = {np.shape(trainInd)}\")\n",
    "        testInd = [i for i in nshotVec if i not in trainInd]\n",
    "        print(f\"shape testInd = {np.shape(testInd)}\")        \n",
    "        print(\"ifremove0 = \", ifremove0)\n",
    "        \n",
    "        #print(\"not ifremove0 = \", not ifremove0)\n",
    "        for n in range(NSamples):            \n",
    "            if not ifremove0:             \n",
    "                measureResTrain[n, :, :] = measureRes[trainInd[n], learnT1:realT+learnT1, :]                                        \n",
    "            else:             \n",
    "                tempmeasure = np.reshape(measureRes[trainInd[n], learnT1:realT+learnT1, :], realT*nqbit)\n",
    "                measureResTrainwout0 = np.delete(tempmeasure, np.where(tempmeasure==0))                \n",
    "                if n==0:\n",
    "                    #print(\"measureResTrainwout0 = \", measureResTrainwout0)\n",
    "                    print(\"shape measureResTrainwout0 = \", np.shape(measureResTrainwout0))\n",
    "                    #print(\"shape measureResTrain = \", np.shape(measureResTrain))                \n",
    "                measureResTrain[n, :] = measureResTrainwout0\n",
    "            ancillaTrain[n] = ancilla[trainInd[n]]           \n",
    "            \n",
    "        for n in range(NTest):\n",
    "            if not ifremove0:\n",
    "                measureResTest[n, :, :] = measureRes[testInd[n], learnT1:realT+learnT1, :]\n",
    "            else:\n",
    "                tempmeasure = np.reshape(measureRes[testInd[n], learnT1:realT+learnT1, :], realT*nqbit)\n",
    "                measureResTestwout0 = np.delete(tempmeasure, np.where(tempmeasure==0))\n",
    "                measureResTest[n, :] = measureResTestwout0                               \n",
    "            ancillaTest[n] = ancilla[testInd[n]]\n",
    "                \n",
    "        if not ifremove0:\n",
    "            inputshape = tuple([NSamples, realT, LDimOfArrays, 1])\n",
    "            testshape = tuple([NTest, realT, LDimOfArrays, 1])\n",
    "        else:\n",
    "            inputshape = tuple([NSamples, NnonZero, 1])\n",
    "            testshape = tuple([NTest, NnonZero, 1])\n",
    "            \n",
    "        convMeasure = np.zeros(inputshape);\n",
    "        convAncilla = np.zeros((NSamples, 1));        \n",
    "        testConvAncilla = np.zeros((NTest, 1));                \n",
    "        \n",
    "        if not ifremove0:\n",
    "            convMeasure[:, :, :, 0] = np.copy(measureResTrain)\n",
    "        else:\n",
    "            convMeasure[:, :, 0] = np.copy(measureResTrain)\n",
    "        \n",
    "        convAncilla = np.copy(ancillaTrain);\n",
    "                \n",
    "        if np.size(testConvMeasure)==0:\n",
    "            testConvMeasure = np.zeros(testshape);\n",
    "            #testConvMeasure[:, :, :, 0] = np.copy(measureResTest);            \n",
    "            if not ifremove0: \n",
    "                testConvMeasure[:, :, :, 0] = np.copy(measureResTest);            \n",
    "            else:\n",
    "                testConvMeasure[:, :, 0] = np.copy(measureResTest);\n",
    "                            \n",
    "        testConvAncilla = np.copy(ancillaTest);        \n",
    "        nnn = 512*(1 + 2*int(NSamples//1000))\n",
    "        if not ifremove0: \n",
    "            print(\"convMeasure[0, :, :, :] = \", convMeasure[0, :, :, 0])\n",
    "\n",
    "        \n",
    "        for nl in range(NRepLearn):\n",
    "            print(\"convMeasure shape = \", np.shape(convMeasure))            \n",
    "            if realT>=1:\n",
    "                print(\"modelname = \", modelname)\n",
    "                if not ifremove0:\n",
    "                    model = NNModel(modelname, NSamples, int(LDimOfArrays), realT)\n",
    "                else:\n",
    "                    nonZero = 1\n",
    "                    model = MLP(NSamples, LDimOfArrays, depth, nonZero, NnonZero)\n",
    "                \n",
    "                #model = create_vit_classifier(nqbit, depth)\n",
    "                #model = resnet50(NSamples, LDimOfArrays, realT)\n",
    "                lrate = 0.01; weight_decay = 0.001;\n",
    "                #decay = .9\n",
    "                #sgd = SGD(lr=lrate, momentum=1, decay=decay, nesterov=False);\n",
    "                #optimizer = SGD(learning_rate=lrate, momentum=.5, nesterov=False);\n",
    "                #optimizer = tf.keras.optimizers.Adam(lrate);\n",
    "                optimizer = tfa.optimizers.AdamW(\n",
    "                    learning_rate=lrate, weight_decay=weight_decay)\n",
    "                kwargs = 'clipnorm';\n",
    "                #optimizer = tf.keras.optimizers.SGD(learning_rate=lrate, momentum=.5, \\\n",
    "                #        nesterov=False, name=\"SGD\")                \n",
    "                #        nesterov=False, name=\"adam\")                                                    \n",
    "                            \n",
    "                model.compile(loss='binary_crossentropy', optimizer=optimizer, \\\n",
    "                              metrics=['accuracy']);\n",
    "                # Train the model\n",
    "                \n",
    "                if NSamples > 20000:\n",
    "                    n_epoch = 500\n",
    "                elif NSamples <= 20000 and NSamples > 1000:\n",
    "                    n_epoch = 300\n",
    "                else:\n",
    "                    n_epoch = 150\n",
    "                #n_epoch = 5\n",
    "                print(\"n_epoch = \", n_epoch)\n",
    "                print(\"NSamples = \", NSamples)\n",
    "                AccHist = [];\n",
    "                valAccHist = [];\n",
    "                histLen = 100\n",
    "                histLen1 = 10           \n",
    "                batch_size = 256\n",
    "\n",
    "                for epoch in range(n_epoch):\n",
    "                    history = model.fit(convMeasure, ancillaTrain, epochs = 1, \\\n",
    "                            batch_size = batch_size, validation_split=0.1, verbose=0)\n",
    "                    if epoch%100==0:\n",
    "                        print(\"epoch = \", epoch)\n",
    "                    if epoch > histLen1:\n",
    "                        if (history.history['val_accuracy'][-1]<.55 and \n",
    "                            history.history['accuracy'][-1]>.8) or \\\n",
    "                        (history.history['val_accuracy'][-1] > .98 and \n",
    "                         history.history['accuracy'][-1] > .98):\n",
    "                            break\n",
    "\n",
    "                    AccHist.append(history.history['accuracy'][-1])                \n",
    "                    valAccHist.append(history.history['val_accuracy'][-1])                                                \n",
    "                    if epoch > histLen:\n",
    "                        if np.average(AccHist[-histLen:-1])-AccHist[-histLen]<0.001:\n",
    "                            a=1;\n",
    "                            break\n",
    "                        elif np.average(valAccHist[-histLen:-1])-valAccHist[-histLen]<0.001:\n",
    "                            a=1;\n",
    "                            break;\n",
    "                sys.stdout.flush()           \n",
    "                sys.stdout.flush()\n",
    "                print(f\"shape measureResTest = {np.shape(measureResTest)}, shape ancillaTest = {np.shape(ancillaTest)}\");\n",
    "\n",
    "                scores = model.evaluate(measureResTest, ancillaTest, verbose=0);\n",
    "                \n",
    "                print(\"scores = \", scores)\n",
    "                #print(\"ntr = \", ntr)\n",
    "                scoresArr[ntr] += scores[1]/NRepLearn;\n",
    "                #print(\"ancillaTest = \", ancillaTest[:10])\n",
    "                #print(\"testConvMeasure = \", testConvMeasure[:10, :, :, 0])\n",
    "                if not list(testConvMeasure):\n",
    "                    #predict=model.predict(testConvMeasure[:, :, :, :]); #input1.reshape(1, d, nq, 1))                 \n",
    "                    predict=model.predict(testConvMeasure);\n",
    "                else:\n",
    "                    predict=model.predict(measureResTest); #input1.reshape(1, d, nq, 1))                                     \n",
    "                    \n",
    "                classes=np.argmax(predict,axis=1);\n",
    "\n",
    "                tempSigma = 1*(predict)-(np.ones(np.shape(predict))-predict);                \n",
    "                print(\"tempSigma = \", tempSigma[:10])                \n",
    "                if scores[1]>.96:\n",
    "                    break\n",
    "            \n",
    "            if scoresArr[ntr]>.96:\n",
    "                print(\"break\");\n",
    "                break\n",
    "                \n",
    "        sigmaPredict[ntr, 0:NTest] = np.copy(np.array(tempSigma[:, 0]))\n",
    "        \n",
    "    if list(testConvMeasure):        \n",
    "        return model, sigmaPredict, testConvMeasure, NTest\n",
    "    else:\n",
    "        testConvMeasure = np.zeros((NTest, realT, LDimOfArrays, 1));\n",
    "        #testConvMeasure[:, :, :, 0] = np.copy(measureResTest);                    \n",
    "        testConvMeasure = np.copy(measureResTest);\n",
    "        return model, sigmaPredict, testConvMeasure, NTest\n",
    "    \n",
    "\"\"\"\n",
    "nq=4;d=2;hundredp=50;p=hundredp/100;refQbitAxis=\"Z\";\n",
    "Nshots=1000; errRate=0;lightCone=0; deltaLDim=0; ifsave=0;\n",
    "learningT1=1;learnDelT=1;renyiInd=2;trajNum=1;circ=\"None\";delNNT=[];seed=0.43;\n",
    "if delNNT==[]:\n",
    "    delNNT=int(.05*Nshots);nnt1=.9*Nshots;\n",
    "marrX, convKX, convKXNon0 = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"X\", Nshots, errRate);            \n",
    "marrY, convKY, convKYNon0 = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"Y\", Nshots, errRate);\n",
    "marrZ, convKZ, convKZNon0 = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"Z\", Nshots, errRate);\n",
    "A = learning(nq, d, hundredp/100, marrX, convKX, NofNTR, Nshots, \\\n",
    "            delNNT, nnt1, lightCone, deltaLDim)\n",
    "\"\"\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrajLearnPred(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, nshots, seed=[], modelname=\"MLP\", \\\n",
    "                     errRate=0, readoutErr=0, lightCone=0, deltaLDim=0, ifsave=0, nnt1=[], NTest=[]):\n",
    "    #d=4; learningT=d;p=0.1;circ=0; delNNT=500;nshots=5000;lightCone=0;deltaLDim=0;\n",
    "    \n",
    "    ### Args:\n",
    "    # nq = number of qubits\n",
    "    # d = depth of the circuit\n",
    "    # learningT1 = the initial time for obtaining S_Q(t)\n",
    "    # learnDelT = steps in the time vector of S_Q(t)\n",
    "    # hundredp = p*100; p= measurement rate\n",
    "    # trajNum = Number of quantum trajectories per each circuit. \n",
    "    # circ = circuit data including the unitary matrices and the measurement locations\n",
    "    # delNNT = steps in the number of samples of the input data for the neural networks. \n",
    "    # nshots = number of shots of quantum trajectories used for learning\n",
    "    # seed = the random seed for creating circuit configurations\n",
    "    # lightCone = Boolean whether or not use the light cone data\n",
    "    # deltaLDim = offset of the light cone box if lightCone==True\n",
    "    # ifsave = Boolean whether or not save the circuit configurations\n",
    "\n",
    "    p = hundredp/100;\n",
    "    print(\"p = \", p)\n",
    "    if circ==\"None\" or circ==0:\n",
    "        circ = genCircConfig(nq, d, p, seed);\n",
    "    \n",
    "    learningT2 = d+1;\n",
    "    #print(\"delNNT before = \", delNNT)\n",
    "    #if delNNT==[]:\n",
    "    #    delNNT=.05*nshots;\n",
    "    if nnt1==[]: \n",
    "        nnt1=int(0.9*nshots);\n",
    "    print(\"nshots = \", nshots)\n",
    "    #print(\"nshots in genTrajLearnPred = \", nshots)\n",
    "    #print(\"((nshots-nnt1)/(delNNT))=\", ((nshots-nnt1)/(delNNT)))\n",
    "    NofNTR = 1; #int(floor((nshots-nnt1)/(delNNT)))-1;\n",
    "    #print(\"NofNTR in genTrajLearnPred = \", NofNTR, \", trajNum = \", trajNum)\n",
    "    learnT = np.arange(learningT1, learningT2, learnDelT);\n",
    "    #print(\"learnT = \", learnT);\n",
    "    lightCone=0; deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    \n",
    "    aveEeVec = np.zeros(len(learnT));\n",
    "    aveEeVecNon0 = np.zeros(len(learnT));\n",
    "    \n",
    "    aveEeVecAllNon0 = np.zeros(len(learnT));\n",
    "    \n",
    "    exactEE = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "\n",
    "    aveEeZVec = np.zeros(len(learnT));\n",
    "    exactEEZ = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "    EEZRes = np.zeros((2, len(learnT)));\n",
    "    \n",
    "    eeVec = np.zeros(len(learnT)); \n",
    "    eeZVec = np.zeros(len(learnT));     \n",
    "    svecAve = np.zeros((3, len(learnT))); \n",
    "    svecAveNon0 = np.zeros((3, len(learnT))); \n",
    "    \n",
    "    print(\"seed = \", seed)\n",
    "    for trj in range(trajNum):   \n",
    "        eeVec = np.zeros(len(learnT));\n",
    "        for t in range(len(learnT)):\n",
    "            print(\"t = \", t)\n",
    "            timel = learnT[t];\n",
    "            print(\"evolving X\")\n",
    "            marrX, convKX, convKXNon0, _, countsX = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"X\", \\\n",
    "                                                                   nshots, errRate, readoutErr, seed);\n",
    "            print(\"evolving Y\")            \n",
    "            marrY, convKY, convKYNon0, _, countsY = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Y\", \\\n",
    "                                                                   nshots, errRate, readoutErr, seed);\n",
    "            print(\"evolving Z\")                        \n",
    "            marrZ, convKZ, convKZNon0, _, countsZ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Z\", \\\n",
    "                                                                   nshots, errRate, readoutErr, seed);\n",
    "            #print(\"np.shape(convKX) = \", np.shape(convKX))\n",
    "            state, rhoAncilla, exactEE[t], measureArr, exactEEZ[t] = timeEvolveAncilla(nq, timel, p, \\\n",
    "                                                                    \"prod\", circ, 2, \"None\", nshots, errRate, readoutErr, seed);  \n",
    "            \n",
    "            # We use the test quantum trajectory produced in circuit X, and use it in the second two circuits.\n",
    "            #print(\"shape convKX = \", np.shape(convKX))\n",
    "            #print(\"convKX = \", convKX[:20])\"\"\n",
    "            print(\"learning X \\n \\n \\n\")\n",
    "            modelx, sxvec, testMeasX, NTest = learning(nq, timel, p, marrX, convKX, NofNTR, nshots, \\\n",
    "                             nnt1, lightCone, deltaLDim, NTest);\n",
    "            \n",
    "            #return model, sigmaPredict, NTest, measureResTest, sigmaPredictNon0\n",
    "            \n",
    "            #print(\"np.shape(testMeasX) =\", np.shape(testMeasX))\n",
    "            #print(\"testMeasX = \", testMeasX[:5, :, :])\n",
    "            \n",
    "            print(\"learning Y \\n \\n \\n\")            \n",
    "            modely, syvec, _, NTest = learning(nq, timel, p, marrY, convKY, NofNTR, nshots, \\\n",
    "                             nnt1, lightCone, deltaLDim, NTest, testMeasX);\n",
    "            print(\"learning Z \\n \\n \\n\")\n",
    "            modelz, szvec, _, NTest = learning(nq, timel, p, marrZ, convKZ, NofNTR, nshots, \\\n",
    "                             nnt1, lightCone, deltaLDim, NTest, testMeasX);\n",
    "                        \n",
    "            \n",
    "            svec=[sxvec, syvec, szvec];        \n",
    "            \n",
    "            svecAve[0, t] = np.mean(sxvec); \n",
    "            svecAve[1, t] = np.mean(syvec);\n",
    "            svecAve[2, t] = np.mean(szvec);\n",
    "            #print(\"np.shape(np.mean(svecAllNon0, axis=2)) = \", np.shape(np.mean(svecAllNon0, axis=2)))\n",
    "            #print(\"svecAllNon0[:, 0, :] = \", svecAllNon0[:, 0, :])\n",
    "                                                \n",
    "            for modelCnt in range(1):\n",
    "                ee=0;\n",
    "                eeZ=0;                \n",
    "                for i in range(NTest): \n",
    "                    if modelCnt==0:                \n",
    "                        sx=sxvec[0, i]\n",
    "                        sy=syvec[0, i]\n",
    "                        sz=szvec[0, i]\n",
    "                        \n",
    "                    method=\"TNC\"; \n",
    "                    physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)\n",
    "                    if np.isnan(physden[0, 0]) or \\\n",
    "                        np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                        np.isnan(physden[1, 1]):\n",
    "                    #print(\"sx = \", sx, \", sy = \", sy, \", sz = \", sz)\n",
    "            \n",
    "                        method=\"nelder-mead\"\n",
    "                        physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)\n",
    "                        #print(\"physden = \", physden)\n",
    "                        if np.isnan(physden[0, 0]) or \\\n",
    "                        np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                        np.isnan(physden[1, 1]):\n",
    "                            method=\"SLSQP\";\n",
    "                            physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method);\n",
    "                            if np.isnan(physden[0, 0]) or \\\n",
    "                            np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                            np.isnan(physden[1, 1]):\n",
    "                            #print(\"continue\")\n",
    "                                continue\n",
    "            \n",
    "                    partialEE = -np.trace(np.matmul(logm(physden),physden));\n",
    "                    eigval = eig(physden)[0];\n",
    "                    if eigval[0]==0:\n",
    "                        eigval[0]=1e-16;\n",
    "                    if eigval[1]==0:\n",
    "                        eigval[1]=1e-16;\n",
    "        \n",
    "                    partialee = -np.sum(np.dot(np.log2(eigval), eigval));\n",
    "                    if np.isnan(partialee):\n",
    "                        continue\n",
    "                    \n",
    "                    ee = ee+np.real(partialee/(NTest));\n",
    "                    #print(\"partialee/NTest = \", partialee/NTest);\n",
    "                    rvecNormZ = abs(sz)\n",
    "                    eigvalsDenZ = [1/2-rvecNormZ/2, 1/2+rvecNormZ/2];\n",
    "                    rhoAncillaZ = [[1/2*(1+sz), 0], [0, 1/2*(1-sz)]];                \n",
    "                    renyiInd=1;\n",
    "                    if renyiInd==1:\n",
    "                        try:\n",
    "                            partialeeZ = -np.real(sum([eigvalsDenZ[i]*np.log2((eigvalsDenZ[i])) for i in range(2)]))                \n",
    "                        except y:\n",
    "                            if isa(y, DomainError):\n",
    "                                println(\"domainError\")\n",
    "                                println(\"eigvalsDen = \", eigvalsDen)\n",
    "                                println(\"ancillaDenMat = \", ancillaDenMat)                    \n",
    "                            else:\n",
    "                                partialeeZ = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncillaZ, renyiInd)))\n",
    "                                partialeeZ = np.real(partialeeZ) \n",
    "                            \n",
    "                        if partialeeZ==1:\n",
    "                            partialeeZ=1-1e-8;\n",
    "                    eeZ = eeZ+np.real(partialeeZ/(NTest));\n",
    "                    \n",
    "                eeVec[t] = ee;            \n",
    "                eeZVec[t] = eeZ;\n",
    "                if modelCnt==0:\n",
    "                    aveEeVec[t] = aveEeVec[t]+eeVec[t];\n",
    "                    aveEeZVec[t] = aveEeZVec[t]+eeZVec[t];            \n",
    "    \"\"\"\n",
    "    densityDictX, densityDictY, densityDictZ = {}, {}, {}\n",
    "    totalDictX, totalDictY, totalDictZ = {}, {}, {}\n",
    "    countsCnt = 0    \n",
    "    countsXYZ = [countsX, countsY, countsZ]\n",
    "    \n",
    "    for dicCnt in range(3):\n",
    "        densityDict, totalDict = {}, {}\n",
    "        counts = countsXYZ[dicCnt]\n",
    "        #print(\"counts = \", counts)\n",
    "        for k,v in counts.items():             \n",
    "            tempInvK = k[::-1]\n",
    "            #print(\"tempInvK = {}, v = {}\".format(tempInvK, v))            \n",
    "            if densityDict.get(tempInvK[0:-1])==None:\n",
    "                totalDict[tempInvK[0:-1]] = v\n",
    "                if tempInvK[-1]==\"1\":\n",
    "                    densityDict[tempInvK[0:-1]] = v\n",
    "                elif tempInvK[-1]==\"0\":  \n",
    "                    densityDict[tempInvK[0:-1]] = -v\n",
    "            else:\n",
    "                totalDict[tempInvK[0:-1]] = totalDict[tempInvK[0:-1]] + v\n",
    "                if tempInvK[-1]==\"1\":\n",
    "                    densityDict[tempInvK[0:-1]] = densityDict[tempInvK[0:-1]] + v\n",
    "                elif tempInvK[-1]==\"0\":\n",
    "                    densityDict[tempInvK[0:-1]] = densityDict[tempInvK[0:-1]] - v\n",
    "            #print(\"tempInvK[0:-1] = {}, densityDict = {}, \\n\".format(tempInvK[0:-1], \\\n",
    "            #                        densityDict[tempInvK[0:-1]]))\n",
    "            \n",
    "        for k,v in densityDict.items():\n",
    "            densityDict[k] = densityDict[k]/totalDict[k]\n",
    "        if dicCnt==0:\n",
    "            totalDictX = totalDict\n",
    "            densityDictX = densityDict\n",
    "        elif dicCnt==1:  \n",
    "            totalDictY = totalDict            \n",
    "            densityDictY = densityDict\n",
    "        else:                       \n",
    "            totalDictZ = totalDict                        \n",
    "            densityDictZ = densityDict\n",
    "        \n",
    "    #print(\"densityDictX = \", densityDictX)\n",
    "    #print(\"densityDictY = \", densityDictY)    \n",
    "    #print(\"densityDictZ = \", densityDictZ)        \n",
    "    \n",
    "    totalEE = 0\n",
    "    for k, v in densityDictZ.items():\n",
    "        print(\"k = \", k)\n",
    "        densityXYZ = np.array([[1/2*(1+densityDictZ[k]), 1/2*(densityDictX[k]-1j*densityDictY[k])],\\\n",
    "                      [1/2*(densityDictX[k]+1j*densityDictY[k]), 1/2*(1-densityDictZ[k])]]) \n",
    "        print(\"densityXYZ = \", densityXYZ)\n",
    "        partialEE = -np.trace(np.matmul(logm(densityXYZ),densityXYZ));        \n",
    "        eigval = eig(densityXYZ)[0];        \n",
    "        print(\"eigval = \", eigval)\n",
    "        if eigval[0]==0:\n",
    "            eigval[0]=1e-16;\n",
    "        if eigval[1]==0:\n",
    "            eigval[1]=1e-16;\n",
    "            \n",
    "        partialEE = -np.sum(np.dot(np.log2(eigval), eigval))\n",
    "        print(\"partialEE = \", partialEE, \"\\n\")\n",
    "        totalEE += totalDict[k]/nshots*partialEE        \n",
    "        #partialee = -np.sum(np.dot(np.log2(eigval), eigval));\n",
    "        #if np.isnan(partialee):\n",
    "        #    continue                    \n",
    "        #ee = np.real(partialee)\n",
    "    print(\"totalEE = \", totalEE)                \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    aveEeVec=[aveEeVec[i]/trajNum for i in range(len(aveEeVec))];\n",
    "    aveEeZVec=[aveEeZVec[i]/trajNum for i in range(len(aveEeZVec))];    \n",
    "    \n",
    "    print(\"aveEeVec = \",aveEeVec);\n",
    "    print(\"exact EE = \", np.real(exactEE));\n",
    "    \n",
    "    EERes[0, 0:len(learnT)] = aveEeVec[0:len(learnT)];\n",
    "    EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "\n",
    "    EEZRes[0, 0:len(learnT)] = aveEeZVec[0:len(learnT)];\n",
    "    EEZRes[1, 0:len(learnT)] = exactEEZ[0:len(learnT)];\n",
    "        \n",
    "    df = pd.DataFrame(EERes);\n",
    "\n",
    "    #fileOpen = open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]), \"a\")\n",
    "    #s = fileOpen.read()\n",
    "                \n",
    "    with open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)    \n",
    "    \n",
    "    with open(\"HaarSpinRes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(svecAve);\n",
    "    \n",
    "    #df.to_csv(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}-time{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]))\n",
    "    \n",
    "    return  aveEeVec, aveEeZVec, exactEE, exactEEZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LDimOfArrays, realT = 8, 1\n",
    "input_shape = (800, realT, LDimOfArrays, 1)\n",
    "x = tf.random.normal(input_shape)\n",
    "kh, kw = 4, 4\n",
    "y1 = tf.keras.layers.Conv2D(int(float(LDimOfArrays/2)), (kh, kw), activation='relu', \\\n",
    "                            kernel_initializer='he_uniform', padding='same',             \n",
    "                            input_shape=(realT, LDimOfArrays, 1))(x)\n",
    "#y2 = tf.keras.layers.BatchNormalization(y1)\n",
    "y2 = tf.keras.layers.Conv2D(LDimOfArrays, (3, 3), activation='relu', \\\n",
    "                             kernel_initializer='he_uniform', padding='same')(y1)\n",
    "\n",
    "#y3 = tf.keras.layers.Conv2D(4, (2, 2), activation='relu', input_shape=input_shape[1:])(y2)\n",
    "\n",
    "y3 = tf.keras.layers.Dense(100, activation='relu')(y2)\n",
    "                \n",
    "y4 = tf.keras.layers.Dense(1, activation='sigmoid')(y3)\n",
    "\n",
    "#print(y1.shape, y2.shape, y3.shape, y4.shape)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningAllSpinNon0(nqbit, depth, p, measureArr, NofNTR, nshots,\n",
    "             delNNT, nnt1, lightCone, deltaLDim, convKNon0, NTest = [], testConvMeasure = [], \n",
    "                        testConvMeasureNon0=[]):\n",
    "    # nqbit: number of qubits\n",
    "    # depth: circuit depth = time duration\n",
    "    # p: measurement rate\n",
    "    # measureArr: Array of mid circuit measurements. \n",
    "    # convKXYZ: measurement results of the spin of the reference qubit along X, Y and Z. \n",
    "    \n",
    "    # nshots: Number of circuit shots.\n",
    "    # errRate: random single-qubit Pauli noise error rate.     \n",
    "    #delNNT: jump in the number of training samples\n",
    "    # nnt1: first training samples number.\n",
    "    # lightCone: is a bitwise number determining whether we only use the light cone data or not.\n",
    "    #measureArr: Array of measured qubits\n",
    "    #countDic: Dictionary of measured outcomes with the repetition of a classical string.\n",
    "    #delNNT: delta in the increase in the number of training samples\n",
    "    #NofNTR: number of delNNT such that the total number of training samples is NofNTR*delNNT. \n",
    "    #We fix NofNTR to be 1.  \n",
    "    #convKVec: measurement results of the ancilla qubit. \n",
    "    # NTest: Number of test samples. \n",
    "    # Dim convKNon0: 3*nshots*(lenNon0+1)\n",
    "    nshotVec = range(nshots)\n",
    "    measureRes = np.zeros((3*nshots, depth, nqbit))\n",
    "    measureRes2 = np.zeros((3*nshots, depth, nqbit))\n",
    "    \n",
    "    lenNon0 = np.shape(convKNon0)[2]\n",
    "    measureResNon0 = np.zeros((3*nshots, lenNon0-1))\n",
    "    \n",
    "    ancilla = np.zeros((nshots, 3))\n",
    "\n",
    "    #convKXYZNon0 = np.zeros((nshots, 3, np.shape(convKXNon0)[1]))\n",
    "    for xyzcnt in range(3):\n",
    "        for nsh in range(nshots):\n",
    "            for t in range(depth):                           \n",
    "                measureResNon0[nshots*xyzcnt+nsh, :] = np.add(0.5*convKNon0[nsh, xyzcnt, 0:-1], 0.5);\n",
    "            ancilla[nsh, xyzcnt] = convKNon0[nsh, xyzcnt, -1]\n",
    "            \n",
    "\n",
    "    nnt = nnt1 + int(np.floor(delNNT*(NofNTR)))\n",
    "    print(\"nnt={}, nnt1 = {}, delNNT={}, NofNTR={}\".format(nnt, nnt1, delNNT, NofNTR))\n",
    "    NSampVec = np.arange(nnt1, nnt, delNNT)\n",
    "    if NTest==[]:\n",
    "        NTest = int(min(abs(nshots-max(NSampVec)), 400));\n",
    "        print(\"NTest = \", NTest)\n",
    "        \n",
    "    sigmaPredictNon0 = np.zeros((NofNTR, NTest))\n",
    "    \n",
    "    #print(\"NSampVec = \", NSampVec);\n",
    "    NRepLearn = 1;            \n",
    "    Ncircuit=1;\n",
    "    n = 0;\n",
    "    realT = depth;\n",
    "    if lightCone:\n",
    "        if nqbit/2-1<depth+1:\n",
    "            LDimOfArrays = nqbit;\n",
    "        else:\n",
    "            LDimOfArrays = 2*(depth+1)+2*deltaLDim;\n",
    "    else:\n",
    "        LDimOfArrays = nqbit;\n",
    "        \n",
    "    refInd = nqbit+1;\n",
    "    #middleInd = 2*L; #In the new version of the time evolution code for ancillas, reference qubit is entangled to the middle qubit which is at the \"end\" of the chain\n",
    "    middleInd = int(floor(nqbit/2)); #In the old version of the time evolution code for ancillas, reference qubit is entangled to the middle qubit which is at the \"middle\" of the chain                        \n",
    "    halfLDim = int(float(LDimOfArrays/2))\n",
    "    \n",
    "    scoresArrNon0 = np.zeros(NofNTR);\n",
    "    sigmaPredictNon0 = np.zeros((NofNTR, 3, NTest))\n",
    "    lamRhoSq = 1;\n",
    "    \n",
    "    for ntr in range(NofNTR):        \n",
    "        NSamples = int(NSampVec[ntr]);        \n",
    "        print(\"NSamples = \", NSamples)\n",
    "        if NTest==[]:\n",
    "            NTest = int(min(abs(nshots-NSamples), 400));            \n",
    "        nnn = 512*(1 + 2*int(NSamples//1000));        \n",
    "        vecSamples = sample(nshotVec, NSamples);        \n",
    "        trainInd = vecSamples;\n",
    "        testInd = [i for i in nshotVec if i not in trainInd]\n",
    "        \n",
    "        for xyzcnt in range(0, 3):            \n",
    "            ancillaTrain = np.zeros((NSamples, 3));\n",
    "            ancillaTest = np.zeros((NTest, 3));              \n",
    "            measureResTrain = np.zeros((NSamples, depth, nqbit));\n",
    "            measureResTest = np.zeros((NTest, depth, nqbit));\n",
    "\n",
    "            for n in range(NSamples):                \n",
    "                measureResTrain[n, :, :] = measureRes[nshots*xyzcnt+trainInd[n], :, :]\n",
    "                ancillaTrain[n, xyzcnt] = ancilla[trainInd[n], xyzcnt]                    \n",
    "                    \n",
    "            for n in range(NTest):\n",
    "                xyzcntTest = 2; # We use the Z measurement data for the test data and making predictions.\n",
    "                measureResTest[n, :, :] = measureRes[nshots*xyzcntTest+testInd[n], :, :]\n",
    "                ancillaTest[n, xyzcntTest] = ancilla[testInd[n], xyzcntTest]\n",
    "                #if convKNon0!=[]:\n",
    "            \n",
    "            if True:\n",
    "                measureResNon0Train = np.zeros((NSamples, lenNon0-1));\n",
    "                measureResNon0Test = np.zeros((NTest, lenNon0-1));        \n",
    "                for n in range(NSamples):                    \n",
    "                    measureResNon0Train[n, :] = measureResNon0[nshots*xyzcnt+trainInd[n], :]\n",
    "                for n in range(NTest):                    \n",
    "                    xyzcntTest = 2; # We use the Z measurement data for making predictions. \n",
    "                    measureResNon0Test[n, :] = measureResNon0[nshots*xyzcntTest+testInd[n], :]\n",
    "\n",
    "                modelNon0 = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Flatten(input_shape=(lenNon0-1, 1)),\n",
    "                tf.keras.layers.Dense(20*(lenNon0-1), activation='relu'),\n",
    "                tf.keras.layers.Dropout(0.2),                                    \n",
    "                tf.keras.layers.Dense(20*(lenNon0-1), activation='relu'),\n",
    "                tf.keras.layers.Dropout(0.2),                                                        \n",
    "                tf.keras.layers.Dense(20*(lenNon0-1), activation='relu'),                    \n",
    "                tf.keras.layers.Dropout(0.2),                                                        \n",
    "                tf.keras.layers.Dense(20*(lenNon0-1), activation='relu'),                                        \n",
    "                tf.keras.layers.Dense(3, activation='sigmoid')]);\n",
    "                input_shape=(realT, LDimOfArrays, 1);\n",
    "                \n",
    "                if realT>=1:\n",
    "                    lrate = 0.001;\n",
    "                    sgd = SGD(learning_rate=lrate, momentum=1, nesterov=False);\n",
    "                    kwargs = 'clipnorm';\n",
    "                    optimizer = tf.keras.optimizers.Adam(lrate);\n",
    "                    #modelNon0.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']);\n",
    "                    modelNon0.compile(loss=myloss(xyzcnt, lamRhoSq), optimizer=optimizer, metrics=['accuracy']);\n",
    "                    n_epoch = 20\n",
    "                    AccHist = [];\n",
    "                    valAccHist = [];\n",
    "                    histLen = 100;\n",
    "                    histLen1 = 10;\n",
    "                    for epoch in range(n_epoch): #convMeasureNon0\n",
    "                        history = modelNon0.fit(measureResNon0Train, ancillaTrain, epochs = 1, \n",
    "                                                batch_size = 100, validation_split=0.1, verbose=1)\n",
    "                        \n",
    "                        if epoch%100==0:\n",
    "                            a=1;                    \n",
    "                        if epoch > histLen1:\n",
    "                            if (history.history['val_accuracy'][-1]<.55 and \n",
    "                                history.history['accuracy'][-1]>.8) or \\\n",
    "                            (history.history['val_accuracy'][-1] > .98 and \n",
    "                             history.history['accuracy'][-1] > .98):\n",
    "                                break\n",
    "                        AccHist.append(history.history['accuracy'][-1])                \n",
    "                        valAccHist.append(history.history['val_accuracy'][-1])                                                \n",
    "                        if epoch > histLen:\n",
    "                            if np.average(AccHist[-histLen:-1])-AccHist[-histLen]<0.001 :\n",
    "                                a=1;\n",
    "                                break\n",
    "                            elif np.average(valAccHist[-histLen:-1])-valAccHist[-histLen]<0.001:\n",
    "                                a=1;\n",
    "                                break;\n",
    "                                \n",
    "                    sys.stdout.flush()\n",
    "                    scoresNon0 = modelNon0.evaluate(measureResNon0Test, \n",
    "                                                    ancillaTest, verbose=0);\n",
    "                    scoresArrNon0[ntr] += scoresNon0[1]/NRepLearn;\n",
    "                    predictNon0=modelNon0.predict(measureResNon0Test); #input1.reshape(1, d, nq, 1))\n",
    "                \n",
    "                    #print(\"measureResNon0Test in learnAllNon0 = \", np.transpose(measureResNon0Test[:20, :]))\n",
    "                    print(\"ancillaTest in learnAllNon0 = \", np.transpose(ancillaTest[:20, :]))                     \n",
    "                    print(\"predictNon0 = \", np.transpose(predictNon0[:20]))\n",
    "\n",
    "                    classesNon0=np.argmax(predictNon0,axis=1);\n",
    "                    tempSigmaNon0 = 1*(predictNon0)-(np.ones(np.shape(predictNon0))-predictNon0);\n",
    "                if scoresArrNon0[ntr]>.96:\n",
    "                    a=1;\n",
    "                sigmaPredictNon0[ntr, :, 0:NTest] = np.transpose(np.array(tempSigmaNon0))    \n",
    "\n",
    "    return model, NTest, testConvMeasureNon0, sigmaPredictNon0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nq=4;d=4;hundredp=50;p=hundredp/100;refQbitAxis=\"Z\";\n",
    "#nshots=5000; errRate=0;lightCone=0; deltaLDim=0; ifsave=0;\n",
    "#learningT1=1;learnDelT=1;renyiInd=2;trajNum=1;delNNT=[];seed=2.387;\n",
    "#if delNNT==[]:\n",
    "#    delNNT=int(.05*nshots);nnt1=.9*nshots;\n",
    "#NofNTR = 1;\n",
    "\"\"\"\n",
    "circ = genCircConfig(nq, d, p, seed)\n",
    "\n",
    "marrX, convKX, convKXNon0, _ = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"X\", nshots, errRate);\n",
    "marrY, convKY, convKYNon0, _ = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"Y\", nshots, errRate);\n",
    "marrZ, convKZ, convKZNon0, _ = timeEvolveAncilla(nq, d, p, \"prod\", circ, 2, \"Z\", nshots, errRate);\n",
    "print(\"np.shape(convKXNon0) = \", np.shape(convKXNon0))\n",
    "print(\"np.shape(convKX) = \", np.shape(convKX))\n",
    "convKXYZ = np.zeros((3, np.shape(convKX)[0]))\n",
    "convKXYZ[0, :] = convKX\n",
    "convKXYZ[1, :] = convKY\n",
    "convKXYZ[2, :] = convKZ\n",
    "\n",
    "convKXYZNon0 = np.zeros((nshots, 3, np.shape(convKXNon0)[1]))\n",
    "convKXYZNon0[:, 0, :] = convKXNon0[:, :]\n",
    "convKXYZNon0[:, 1,  :] = convKYNon0[:, :]\n",
    "convKXYZNon0[:, 2, :] = convKZNon0[:, :]\n",
    "\n",
    "\"\"\";\n",
    "#A = learningAllSpinNon0(nq, d, p, marrX, NofNTR, nshots,\n",
    "#            delNNT, nnt1, lightCone, deltaLDim, convKXYZNon0, NTest = [],\n",
    "#            testConvMeasure = [], testConvMeasureNon0=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrajLearnPredAllNon0(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, seed, \\\n",
    "                     errRate=0, lightCone=0, deltaLDim=0, ifsave=0, nnt1=[], NTest=[]):\n",
    "    #d=4; learningT=d;p=0.1;circ=0; delNNT=500;nshots=5000;lightCone=0;deltaLDim=0;\n",
    "    \n",
    "    ### Args:\n",
    "    # nq = number of qubits\n",
    "    # d = depth of the circuit\n",
    "    # learningT1 = the initial time for obtaining S_Q(t)\n",
    "    # learnDelT = steps in the time vector of S_Q(t)\n",
    "    # hundredp = p*100; p= measurement rate\n",
    "    # trajNum = Number of quantum trajectories per each circuit. \n",
    "    # circ = circuit data including the unitary matrices and the measurement locations\n",
    "    # delNNT = steps in the number of samples of the input data for the neural networks. \n",
    "    # nshots = number of shots of quantum trajectories used for learning\n",
    "    # seed = the random seed for creating circuit configurations\n",
    "    # lightCone = Boolean whether or not use the light cone data\n",
    "    # deltaLDim = offset of the light cone box if lightCone==True\n",
    "    # ifsave = Boolean whether or not save the circuit configurations\n",
    "\n",
    "    p = hundredp/100;\n",
    "    print(\"p = \", p)\n",
    "    if circ==\"None\" or circ==0:\n",
    "        circ = genCircConfig(nq, d, p, seed);\n",
    "    \n",
    "    learningT2 = d+1;\n",
    "    #print(\"delNNT before = \", delNNT)\n",
    "    if delNNT==[]:\n",
    "        delNNT=.05*nshots;\n",
    "    if nnt1==[]: \n",
    "        nnt1=.9*nshots;\n",
    "    #print(\"delNNT after = \", delNNT)\n",
    "    #print(\"nshots in genTrajLearnPred = \", nshots)\n",
    "    #print(\"((nshots-nnt1)/(delNNT))=\", ((nshots-nnt1)/(delNNT)))\n",
    "    NofNTR = 1; #int(floor((nshots-nnt1)/(delNNT)))-1;\n",
    "    print(\"NofNTR in genTrajLearnPred = \", NofNTR, \", trajNum = \", trajNum)\n",
    "    learnT = np.arange(learningT1, learningT2, learnDelT);\n",
    "    #print(\"learnT = \", learnT);\n",
    "    lightCone=0; deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    \n",
    "    aveEeVecAllNon0 = np.zeros((trajNum, len(learnT)));\n",
    "    \n",
    "    exactEE = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "\n",
    "\n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "    EEZRes = np.zeros((2, len(learnT)));\n",
    "    \n",
    "    svecAveNon0 = np.zeros((3, len(learnT))); \n",
    "    \n",
    "    for trj in range(trajNum):   \n",
    "        eeVec = np.zeros(len(learnT));\n",
    "        for t in range(len(learnT)):\n",
    "            print(\"t = \", t)\n",
    "            timel = learnT[t];\n",
    "            print(\"evolving X\")\n",
    "            marrX, convKX, convKXNon0 = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"X\", nshots, errRate);\n",
    "            print(\"evolving Y\")            \n",
    "            marrY, convKY, convKYNon0 = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Y\", nshots, errRate);\n",
    "            print(\"evolving Z\")                        \n",
    "            marrZ, convKZ, convKZNon0 = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Z\", nshots, errRate);\n",
    "            #print(\"np.shape(convKX) = \", np.shape(convKX))\n",
    "            state, rhoAncilla, exactEE[t], measureArr, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots, errRate);  \n",
    "            # We use the test quantum trajectory produced in circuit X, and use it in the second two circuits.\n",
    "            #print(\"shape convKX = \", np.shape(convKX))\n",
    "            #print(\"convKX = \", convKX[:20])\n",
    "\n",
    "            convKXYZNon0 = np.zeros((nshots, 3, np.shape(convKXNon0)[1]))\n",
    "            convKXYZNon0[:, 0, :] = convKXNon0[:, :]\n",
    "            convKXYZNon0[:, 1,  :] = convKYNon0[:, :]\n",
    "            convKXYZNon0[:, 2, :] = convKZNon0[:, :]\n",
    "            print(\"\\n \\n \\n learningAllSpin \")\n",
    "\n",
    "            _, _, _, svecAllNon0 = learningAllSpinNon0(nq, timel, p, marrX, NofNTR, nshots, \n",
    "                delNNT, nnt1, lightCone, deltaLDim, convKXYZNon0, NTest, \n",
    "                testConvMeasure = [], testConvMeasureNon0=[]);\n",
    "\n",
    "            print(\"after learningAllSpin\")\n",
    "            #print(\"shape svecAllNon0 = \", np.shape(svecAllNon0))\n",
    "            \n",
    "            print(np.mean(svecAllNon0[:, 0, :], axis=1))\n",
    "            svecAveNon0[0, t] = np.mean(svecAllNon0[:, 0, :], axis=1); \n",
    "            svecAveNon0[1, t] = np.mean(svecAllNon0[:, 1, :], axis=1);\n",
    "            svecAveNon0[2, t] = np.mean(svecAllNon0[:, 2, :], axis=1);\n",
    "                                                \n",
    "            for modelCnt in range(1):\n",
    "                ee=0;\n",
    "                eeZ=0;                \n",
    "                for i in range(NTest): \n",
    "                    if modelCnt==0:                \n",
    "                        sx=svecAllNon0[0, 0, i]\n",
    "                        sy=svecAllNon0[0, 1, i]\n",
    "                        sz=svecAllNon0[0, 2, i]\n",
    "                        \n",
    "                    method=\"TNC\"; \n",
    "                    physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)        \n",
    "                \n",
    "                    if np.isnan(physden[0, 0]) or \\\n",
    "                    np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                    np.isnan(physden[1, 1]):\n",
    "                    #print(\"sx = \", sx, \", sy = \", sy, \", sz = \", sz)            \n",
    "                        method=\"nelder-mead\";\n",
    "                        physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)\n",
    "                        #print(\"physden = \", physden)\n",
    "                        if np.isnan(physden[0, 0]) or \\\n",
    "                                np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                                np.isnan(physden[1, 1]):\n",
    "                            method=\"SLSQP\";\n",
    "                            physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method);\n",
    "                            if np.isnan(physden[0, 0]) or \\\n",
    "                            np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                            np.isnan(physden[1, 1]):\n",
    "                                continue\n",
    "            \n",
    "                    partialEE = -np.trace(np.multiply(logm(physden),physden));\n",
    "                    eigval = eig(physden)[0];\n",
    "                    if eigval[0]==0:\n",
    "                        eigval[0]=1e-16;\n",
    "                    if eigval[1]==0:\n",
    "                        eigval[1]=1e-16;\n",
    "        \n",
    "                    partialee = -np.sum(np.dot(np.log2(eigval), eigval));\n",
    "                    if np.isnan(partialee):\n",
    "                        continue\n",
    "                    \n",
    "                    ee = ee+np.real(partialee/(NTest));\n",
    "                    #print(\"partialee/NTest = \", partialee/NTest);\n",
    "                    rvecNormZ = abs(sz)\n",
    "                    eigvalsDenZ = [1/2-rvecNormZ/2, 1/2+rvecNormZ/2];\n",
    "                    rhoAncillaZ = [[1/2*(1+sz), 0], [0, 1/2*(1-sz)]];                \n",
    "                    renyiInd=1;\n",
    "                    if renyiInd==1:\n",
    "                        try:\n",
    "                            partialeeZ = -np.real(sum([eigvalsDenZ[i]*np.log2((eigvalsDenZ[i])) for i in range(2)]))                \n",
    "                        except y:\n",
    "                            if isa(y, DomainError):\n",
    "                                println(\"domainError\")\n",
    "                                println(\"eigvalsDen = \", eigvalsDen)\n",
    "                                println(\"ancillaDenMat = \", ancillaDenMat)                                                \n",
    "                    \n",
    "                eeVec[t] = ee;            \n",
    "                if modelCnt==0:\n",
    "                    aveEeVecAllNon0[trj, t] = aveEeVecAllNon0[trj, t]+eeVec[t];\n",
    "\n",
    "                        \n",
    "    print(\"aveEeVecAllNon0 = \", aveEeVecAllNon0)\n",
    "    print(\"exact EE = \", np.real(exactEE));\n",
    "    \n",
    "    EERes[0, 0:len(learnT)] = aveEeVecAllNon0[0:len(learnT)];\n",
    "    EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    \n",
    "    #print(\"EERes = \", EERes);\n",
    "\n",
    "    #seconds = time.time()\n",
    "    #print(\"Seconds since epoch =\", seconds)\n",
    "    \n",
    "    df = pd.DataFrame(EERes);\n",
    "    #dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    #print(\"time =\", dt_string[-8:])\n",
    "\n",
    "    #fileOpen = open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]), \"a\")\n",
    "    #s = fileOpen.read()\n",
    "                \n",
    "    #fileOpen.write(EERes)\n",
    "    with open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)    \n",
    "    \n",
    "    with open(\"HaarSpinRes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(svecAve);\n",
    "    \n",
    "    #df.to_csv(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}-time{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]))\n",
    "        \n",
    "    return  aveEeVec, aveEeZVec, exactEE, exactEEZ\n",
    "\n",
    "#nq=4;d=3;hundredp=30;nnt1=int(0.8*Nshots)\n",
    "#Nshots=10000; errRate=0;lightCone=0; deltaLDim=0; ifsave=0;NTest=int(.2*Nshots)\n",
    "#learningT1=1;learnDelT=1;renyiInd=2;trajNum=4;circ=\"None\";delNNT=[];seed=4.25;\n",
    "#A = genTrajLearnPredAllNon0(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, \n",
    "#    Nshots, seed, errRate, lightCone, deltaLDim, ifsave, nnt1, NTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrajLearnPredParallel(nrep, nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, seed, \\\n",
    "                             errRate=0, lightCone=0, deltaLDim=0, ifsave=0,  nnt1=[], NTest=[]):\n",
    "    #print(\"nshots = \", nshots);\n",
    "    learningT2=d+1;\n",
    "    learnT = np.arange(learningT1, learningT2, learnDelT);\n",
    "    totalee=np.zeros(len(learnT));\n",
    "    totalexactee=np.zeros(len(learnT));\n",
    "    totaleeZ=np.zeros(len(learnT));\n",
    "    totalexacteeZ=np.zeros(len(learnT));\n",
    "\n",
    "    for i in range(nrep):\n",
    "        #print(\"i in nrep = \", i)\n",
    "        print(\"seed in parallel = \", seed+i)\n",
    "        seedi= seed+i;\n",
    "        aveEeVec, aveEeZVec, exactEE, exactEEZ = genTrajLearnPred(nq, d, \\\n",
    "            learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, \\\n",
    "            seedi, errRate, lightCone, deltaLDim, ifsave, nnt1, NTest);\n",
    "        print(\"aveEeVec = \", aveEeVec)\n",
    "        print(\"exactEE = \", exactEE)\n",
    "        totalee = np.add(eeVec, totalee);\n",
    "        totalexactee = np.add(exactEE, totalexactee);    \n",
    "    \n",
    "    print(\"totalee = \", totalee)\n",
    "    print(\"totalexactee = \", totalexactee)\n",
    "    return totalee, totalexactee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningGenData(nq, d, p, nshots, seed, \\\n",
    "        errRate=0, readErr=0, gate=0, allTimes=0, realT=0, learnT1=0, nnmodel=0, \\\n",
    "        nfold=1, ifremove0=0, lightCone=0, deltaLDim=0, nnt1=[], NTest=[]):\n",
    "    if lightCone: \n",
    "        ifremove0 = 1\n",
    "\n",
    "    # Here we force ifremove0 to be 1, because there is no point in using 0 measurements if we \n",
    "    \n",
    "    #(nqbit, depth, p, measureArr, convKVec, NofNTR, nshots, \n",
    "    #         nnt1, lightCone, deltaLDim, NTest = [], testConvMeasure = [], \\\n",
    "    #         modelname=\"MyResnet\")\n",
    "    \n",
    "    # Here, for training and making predictions we use data generated by noisy circuits \n",
    "    # meaning that for each realization of the trajectory we assume that the circuit has slightltly\n",
    "    # changed due to the presence of the noise.\n",
    "    #d=4; learningT=d;p=0.1;circ=0; delNNT=500;nshots=5000;lightCone=0;deltaLDim=0;\n",
    "    \n",
    "    ### Args:\n",
    "    # nq = number of qubits\n",
    "     # learningT1 = the initial time for obtaining S_Q(t)\n",
    "    # learnDelT = steps in the time vector of S_Q(t)\n",
    "    # hundredp = p*100; p= measurement rate\n",
    "    # trajNum = Number of quantum trajectories per each circuit. \n",
    "    # circ = circuit data including the unitary matrices and the measurement locations\n",
    "    # delNNT = steps in the number of samples of the input data for the neural networks. \n",
    "    # nshots = number of shots of quantum trajectories used for learning\n",
    "    # seed = the random seed for creating circuit configurations\n",
    "    # lightCone = Boolean whether or not use the light cone data\n",
    "    # deltaLDim = offset of the light cone box if lightCone==True\n",
    "    #p = hundredp/100;\n",
    "    \n",
    "    if learnT1!=0: \n",
    "        print(\"learnT1 = \", learnT1)\n",
    "        \n",
    "    if realT!=0:        \n",
    "        realTlabel = \"-learnTi{}Tf{}\".format(learnT1, realT+learnT1)\n",
    "    else:\n",
    "        realT = d; \n",
    "        realTlabel = \"\"\n",
    "    \n",
    "    print(\"realT in learningGenData= \", realT)    \n",
    "    print(\"p = \", p)\n",
    "    trajNum = 1;\n",
    "    nqbit=nq;\n",
    "    #learningT2 = d+1;\n",
    "    delNNT=.05*nshots;\n",
    "    if nnt1==[] or nnt1==0:\n",
    "        nnt1=int(0.9*nshots);\n",
    "        NTest=int(0.1*nshots);    \n",
    "    print(\"nnt1 = \", nnt1)\n",
    "\n",
    "    if gate==0:\n",
    "        gatelabel = \"\"\n",
    "    elif gate==1:\n",
    "        gatelabel = \"-CNOT\"    \n",
    "    elif gate==2:\n",
    "        gatelabel = \"-iSwap\"\n",
    "        \n",
    "    nfoldlabel = \"\";\n",
    "    if nfold!=1:\n",
    "        nfoldlabel = \"-nfold{}\".format(nfold)                \n",
    "        \n",
    "    print(\"nfold in gentraj = \", nfold)\n",
    "    print(\"nfoldlabel = \", nfoldlabel)\n",
    "    remove0label = \"\";\n",
    "    if ifremove0==1:\n",
    "        remove0label = \"-remove0\"\n",
    "    print(f\"ifremove0={ifremove0}, remove0label={remove0label}\")\n",
    "    #gatelabel, nfoldlabel        \n",
    "\n",
    "    print(f\"allTimes = {allTimes}\")\n",
    "    if not(allTimes):\n",
    "        learnT = np.arange(d, d+1)\n",
    "    else:\n",
    "        learnT = np.arange(1, d+1)\n",
    "    print(\"learnT = \", learnT)\n",
    "    \n",
    "    \n",
    "    NofNTR = 1;\n",
    "\n",
    "    deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    \n",
    "    aveEeVec = np.zeros(len(learnT));\n",
    "    exactEE = np.zeros(len(learnT));  \n",
    "    timeLrnEE = np.zeros((nshots, len(learnT)));\n",
    "    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "    aveEeZVec = np.zeros(len(learnT));\n",
    "    exactEEZ = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "    EEZRes = np.zeros((2, len(learnT)));\n",
    "    \n",
    "    eeVec = np.zeros(len(learnT)); \n",
    "    eeZVec = np.zeros(len(learnT));     \n",
    "    svecAve = np.zeros((3, len(learnT)));     \n",
    "    \n",
    "    for t in range(len(learnT)):\n",
    "        timel = learnT[t];\n",
    "        print(\"timel = \", timel);        \n",
    "        \n",
    "        convKVecX = []\n",
    "        convKVecY = []\n",
    "        convKVecZ = []\n",
    "        #state, rhoAncilla, exactEE[t], measureArr, exactEEZ[t] = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots, errRate);          \n",
    "        #for noisyshot in range(nshots):            \n",
    "        print(\"MeasureResX-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, timel, nshots, errRate, 0.0, gatelabel, nfoldlabel, seed))\n",
    "        try: \n",
    "            # We set readErr=0 for opening the files and then flip the measurement outcomes.\n",
    "            with open(\"MeasureResX-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, timel, nshots, errRate, 0.0, gatelabel, nfoldlabel, seed), 'r') as read_obj:    \n",
    "                accreader = csv.reader(read_obj, delimiter=',', quotechar=' ')\n",
    "                for row in read_obj:\n",
    "                    MeasureResX = [(float(x)) for x in (row.split())]\n",
    "            print(\"shape MeasureResX = \", np.shape(MeasureResX))\n",
    "            print(\"MeasureResX = \", MeasureResX[:20])\n",
    "            print(\"Files X Found\")                \n",
    "            with open(\"MeasureResY-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, timel, nshots, errRate, 0.0, gatelabel, nfoldlabel, seed), 'r') as read_obj:    \n",
    "                accreader = csv.reader(read_obj, delimiter=',', quotechar=' ')\n",
    "                for row in read_obj:\n",
    "                    MeasureResY = [(float(x)) for x in (row.split())]\n",
    "            print(\"Files Y Found\")        \n",
    "            with open(\"MeasureResZ-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, timel, nshots, errRate, 0.0, gatelabel, nfoldlabel, seed), 'r') as read_obj:    \n",
    "                accreader = csv.reader(read_obj, delimiter=',', quotechar=' ')\n",
    "                for row in read_obj:\n",
    "                    MeasureResZ = [(float(x)) for x in (row.split())]\n",
    "                    print(\"len(MeasureResZ)/(5000) = \", len(MeasureResZ)/(5000))\n",
    "            print(\"Files Z Found\")        \n",
    "        except:\n",
    "            print(\"Files Not Found\")\n",
    "            continue\n",
    "\n",
    "        print(\"shape convKVecZ = \", np.shape(convKVecZ))           \n",
    "        \n",
    "        if readErr!=0:\n",
    "            for i in range(3):\n",
    "                if i==0:\n",
    "                    convKVec = MeasureResX\n",
    "                elif i==1:\n",
    "                    convKVec = MeasureResY\n",
    "                elif i==2:\n",
    "                    convKVec = MeasureResZ\n",
    "                #print(\"init convKVec = \", [int(i) for i in convKVec[:40]])\n",
    "                readerrArr = np.random.uniform(0, 1, len(convKVec))\n",
    "                ref = readErr*np.ones(len(convKVec))\n",
    "                flip = (readerrArr < ref)+0\n",
    "                #print(\"flip = \", flip[:40])\n",
    "                convKVecOriginal = np.copy(convKVec)\n",
    "                for i in range(len(flip)):\n",
    "                    if i%(nqbit*timel+1)!=nqbit*timel:\n",
    "                        #print(f\"if i={i}\")\n",
    "                        convKVec[i] = int((-1)**flip[i]*convKVec[i])\n",
    "                    else:                \n",
    "                        #print(f\"else i={i}\")                        \n",
    "                        if flip[i]:\n",
    "                            convKVec[i] = int(not(convKVec[i]))            \n",
    "                if i==0:\n",
    "                    MeasureResX = convKVec\n",
    "                elif i==1:\n",
    "                    MeasureResY = convKVec\n",
    "                elif i==2:\n",
    "                    MeasureResZ = convKVec             \n",
    "                #print(\"final convKVec = \", convKVec[:40])                \n",
    "        \n",
    "        eeVec = np.zeros(len(learnT)); \n",
    "\n",
    "        # We use the test quantum trajectory produced in circuit X, and use it in the second two circuits.\n",
    "        \n",
    "        print(\"Lrn X\")\n",
    "        modelx, sxvec, testMeasX, NTest = learning(nq, timel, p, [], MeasureResX, NofNTR, nshots, \\\n",
    "                             nnt1, realT, learnT1, lightCone, deltaLDim, NTest, [], nnmodel, ifremove0);\n",
    "        print(\"Lrn Y\")        \n",
    "        modely, syvec, testMeasY, _ = learning(nq, timel, p, [], MeasureResY, NofNTR, nshots, \\\n",
    "                             nnt1, realT, learnT1, lightCone, deltaLDim, NTest, testMeasX, nnmodel, ifremove0);\n",
    "        print(\"Lrn Z\")        \n",
    "        modelz, szvec, testMeasZ, _ = learning(nq, timel, p, [], MeasureResZ, NofNTR, nshots, \\\n",
    "                             nnt1, realT, learnT1, lightCone, deltaLDim, NTest, testMeasX, nnmodel, ifremove0);\n",
    "                        \n",
    "        svec=[sxvec, syvec, szvec];\n",
    "        \n",
    "        svecAve[0, t] = np.mean(sxvec); \n",
    "        svecAve[1, t] = np.mean(syvec);\n",
    "        svecAve[2, t] = np.mean(szvec);            \n",
    "        ee=0;\n",
    "        eeZ=0;        \n",
    "        for i in range(NTest):\n",
    "            sx=sxvec[0, i]\n",
    "            sy=syvec[0, i]\n",
    "            sz=szvec[0, i]\n",
    "            method=\"TNC\";\n",
    "            physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)        \n",
    "            if np.isnan(physden[0, 0]) or \\\n",
    "            np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "            np.isnan(physden[1, 1]):\n",
    "                method=\"nelder-mead\"\n",
    "                physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)\n",
    "                #print(\"physden = \", physden)\n",
    "                if np.isnan(physden[0, 0]) or \\\n",
    "                np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                np.isnan(physden[1, 1]):\n",
    "                    method=\"SLSQP\";\n",
    "                    physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method);\n",
    "                    if np.isnan(physden[0, 0]) or \\\n",
    "                    np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                    np.isnan(physden[1, 1]):\n",
    "                        #print(\"continue\")\n",
    "                        continue\n",
    "            \n",
    "            partialEE = -np.trace(np.multiply(logm(physden),physden));\n",
    "            eigval = eig(physden)[0];\n",
    "            if eigval[0]==0:\n",
    "                eigval[0]=1e-16;\n",
    "            if eigval[1]==0:\n",
    "                eigval[1]=1e-16;\n",
    "        \n",
    "            partialee = -np.sum(np.dot(np.log2(eigval), eigval));\n",
    "            if np.isnan(partialee):\n",
    "                continue\n",
    "                    \n",
    "            ee = ee+np.real(partialee/(NTest));\n",
    "            #print(\"partialee/NTest = \", partialee/NTest);\n",
    "                \n",
    "            rvecNormZ = abs(sz)\n",
    "            eigvalsDenZ = [1/2-rvecNormZ/2, 1/2+rvecNormZ/2];\n",
    "            rhoAncillaZ = [[1/2*(1+sz), 0], [0, 1/2*(1-sz)]];                \n",
    "            renyiInd=1;\n",
    "            if renyiInd==1:\n",
    "                try:\n",
    "                    partialeeZ = -np.real(sum([eigvalsDenZ[i]*np.log2((eigvalsDenZ[i])) for i in range(2)]))                \n",
    "                except y:\n",
    "                    if isa(y, DomainError):\n",
    "                        println(\"domainError\")\n",
    "                        println(\"eigvalsDen = \", eigvalsDen)\n",
    "                        println(\"ancillaDenMat = \", ancillaDenMat)                    \n",
    "                    else:\n",
    "                        partialeeZ = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncillaZ, renyiInd)))\n",
    "                        partialeeZ = np.real(partialeeZ) \n",
    "                        \n",
    "                if partialeeZ==1:\n",
    "                    partialeeZ=1-1e-8;\n",
    "            eeZ = eeZ+np.real(partialeeZ/(NTest));\n",
    "                \n",
    "        print(\"ee. = \", ee)\n",
    "        eeVec[t] = ee;            \n",
    "        eeZVec[t] = eeZ;            \n",
    "        aveEeVec[t] = aveEeVec[t]+eeVec[t];\n",
    "        aveEeZVec[t] = aveEeZVec[t]+eeZVec[t];            \n",
    "    \n",
    "    aveEeVec=[aveEeVec[i]/trajNum for i in range(len(aveEeVec))];\n",
    "    aveEeZVec=[aveEeZVec[i]/trajNum for i in range(len(aveEeZVec))];\n",
    "    \n",
    "    print(\"aveEeVec = \",aveEeVec);        \n",
    "    print(\"exact EE = \", np.real(exactEE));\n",
    "    \n",
    "    EERes[0, 0:len(learnT)] = aveEeVec[0:len(learnT)];\n",
    "    EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "\n",
    "    EEZRes[0, 0:len(learnT)] = aveEeZVec[0:len(learnT)];\n",
    "    EEZRes[1, 0:len(learnT)] = exactEEZ[0:len(learnT)];        \n",
    "    df = pd.DataFrame(EERes);\n",
    "    \n",
    "    #fileOpen = open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]), \"a\")\n",
    "    #s = fileOpen.read()                \n",
    "    #fileOpen.write(EERes)HaarEERes \n",
    "    if nnmodel==0:\n",
    "        modelname=\"MyResnet\"    \n",
    "    elif nnmodel==1:\n",
    "        modelname=\"VIT\"\n",
    "    elif nnmodel==3:\n",
    "        modelname=\"MLP\"\n",
    "    elif nnmodel==4:\n",
    "        modelname=\"CNN\"\n",
    "    elif nnmodel==5:\n",
    "        modelname=\"RNN\"\n",
    "        \n",
    "    print(\"EERes = \", EERes)\n",
    "    if nnmodel==0: \n",
    "\n",
    "        with open(\"HaarEERes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes{}-lightCone{}{}{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, d, nshots, errRate, readErr, int(allTimes), lightCone, gatelabel, nfoldlabel, realTlabel, remove0label, seed), 'a') as f:\n",
    "            csv.writer(f, delimiter=' ').writerows(EERes)    \n",
    "    \n",
    "        with open(\"HaarSpinRes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes{}-lightCone{}{}{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, d, nshots, errRate, readErr, int(allTimes), lightCone, gatelabel, nfoldlabel, realTlabel, remove0label, seed), 'a') as f:\n",
    "            csv.writer(f, delimiter=' ').writerows(svecAve); \n",
    "    elif nnmodel!=0:\n",
    "        \n",
    "        with open(\"HaarEERes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes{}-lightCone{}-NNmodel{}{}{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, d, nshots, errRate, readErr, int(allTimes), lightCone, modelname, gatelabel, nfoldlabel, realTlabel, remove0label, seed), 'a') as f:\n",
    "            csv.writer(f, delimiter=' ').writerows(EERes)    \n",
    "    \n",
    "        with open(\"HaarSpinRes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes{}-lightCone{}-NNmodel{}{}{}{}{}-seed{}.csv\".format(nq, \\\n",
    "            p, d, nshots, errRate, readErr, int(allTimes), lightCone, modelname, gatelabel, nfoldlabel, realTlabel, remove0label, seed), 'a') as f:\n",
    "            csv.writer(f, delimiter=' ').writerows(svecAve);\n",
    "        \n",
    "    #df.to_csv(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}-time{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]))\n",
    "        \n",
    "    return aveEeVec, aveEeZVec, exactEE, exactEEZ\n",
    "\n",
    "\n",
    "#def LearningGenDataMain(args):\n",
    "def LearningGenDataMain(*args):\n",
    "    args = args[0]\n",
    "    print(f\"args = {args}\")    \n",
    "    nq, d, p, nshots, seed = int(args[0]), int(args[1]), float(args[2]), \\\n",
    "        int(args[3]), float(args[4])\n",
    "    \n",
    "    errRate = 0 if len(args)<=5 else float(args[5])\n",
    "    readErr = 0 if len(args)<=6 else float(args[6])\n",
    "    gate = 0 if len(args)<=7 else int(args[7])\n",
    "    print(f\"args[8] = {args[8]}\")\n",
    "    allTimes = 0 if len(args)<=8 else int(args[8])\n",
    "    print(f\"allTimes = {allTimes}\")\n",
    "    realT = 0 if len(args)<=9 else int(args[9])\n",
    "    learnT1 = 0 if len(args)<=10 else int(args[10])\n",
    "    nnmodel = 0 if len(args)<=11 else int(args[11])\n",
    "    nfold = 1 if len(args)<=12 else int(args[12])\n",
    "    ifremove0 = 0 if len(args)<=13 else int(args[13])\n",
    "    lightCone = 0 if len(args)<=14 else int(args[14])\n",
    "    deltaLDim = 0 if len(args)<=15 else int(args[15])\n",
    "    nnt1 = 0 if len(args)<=16 else int(args[16])\n",
    "    NTest = 0 if len(args)<=17 else int(args[17])    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"realT in LearningGenDataMain = \", realT)\n",
    "    print(\"nnmodel = \", nnmodel)\n",
    "    \n",
    "    if len(args)<=10:\n",
    "        print(\"lenss than 10\")\n",
    "        A = learningGenData(nq, d, p, nshots, seed, \\\n",
    "            errRate, readErr, gate, allTimes, realT, learnT1)\n",
    "        \n",
    "    else:\n",
    "        A = learningGenData(nq, d, p, nshots, seed, errRate, readErr, \\\n",
    "            gate, allTimes, realT, learnT1, nnmodel, nfold, ifremove0, \\\n",
    "            lightCone, deltaLDim, nnt1, NTest)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nq, d, p, nshots, seed, errRate, readErr, gate, allTimes, realT, learnT1, nnmodel, nfold, ifremove0 = \\\n",
    "    8, 6, 0.5, 5000, 23.0, 0.092, 0.0, 1, 1, 0, 0, 0, 1, 0\n",
    "args = [nq, d, p, nshots, seed, errRate, readErr, gate, allTimes, realT, learnT1, nnmodel]\n",
    "nnmodel = 0; allTimes=True; gate=1;\n",
    "#os.chdir('/Users/hosseindehghani/Desktop/Hafezi/Codes/measurementPT/Haar/');\n",
    "#A = LearningGenDataMain(args)\n",
    "#print(\"ifremoveZero = \", ifremove0)\n",
    "#A = learningGenData(nq, d, p, nshots, seed, errRate, readErr, gate=gate, \\\n",
    "#   allTimes=allTimes, realT=realT, learnT1=learnT1, nnmodel=nnmodel, \\\n",
    "#   nfold=nfold, ifremove0=ifremove0, lightCone=1, deltaLDim=0, nnt1=[], NTest=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genNoisyTrajLearnPred(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, nshots, seed, \\\n",
    "                     errRate=0, lightCone=0, deltaLDim=0, ifsave=0, nnt1=[], NTest=[]):\n",
    "    # Here, for training and making predictions we use data generated by noisy circuits \n",
    "    # meaning that for each realization of the trajectory we assume that the circuit has slightltly\n",
    "    # changed due to the presence of the noise.\n",
    "    #d=4; learningT=d; p=0.1; circ=0; delNNT=500; nshots=5000; lightCone=0; deltaLDim=0;\n",
    "    \n",
    "    ### Args:\n",
    "    # nq = number of qubits\n",
    "    # d = depth of the circuit\n",
    "    # learningT1 = the initial time for obtaining S_Q(t)\n",
    "    # learnDelT = steps in the time vector of S_Q(t)\n",
    "    # hundredp = p*100; p= measurement rate\n",
    "    # trajNum = Number of quantum trajectories per each circuit. \n",
    "    # circ = circuit data including the unitary matrices and the measurement locations\n",
    "    # delNNT = steps in the number of samples of the input data for the neural networks. \n",
    "    # nshots = number of shots of quantum trajectories used for learning\n",
    "    # seed = the random seed for creating circuit configurations\n",
    "    # lightCone = Boolean whether or not use the light cone data\n",
    "    # deltaLDim = offset of the light cone box if lightCone==True\n",
    "    # ifsave = Boolean whether or not save the circuit configurations\n",
    "    \n",
    "    p = hundredp/100;\n",
    "    print(\"p = \", p)\n",
    "    if circ==\"None\" or circ==0:\n",
    "        circ = genCircConfig(nq, d, p, seed);\n",
    "    \n",
    "    learningT2 = d+1;\n",
    "    #print(\"delNNT before = \", delNNT)\n",
    "    #if delNNT==[]:\n",
    "    delNNT=.05*nshots;nnt1=.9*nshots;\n",
    "    \n",
    "    #print(\"nshots in genTrajLearnPred = \", nshots)\n",
    "    #print(\"((nshots-nnt1)/(delNNT))=\", ((nshots-nnt1)/(delNNT)))\n",
    "    NofNTR = int(floor((nshots-nnt1)/(delNNT)))-1;\n",
    "    NofNTR = 1;\n",
    "    print(\"NofNTR in genTrajLearnPred = \", NofNTR, \", trajNum = \", trajNum)\n",
    "    learnT = np.arange(learningT1, learningT2, learnDelT);\n",
    "    print(\"learnT = \", learnT);\n",
    "    lightCone=0; deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    \n",
    "    aveEeVec = np.zeros(len(learnT));\n",
    "    exactEE = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "\n",
    "    aveEeZVec = np.zeros(len(learnT));\n",
    "    exactEEZ = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "    EEZRes = np.zeros((2, len(learnT)));\n",
    "    \n",
    "    eeVec = np.zeros(len(learnT)); \n",
    "    eeZVec = np.zeros(len(learnT));     \n",
    "    svecAve = np.zeros((3, len(learnT))); \n",
    "    #for trj in range(trajNum):   \n",
    "    #    eeVec = np.zeros(len(learnT));\n",
    "    #    eeZVec = np.zeros(len(learnT));\n",
    "          \n",
    "    for t in range(len(learnT)):\n",
    "        timel = learnT[t];\n",
    "        print(\"timel = \", timel);\n",
    "        \n",
    "        convKX = np.zeros((nshots, learnT[t]*nq+1))\n",
    "        convKY = np.zeros((nshots, learnT[t]*nq+1))\n",
    "        convKZ = np.zeros((nshots, learnT[t]*nq+1))\n",
    "\n",
    "        convKVecX = []\n",
    "        convKVecY = []\n",
    "        convKVecZ = []\n",
    "        state, rhoAncilla, exactEE[t], measureArr, exactEEZ[t] = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots, errRate);          \n",
    "        for noisyshot in range(nshots):            \n",
    "            nshot=1;        \n",
    "            marrX, tempconvKX, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"X\", nshot, errRate);\n",
    "            marrY, tempconvKY, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Y\", nshot, errRate);\n",
    "            marrZ, tempconvKZ, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Z\", nshot, errRate);\n",
    "            convKX=np.append(convKX, [tempconvKX], axis=0)\n",
    "            convKY=np.append(convKY, [tempconvKY], axis=0)\n",
    "            convKZ=np.append(convKZ, [tempconvKZ], axis=0)            \n",
    "\n",
    "            convKVecX=np.append(convKVecX, tempconvKX, axis=0)\n",
    "            convKVecY=np.append(convKVecY, tempconvKY, axis=0)\n",
    "            convKVecZ=np.append(convKVecZ, tempconvKZ, axis=0)            \n",
    "            \n",
    "        print(\"shape convKVecZ = \", np.shape(convKVecZ))           \n",
    "        eeVec = np.zeros(len(learnT)); \n",
    "\n",
    "        # We use the test quantum trajectory produced in circuit X, and use it in the second two circuits.\n",
    "\n",
    "        modelx, sxvec, testMeasX, NTest = learning(nq, timel, p, marrX, convKVecX, NofNTR, nshots, \\\n",
    "                             nnt1, lightCone, deltaLDim, NTest);        \n",
    "        modely, syvec, testMeasY, _ = learning(nq, timel, p, marrY, convKVecY, NofNTR, nshots, \\\n",
    "                             nnt1, lightCone, deltaLDim, NTest, testMeasX);\n",
    "        modelz, szvec, testMeasZ, _ = learning(nq, timel, p, marrZ, convKVecZ, NofNTR, nshots, \\\n",
    "                             nnt1, lightCone, deltaLDim, NTest, testMeasX);\n",
    "                        \n",
    "        svec=[sxvec, syvec, szvec];\n",
    "        \n",
    "        svecAve[0, t] = np.mean(sxvec); \n",
    "        svecAve[1, t] = np.mean(syvec);\n",
    "        svecAve[2, t] = np.mean(szvec);            \n",
    "        ee=0;\n",
    "        eeZ=0;        \n",
    "        for i in range(NTest):\n",
    "            sx=sxvec[0, i]\n",
    "            sy=syvec[0, i]\n",
    "            sz=szvec[0, i]\n",
    "            method=\"TNC\";\n",
    "            physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)        \n",
    "            if np.isnan(physden[0, 0]) or \\\n",
    "            np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "            np.isnan(physden[1, 1]):\n",
    "                method=\"nelder-mead\"\n",
    "                physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)\n",
    "                #print(\"physden = \", physden)\n",
    "                if np.isnan(physden[0, 0]) or \\\n",
    "                np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                np.isnan(physden[1, 1]):\n",
    "                    method=\"SLSQP\";\n",
    "                    physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method);\n",
    "                    if np.isnan(physden[0, 0]) or \\\n",
    "                    np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                    np.isnan(physden[1, 1]):\n",
    "                        #print(\"continue\")\n",
    "                        continue\n",
    "            \n",
    "            partialEE = -np.trace(np.multiply(logm(physden),physden));\n",
    "            eigval = eig(physden)[0];\n",
    "            if eigval[0]==0:\n",
    "                eigval[0]=1e-16;\n",
    "            if eigval[1]==0:\n",
    "                eigval[1]=1e-16;\n",
    "        \n",
    "            partialee = -np.sum(np.dot(np.log2(eigval), eigval));\n",
    "            if np.isnan(partialee):\n",
    "                continue\n",
    "                    \n",
    "            ee = ee+np.real(partialee/(NTest));\n",
    "            #print(\"partialee/NTest = \", partialee/NTest);\n",
    "                \n",
    "            rvecNormZ = abs(sz)\n",
    "            eigvalsDenZ = [1/2-rvecNormZ/2, 1/2+rvecNormZ/2];\n",
    "            rhoAncillaZ = [[1/2*(1+sz), 0], [0, 1/2*(1-sz)]];                \n",
    "            renyiInd=1;\n",
    "            if renyiInd==1:\n",
    "                try:\n",
    "                    partialeeZ = -np.real(sum([eigvalsDenZ[i]*np.log2((eigvalsDenZ[i])) for i in range(2)]))                \n",
    "                except y:\n",
    "                    if isa(y, DomainError):\n",
    "                        println(\"domainError\")\n",
    "                        println(\"eigvalsDen = \", eigvalsDen)\n",
    "                        println(\"ancillaDenMat = \", ancillaDenMat)                    \n",
    "                    else:\n",
    "                        partialeeZ = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncillaZ, renyiInd)))\n",
    "                        partialeeZ = np.real(partialeeZ) \n",
    "                        \n",
    "                if partialeeZ==1:\n",
    "                    partialeeZ=1-1e-8;\n",
    "            eeZ = eeZ+np.real(partialeeZ/(NTest));\n",
    "                \n",
    "        print(\"ee. = \", ee)\n",
    "        eeVec[t] = ee;            \n",
    "        eeZVec[t] = eeZ;            \n",
    "        aveEeVec[t] = aveEeVec[t]+eeVec[t];\n",
    "        aveEeZVec[t] = aveEeZVec[t]+eeZVec[t];            \n",
    "    \n",
    "    aveEeVec=[aveEeVec[i]/trajNum for i in range(len(aveEeVec))];\n",
    "    aveEeZVec=[aveEeZVec[i]/trajNum for i in range(len(aveEeZVec))];\n",
    "    \n",
    "    print(\"aveEeVec = \",aveEeVec);        \n",
    "    print(\"exact EE = \", np.real(exactEE));\n",
    "    \n",
    "    EERes[0, 0:len(learnT)] = aveEeVec[0:len(learnT)];\n",
    "    EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "\n",
    "    EEZRes[0, 0:len(learnT)] = aveEeZVec[0:len(learnT)];\n",
    "    EEZRes[1, 0:len(learnT)] = exactEEZ[0:len(learnT)];        \n",
    "    df = pd.DataFrame(EERes);\n",
    "    \n",
    "    #fileOpen = open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]), \"a\")\n",
    "    #s = fileOpen.read()\n",
    "                \n",
    "    #fileOpen.write(EERes)\n",
    "    with open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)    \n",
    "    \n",
    "    with open(\"HaarSpinRes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(svecAve);\n",
    "    \n",
    "    #df.to_csv(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}-time{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]))\n",
    "        \n",
    "    return aveEeVec, aveEeZVec, exactEE, exactEEZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq=4; d=1; learningT1=1; learnDelT=1; hundredp=30; trajNum=1; circ=\"None\"; delNNT=[];\n",
    "nshots=100; seed=1.0; errRate=0.1;lightCone=0; deltaLDim=0; ifsave=0;\n",
    "#A = genNoisyTrajLearnPred(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, nshots, seed, errRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrajLearnPredArgs(argv):\n",
    "#python HaarRandomPyHPC.py 4 6 0.1 1 1 5 0 5000 0 1 10\n",
    "#genTrajLearnPred(nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, seed, \\\n",
    "#                     lightCone=0, deltaLDim=0, ifsave=0, nnt1=[], NTest=[]):\n",
    "    print(\"learningARGS\")\n",
    "    print('Argument List:', str(argv))\n",
    "    opts, args = getopt.getopt(argv, \"hi:o:\")\n",
    "\n",
    "    nq = int(args[0]); d = int(args[1]); p = float(args[2]);\n",
    "    learningT1 = int(args[3]); learnDelT = int(args[4]);    \n",
    "    #hundredp = float(args[5]);\n",
    "    #p = hundredp/100;\n",
    "    trajNum = int(args[5]); circ = int(args[6]);\n",
    "    if circ==0:\n",
    "        circ = \"None\";\n",
    "        \n",
    "    nshots=int(args[7]); learningT2 = d+1;\n",
    "    learnT = np.arange(learningT1, learningT2, learnDelT);\n",
    "    \n",
    "    eeVec = np.zeros(len(learnT));\n",
    "    seed = float(args[8]); errRate = float(args[9]); \n",
    "    readoutErr = float(args[10]);\n",
    "    #lightCone=int(args[10]); deltaLDim=0 #int(args[12]);\n",
    "    #ifsave=int(args[11]); \n",
    "    #nnt1=int(args[12]);\n",
    "    #NTest=int(args[13]);\n",
    "    \n",
    "    if circ==\"None\":\n",
    "        if seed==0:\n",
    "            seed = random.random();\n",
    "            seed = int(floor(round(seed, 5)))\n",
    "            print(\"generated seed in args = \", int(floor(seed)))\n",
    "        circ = genCircConfig(nq, d, p, seed, ifsave);\n",
    "        \n",
    "    #delNNT=.05*nshots;\n",
    "    nnt1=int(.8*nshots);\n",
    "\n",
    "    NTest = int(0.2*nshots) #int(min(abs(nshots-nnt1), 400));\n",
    "    #NofNTR = int(floor((nshots-nnt1)/(delNNT)))-1;\n",
    "    NofNTR=1;\n",
    "    print(\"NofNTR = \", NofNTR);\n",
    "    print(\"nshots = \", nshots);\n",
    "    \n",
    "    lightCone=0; deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    svec=[0, 0, 0];\n",
    "    aveEeVec = np.zeros(len(learnT));\n",
    "    aveEeZVec = np.zeros(len(learnT));    \n",
    "    exactEE = np.zeros(len(learnT));\n",
    "    exactEEZ = np.zeros(len(learnT));\n",
    "    \n",
    "    #print(\"eeVec = \", eeVec)\n",
    "    EERes = np.zeros((2, len(learnT)));\n",
    "    EEZRes = np.zeros((2, len(learnT)));\n",
    "    svecAve = np.zeros((3, len(learnT)));\n",
    "    eeVec = np.zeros((trajNum, len(learnT))); \n",
    "    eeZVec = np.zeros((trajNum, len(learnT)));\n",
    "    \n",
    "    for trj in range(trajNum):   \n",
    "        for t in range(len(learnT)):\n",
    "            timel = learnT[t];            \n",
    "            convKX = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKY = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKZ = np.zeros((nshots, learnT[t]*nq+1))\n",
    "            convKVecX = []\n",
    "            convKVecY = []\n",
    "            convKVecZ = []\n",
    "            #state, rhoAncilla, exactEE[t], measureArr, exactEEZ[t] = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots, errRate, readoutErr);          \n",
    "            if errRate!=0:\n",
    "                #print(\"errRate not zero!\")\n",
    "                for noisyshot in range(nshots):\n",
    "                    nshot=1;        \n",
    "                    marrX, tempconvKX, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"X\", nshot, errRate, readoutErr);\n",
    "                    marrY, tempconvKY, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Y\", nshot, errRate, readoutErr);\n",
    "                    marrZ, tempconvKZ, _ = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"Z\", nshot, errRate, readoutErr);\n",
    "                    convKX=np.append(convKX, [tempconvKX], axis=0)\n",
    "                    convKY=np.append(convKY, [tempconvKY], axis=0)\n",
    "                    convKZ=np.append(convKZ, [tempconvKZ], axis=0)            \n",
    "\n",
    "                    convKVecX=np.append(convKVecX, tempconvKX, axis=0)\n",
    "                    convKVecY=np.append(convKVecY, tempconvKY, axis=0)\n",
    "                    convKVecZ=np.append(convKVecZ, tempconvKZ, axis=0)                  \n",
    "            elif errRate==0 and readoutErr==0:        \n",
    "                print(\"evolving X\");\n",
    "                print(\"{}, {}, {}, {}, {}, {}, {}, {}, {}, {}\".format(nq, timel, p, \\\n",
    "                        \"prod\", circ, 2, \"X\", nshots, errRate, readoutErr));\n",
    "                \n",
    "                marrX, convKVecX, convKXNon0 = timeEvolveAncilla(nq, timel, p, \\\n",
    "                        \"prod\", \"None\", 2, \"X\", nshots, errRate, readoutErr);\n",
    "                print(\"evolving Y\")\n",
    "                marrY, convKVecY, convKYNon0 = timeEvolveAncilla(nq, timel, p, \\\n",
    "                        \"prod\", circ, 2, \"Y\", nshots, errRate, readoutErr);\n",
    "                print(\"evolving Z\")                        \n",
    "                marrZ, convKVecZ, convKZNon0 = timeEvolveAncilla(nq, timel, p, \\\n",
    "                        \"prod\", circ, 2, \"Z\", nshots, errRate, readoutErr);\n",
    "                            \n",
    "            #print(\"t = \", t)    \n",
    "            # We use the test quantum trajectory produced in circuit X, and use it in the second two circuits.\n",
    "           \n",
    "            print(\"shape convKVecZ = \", np.shape(convKVecZ))                       \n",
    "\n",
    "            modelx, sxvec, testMeasX, NTest = learning(nq, timel, p, marrX, convKVecX, NofNTR, nshots, \\\n",
    "                                 nnt1, lightCone, deltaLDim, NTest);        \n",
    "            modely, syvec, testMeasY, _ = learning(nq, timel, p, marrY, convKVecY, NofNTR, nshots, \\\n",
    "                                 nnt1, lightCone, deltaLDim, NTest, testMeasX);\n",
    "            modelz, szvec, testMeasZ, _ = learning(nq, timel, p, marrZ, convKVecZ, NofNTR, nshots, \\\n",
    "                                 nnt1, lightCone, deltaLDim, NTest, testMeasX);\n",
    "                        \n",
    "            svec=[sxvec, syvec, szvec];\n",
    "        \n",
    "            svecAve[0, t] = np.mean(sxvec);\n",
    "            svecAve[1, t] = np.mean(syvec);\n",
    "            svecAve[2, t] = np.mean(szvec);\n",
    "            ee=0;\n",
    "            eeZ=0;\n",
    "            for modelCnt in range(1):\n",
    "                ee=0;\n",
    "                eeZ=0;                \n",
    "                for i in range(NTest):\n",
    "                    if modelCnt==0:\n",
    "                        sx=sxvec[0, i]\n",
    "                        sy=syvec[0, i]\n",
    "                        sz=szvec[0, i]\n",
    "                    method=\"TNC\"; \n",
    "                    physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)        \n",
    "                \n",
    "                    if np.isnan(physden[0, 0]) or \\\n",
    "                    np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                    np.isnan(physden[1, 1]):\n",
    "            \n",
    "                        method=\"nelder-mead\"\n",
    "                        physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method)\n",
    "                        #print(\"physden = \", physden)\n",
    "                        if np.isnan(physden[0, 0]) or \\\n",
    "                        np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                        np.isnan(physden[1, 1]):\n",
    "                            method=\"SLSQP\";\n",
    "                            physden, tempresx, tempres=maxLikelihoodDen(sx, sy, sz, method);\n",
    "                            if np.isnan(physden[0, 0]) or \\\n",
    "                            np.isnan(physden[1, 0]) or np.isnan(physden[0, 1]) or \\\n",
    "                            np.isnan(physden[1, 1]):\n",
    "                            #print(\"continue\")\n",
    "                                continue\n",
    "            \n",
    "                    partialEE = -np.trace(np.multiply(logm(physden),physden));\n",
    "                    eigval = eig(physden)[0];\n",
    "                    if eigval[0]==0:\n",
    "                        eigval[0]=1e-16;\n",
    "                    if eigval[1]==0:\n",
    "                        eigval[1]=1e-16;\n",
    "        \n",
    "                    partialee = -np.sum(np.dot(np.log2(eigval), eigval));\n",
    "                    if np.isnan(partialee):\n",
    "                        continue\n",
    "                    \n",
    "                    ee = ee+np.real(partialee/(NTest));\n",
    "                    #print(\"partialee/NTest = \", partialee/NTest);\n",
    "                    rvecNormZ = abs(sz)\n",
    "                    eigvalsDenZ = [1/2-rvecNormZ/2, 1/2+rvecNormZ/2];\n",
    "                    rhoAncillaZ = [[1/2*(1+sz), 0], [0, 1/2*(1-sz)]];                \n",
    "                    renyiInd=1;\n",
    "                    if renyiInd==1:\n",
    "                        try:\n",
    "                            partialeeZ = -np.real(sum([eigvalsDenZ[i]*np.log2((eigvalsDenZ[i])) for i in range(2)]))                \n",
    "                        except y:\n",
    "                            if isa(y, DomainError):\n",
    "                                println(\"domainError\")\n",
    "                                println(\"eigvalsDen = \", eigvalsDen)\n",
    "                                println(\"ancillaDenMat = \", ancillaDenMat)                    \n",
    "                            else:\n",
    "                                partialeeZ = 1/(1-renyiInd) * np.log2(np.trace(matrix_power(rhoAncillaZ, renyiInd)))\n",
    "                                partialeeZ = np.real(partialeeZ) \n",
    "                            \n",
    "                        if partialeeZ==1:\n",
    "                            partialeeZ=1-1e-8;\n",
    "                    eeZ = eeZ+np.real(partialeeZ/(NTest));                    \n",
    "                    \n",
    "                eeVec[trj, t] = \"{:.8e}\".format(ee);          \n",
    "                eeZVec[trj, t] = \"{:.8e}\".format(eeZ);          \n",
    "                \n",
    "                if modelCnt==0:\n",
    "                    aveEeVec[t] = aveEeVec[t]+eeVec[trj, t];\n",
    "                    aveEeZVec[t] = aveEeZVec[t]+eeZVec[trj, t];            \n",
    "\n",
    "    aveEeVec=[aveEeVec[i]/trajNum for i in range(len(aveEeVec))];\n",
    "    aveEeZVec=[aveEeZVec[i]/trajNum for i in range(len(aveEeZVec))];\n",
    "    \n",
    "    print(\"aveEeVec = \",aveEeVec);\n",
    "    print(\"exact EE = \", np.real(exactEE));\n",
    "                \n",
    "    aveEeVec = [\"{:.8e}\".format(aveEeVec[i]) for i in range(len(aveEeVec))]\n",
    "    aveEeZVec = [\"{:.8e}\".format(aveEeZVec[i]) for i in range(len(aveEeZVec))]\n",
    "    \n",
    "    exactEE = [\"{:.8e}\".format(exactEE[i]) for i in range(len(exactEE))]\n",
    "    exactEEZ = [\"{:.8e}\".format(exactEEZ[i]) for i in range(len(exactEEZ))]    \n",
    "\n",
    "    print(\"aveEeVec after = \",aveEeVec)       \n",
    "    print(\"exact EE = \", np.real(exactEE))\n",
    "    \n",
    "    EERes[0, 0:len(learnT)] = aveEeVec[0:len(learnT)];\n",
    "    EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    \n",
    "    \n",
    "    with open(\"HaarEEPerTraj-nq{}-p{}-ti{}-tf{}-trjNum{}-lightCone{}-nshots{}-errRate{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, trajNum, lightCone, nshots, errRate, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(eeVec)        \n",
    "    \n",
    "    df = pd.DataFrame(EERes);\n",
    "    with open(\"HaarAveEE-nq{}-p{}-ti{}-tf{}-trjNum{}-lightCone{}-nshots{}-errRate{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, trajNum, lightCone, nshots, errRate, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)\n",
    "\n",
    "    #df = pd.DataFrame(EEZRes);\n",
    "    #with open(\"HaarEEZRes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "    #    csv.writer(f, delimiter=' ').writerows(EEZRes)    \n",
    "        \n",
    "    with open(\"HaarSpinRes-nq{}-p{}-ti{}-tf{}-trjNum{}-lightCone{}-nshots{}-errRate{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, trajNum, lightCone, nshots, errRate, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(svecAve);\n",
    "        \n",
    "        \n",
    "    return circ, svec, eeVec, eeZVec\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def genTrajExactPred(nq, d, T1, DelT, hundredp, trajNum, circ, nshots, seed, ifsave=0):\n",
    "    \n",
    "    #d=4; learningT=d;p=0.1;circ=0; delNNT=500;nshots=5000;lightCone=0;deltaLDim=0;\n",
    "    \n",
    "    ### Args:\n",
    "    # nq = number of qubits\n",
    "    # trajNum = Number of quantum trajectories per each circuit. \n",
    "\n",
    "    \n",
    "    p = hundredp/100;\n",
    "    #print(\"p = \", p)\n",
    "    if circ==\"None\" or circ==0:\n",
    "        circ = genCircConfig(nq, d, p, seed);\n",
    "    \n",
    "    T2 = d+1;\n",
    "    delNNT=.05*nshots;nnt1=.9*nshots;\n",
    "    NofNTR = int(floor((nshots-nnt1)/(delNNT)))-1;\n",
    "    learnT = np.arange(T1, T2, DelT);\n",
    "    #print(\"learnT = \", learnT);\n",
    "    lightCone=0; deltaLDim=0;\n",
    "    middleInd=int(float(nq/2));\n",
    "    \n",
    "\n",
    "    exactEE = np.zeros(len(learnT));    \n",
    "    EERes = np.zeros((1, len(learnT)));\n",
    "\n",
    "    exactEEz = np.zeros(len(learnT));    \n",
    "    EEResZ = np.zeros((1, len(learnT)));\n",
    "    \n",
    "    for trj in range(trajNum):   \n",
    "        eeVec = np.zeros(len(learnT));\n",
    "        for t in range(len(learnT)):    #if True:         \n",
    "            #print(\"t = \", t)    \n",
    "            timel = learnT[t];\n",
    "            \n",
    "        \n",
    "            state, rhoAncilla, tempEE, measureArr, tempEEz = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots);        \n",
    "            exactEE[t] = exactEE[t] + tempEE; \n",
    "            exactEEz[t] = exactEEz[t] + tempEEz; \n",
    "        print(\"exactEE = \",exactEE)        \n",
    "        print(\"exactEEz = \",exactEEz)                    \n",
    "        \n",
    "    exactEE=[exactEE[i]/trajNum for i in range(len(exactEE))];\n",
    "    exactEEz=[exactEEz[i]/trajNum for i in range(len(exactEEz))];\n",
    "    \n",
    "    print(\"exact EE = \", np.real(exactEE))\n",
    "    print(\"exact EEz = \", np.real(exactEEz))    \n",
    "\n",
    "    #return circ, svec, eeVec\n",
    "        \n",
    "    EERes[0, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    EEResZ[0, 0:len(learnT)] = exactEEz[0:len(learnT)];    \n",
    "    #EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    \n",
    "    #print(\"len(EERes) = \", len(EERes))\n",
    "    #seconds = time.time()\n",
    "    #print(\"Seconds since epoch =\", seconds)\t\n",
    "    \n",
    "    df = pd.DataFrame(EERes);\n",
    "    with open(\"HaarExactEERes-nq{}-p{}-ti{}-tf{}-delT{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, T1, T2, DelT, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)   \n",
    "        \n",
    "    df = pd.DataFrame(EERes);        \n",
    "    with open(\"HaarExactEEResZ-nq{}-p{}-ti{}-tf{}-delT{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, T1, T2, DelT, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EEResZ)   \n",
    "    \n",
    "    \n",
    "    return exactEE, exactEEz\n",
    "\n",
    "\n",
    "\n",
    "def genTrajExactPredParallel(nrep, nq, d, T1, DelT, hundredp, trajNum, circ, nshots, seed, \\\n",
    "                             lightCone=0, deltaLDim=0, ifsave=0):\n",
    "    T2=d+1;\n",
    "    learnT = np.arange(T1, learningT2, learnDelT);\n",
    "    #print(\"learnT = \", learnT)\n",
    "    totalee=np.zeros(len(learnT));\n",
    "    totalexactee=np.zeros(len(learnT));\n",
    "        \n",
    "    for i in range(nrep):\n",
    "        print(\"i in nrep = \", i)\n",
    "        #seed = seed+i                \n",
    "        print(\"seed in parallel = \", seed+i)\n",
    "        eeVec, tempexactee = genTrajLearnPred(nq, d, learningT1, learnDelT, hundredp, trajNum, \n",
    "                            circ, delNNT, nshots, seed, lightCone, deltaLDim, ifsave, delNNT, nnt1, NTest);                              \n",
    "        #print(\"totalee = \", totalee);\n",
    "        #print(\"eeVec = \", eeVec);\n",
    "        totalee = np.add(eeVec, totalee);\n",
    "        totalexactee = np.add(tempexactee, totalexactee);    \n",
    "    \n",
    "    print(\"totalee = \", totalee)\n",
    "    print(\"totalexactee = \", totalexactee)\n",
    "    return totalee, totalexactee\n",
    "\n",
    "def genTrajExactPredArgs(argv):\n",
    "#    (nq, d, p, circ, delNNT, nshots, lightCone=0, deltaLDim=0):\n",
    "    print(\"learningARGS\")    \n",
    "    print('Argument List:', str(argv))\n",
    "    opts, args = getopt.getopt(argv, \"hi:o:\")\n",
    "\n",
    "    nq = int(args[0]);\n",
    "    d = int(args[1]);\n",
    "    p = float(args[2]);\n",
    "    T1 = int(args[3]);\n",
    "    DelT = int(args[4]);    \n",
    "    #hundredp = float(args[5]);    \n",
    "    #p = hundredp/100;\n",
    "    trajNum = int(args[5]);    \n",
    "    circ = int(args[6]);\n",
    "    if circ==0:\n",
    "        circ = \"None\"; \n",
    "        \n",
    "    nshots=int(args[7]);\n",
    "    T2 = d+1;\n",
    "    learnT = np.arange(T1, T2, DelT);\n",
    "    \n",
    "    eeVec = np.zeros(len(learnT))\n",
    "    \n",
    "    seed = float(args[8]);\n",
    "    ifsave=int(args[9]);    \n",
    "    \n",
    "    if circ==\"None\":\n",
    "        if seed==0:\n",
    "            seed = random.random();\n",
    "            seed = round(seed, 5)                        \n",
    "        circ = genCircConfig(nq, d, p, seed, ifsave);\n",
    "\n",
    "    #print(\"nshots = \", nshots)\n",
    "    \n",
    "    for trj in range(trajNum):   \n",
    "        eeVec = np.zeros(len(learnT));\n",
    "        for t in range(len(learnT)):    #if True:         \n",
    "            #print(\"t = \", t)    \n",
    "            timel = learnT[t];\n",
    "            \n",
    "        \n",
    "            state, rhoAncilla, tempEE, measureArr, tempEEz = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots);        \n",
    "            state, rhoAncilla, tempEE, measureArr, tempEEz = timeEvolveAncilla(nq, timel, p, \"prod\", circ, 2, \"None\", nshots);                    \n",
    "\n",
    "            exactEE[t] = exactEE[t] + tempEE; \n",
    "            exactEEz[t] = exactEEz[t] + tempEEz;\n",
    "            \n",
    "        print(\"exactEE = \",exactEE)        \n",
    "        print(\"exactEEz = \",exactEEz)                \n",
    "            \n",
    "    exactEE=[exactEE[i]/trajNum for i in range(len(exactEE))];\n",
    "    exactEEz=[exactEEz[i]/trajNum for i in range(len(exactEEz))];    \n",
    "    print(\"exact EE = \", np.real(exactEE))\n",
    "    print(\"exact EEz = \", np.real(exactEEz))\n",
    "    \n",
    "    #return circ, svec, eeVec\n",
    "        \n",
    "    EERes[0, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    EEResZ[0, 0:len(learnT)] = exactEEz[0:len(learnT)];\n",
    "    #EERes[1, 0:len(learnT)] = exactEE[0:len(learnT)];\n",
    "    \n",
    "    print(\"len(EERes) = \", len(EERes))\n",
    "    #seconds = time.time()\n",
    "    #print(\"Seconds since epoch =\", seconds)\n",
    "    \n",
    "    df = pd.DataFrame(EERes);\n",
    "    with open(\"HaarExactEERes-nq{}-p{}-ti{}-tf{}-delT{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, T1, T2, DelT, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)   \n",
    "    \n",
    "    df = pd.DataFrame(EEResZ);\n",
    "    with open(\"HaarExactEEResZ-nq{}-p{}-ti{}-tf{}-delT{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, T1, T2, DelT, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EEResZ)   \n",
    "    return exactEE, exactEEz\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delNNT=.05*nshots;nnt1=.9*nshots;NofNTR = int(floor((nshots-nnt1)/(delNNT)))-1\n",
    "#lightCone=0; deltaLDim=0; middleInd=int(float(nq/2));\n",
    "\n",
    "#nq=4; d=4; p=.5; seed=1;\n",
    "#circ, _ = genCircConfig(nq, d, p, seed);\n",
    "#counts, convK, marr\n",
    "#nshots=1000;renyiInd=2;refQbitAxis=\"None\";\n",
    "\"\"\"\n",
    "marrX, convKX, countsY = timeEvolveAncilla(nq, d, p, \"prod\", circ, renyiInd, \"X\", nshots);\n",
    "marrY, convKY, countsY = timeEvolveAncilla(nq, d, p, \"prod\", circ, renyiInd, \"Y\", nshots);\n",
    "marrZ, convKZ, countsZ = timeEvolveAncilla(nq, d, p, \"prod\", circ, renyiInd, \"Z\", nshots);\n",
    "\n",
    "model, sigmaPredict, NTest, testConvMeasure = learning(nq, d, p, marrX, convKX, countsX, NofNTR, nshots, \\\n",
    "             nnt1, lightCone, deltaLDim, middleInd)\n",
    "model, sigmaPredict, NTest, testConvMeasure = learning(nq, d, p, marrZ, convKZ, countsZ, NofNTR, nshots, \\\n",
    "             nnt1, lightCone, deltaLDim, middleInd)\n",
    "model, sigmaPredict, NTest, testConvMeasure = learning(nq, d, p, marrY, convKY, countsY, NofNTR, nshots, \\\n",
    "             nnt1, lightCone, deltaLDim, middleInd)\n",
    "#\"\"\";\n",
    "# return measureArr, convKVec, counts\n",
    "#dstate, rhoAncilla, renyiEnt, measureArr, renyiEntZ = timeEvolveAncilla(nqbit, circDep, p, initStateLabel, circConfig, renyiInd, refQbitAxis, Nshots, errRate=0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '/Users/hosseindehghani/Library/Jupyter/runtime/kernel-4d6400c1-d655-466f-b582-1385360e2f3d.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-8c1b5c181ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nprocess = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#pool = Pool(processes=nprocess)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/Users/hosseindehghani/Library/Jupyter/runtime/kernel-4d6400c1-d655-466f-b582-1385360e2f3d.json'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    nprocess = int(float(sys.argv[-1]))\n",
    "    print(\"nprocess = \", nprocess)\n",
    "    #pool = Pool(processes=nprocess)        \n",
    "    cvec = []\n",
    "    if sys.argv[-2]== \"False\":\n",
    "        print(\"cvec = False.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"else cvec==False\")\n",
    "        cvecstr = sys.argv[-2].split(',')\n",
    "    \n",
    "        for i in cvecstr:\n",
    "            print(\"i = \", i)\n",
    "            cvec.append(int(float(i)))\n",
    "    print(\"main cvec = \", cvec)            \n",
    "    \n",
    "    \n",
    "    argsarr = [];\n",
    "    for i in range(nprocess):\n",
    "        argsarr.append(sys.argv[1:-1])\n",
    "        #argsarr.append(sys.argv[1:-2])\n",
    "        #argsarr[-1].append(str(cvec[i]))\n",
    "    \n",
    "    print(\"argsarr = \", argsarr)\n",
    "    \n",
    "    LearningGenDataMain(sys.argv[1:-1])\n",
    "    \n",
    "    #pool.map(genTrajLearnPredArgs, argsarr)    \n",
    "    #pool.map(genTrajArgsv2, argsarr)    \n",
    "        \n",
    "    #print(\"GeneratingData\")    \n",
    "    #print('Argument List:', str(argv))\n",
    "    #opts, args = getopt.getopt(argv, \"hi:o:\")\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":  # confirms that the code is under main function\n",
    "    names = ['America', 'Europe', 'Africa']\n",
    "    procs = []\n",
    "    proc = Process(target=print_func)  # instantiating without any argument\n",
    "    procs.append(proc)\n",
    "    proc.start()\n",
    "\n",
    "    # instantiating process with arguments\n",
    "    for name in names:\n",
    "        # print(name)\n",
    "        proc = Process(target=print_func, args=(name,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "\n",
    "    # complete the processes\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n=1; nq=8; d=4; hundredp=50;circ=0; trajNum=1;\n",
    "lightCone=0;lc=lightCone;deltaLDim=0;p=hundredp/100;circ = 0;nshots=2000;\n",
    "delNNT=[];NofNTR = 1; NTest=[];\n",
    "# Each processor has a different circuit. For each processor we have \"n\"\n",
    "#print(f'You have {npr} cores')\n",
    "learningT1=d-2; learningT2= d+1; learnDelT=1; ifsave=1;\n",
    "learnT = np.arange(learningT1, learningT2, learnDelT);\n",
    "inputdata=[n, nq, d, learningT1, learnDelT, hundredp, trajNum, \\\n",
    "           circ, delNNT, nshots, seed, lightCone, deltaLDim, ifsave];\n",
    "inputmat = np.zeros((npr, len(inputdata)), dtype=int);\n",
    "eeVec=0; eeVecZ=0; \n",
    "exactee=np.zeros((d)); exacteeZ=np.zeros((d));\n",
    "print(\"nshots = \", nshots)\n",
    "numseed = 20;\n",
    "errRate=0;\n",
    "seed = random.random();\n",
    "seed = round(seed, 5);\n",
    "seed = np.arange(0, 20, step=1); seed= [i+0.05 for i in seed]\n",
    "print(\"seed = \", seed)\n",
    "aveevec = np.zeros(np.shape(learnT))\n",
    "exactee = np.zeros(np.shape(learnT))\n",
    "EERes = np.zeros((2, np.shape(learnT)[0]))\n",
    "#def main():\n",
    "if True:\n",
    "    start = timer()    \n",
    "    #with Pool(processes=npr) as pool:    \n",
    "    for ns in range(numseed):\n",
    "        print(\"seed = \", seed);\n",
    "        measureArr, unitaryArr = genCircConfig(nq, d, p, seed[ns], 1);\n",
    "        path = Path('~/Desktop/Hafezi/Codes/Haar/').expanduser();\n",
    "\n",
    "        path.mkdir(parents=True, exist_ok=True);\n",
    "\n",
    "        measureloaded = np.load(path/\"measure-nq{}-depth{}-p{}-seed{}.npy\".format(nq, \\\n",
    "            d, p, seed[ns]))\n",
    "        unitaryloaded = np.load(path/\"unitary-nq{}-depth{}-p{}-seed{}.npy\".format(nq, \\\n",
    "            d, p, seed[ns]))\n",
    "        circ={}\n",
    "        circ[0] = measureloaded;\n",
    "        circ[1] = unitaryloaded;\n",
    "        \n",
    "        #for i in range(npr):\n",
    "        #    inputdata=[n, nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, \\\n",
    "        #               seed, lightCone, deltaLDim, ifsave];            \n",
    "        #    inputmat[i, 0:len(inputdata)] = inputdata;                \n",
    "        #inputdata=[1, nq, d, learningT1, learnDelT, hundredp, trajNum, circ, delNNT, nshots, seed, \\\n",
    "        #lightCone, deltaLDim, ifsave];\n",
    "        \n",
    "        #exactee, exacteeZ = genTrajLearnPredParallel(nrep, nq, d, learningT1, learnDelT, \\\n",
    "        #hundredp, trajNum, circ, delNNT, nshots, seed, lc, deltaLDim,ifsave,nnt1,NTest);\n",
    "        tempaveevec, _, tempexactee, _ = genTrajLearnPred(nq, d, learningT1, learnDelT, \\\n",
    "        hundredp, trajNum, circ, delNNT, nshots, seed, errRate, lc, deltaLDim,ifsave,nnt1,NTest);\n",
    "    \n",
    "        aveevec = np.add(aveevec, tempaveevec)                    \n",
    "        exactee = np.add(exactee, tempexactee)\n",
    "        end = timer()        \n",
    "    EERes[0, :] = aveevec[:]\n",
    "    EERes[1, :] = exactee[:]    \n",
    "    df = pd.DataFrame(EERes);    \n",
    "    df.to_csv(\"HaarEERes-nq{}-p{}-npr{}-nrep{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, npr, n, learningT1, learningT2, learnDelT, lightCone, nshots, seed))\n",
    "    \n",
    "#if __name__=='__main__':\n",
    "#    main();\n",
    "line1 = plt.plot(exactee, 'r*-');\n",
    "line1 = plt.plot(aveevec, 'b*-');\n",
    "plt.show();\n",
    "\"\"\";\n",
    "#aveEeVec =  [0.9764309956239562, 0.9793401454389833, 0.9287384211720814]\n",
    "#exact EE =  [0.88070163 0.88070163 0.27325468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n=1; nq=6; d=6; hundredp=10;circ=0; trajNum=10; delNNT=500;nshots=5000;\n",
    "lightCone=0;deltaLDim=0;p=hundredp/100;circ = 0;\n",
    "delNNT=.05*nshots;nnt1=.9*nshots;NofNTR = int(np.floor((nshots-nnt1)/(delNNT)))-1;\n",
    "#print(\"NofNTR = \", NofNTR);\n",
    "seed=0.4567;T1=1;DelT=1;\n",
    "\n",
    "#A = genTrajExactPred(nq, d, T1, DelT, hundredp, trajNum, circ, nshots, seed, ifsave=0);\n",
    "\n",
    "seedvec = np.arange(0.0, 0.2, 0.005)\n",
    "exactEE = np.zeros(d);\n",
    "\n",
    "exactEEz = np.zeros(d);\n",
    "\n",
    "\n",
    "for i in range(len(seedvec)):\n",
    "    seed = seedvec[i]\n",
    "    print(\"seed = \", seed)\n",
    "    A, Az = genTrajExactPred(nq, d, T1, DelT, hundredp, trajNum, circ, nshots, seed, ifsave=0);    \n",
    "    exactEE = np.add(A, exactEE)\n",
    "    exactEEz = np.add(Az, exactEEz)    \n",
    "    print(exactEE)\n",
    "    print(exactEEz)    \n",
    "    #d=4; learningT=d;p=0.1;circ=0; delNNT=500;nshots=5000;lightCone=0;deltaLDim=0;    \n",
    "    \n",
    "\n",
    "exactEE = [exactEE[i]/len(seedvec) for i in range(len(exactEE))];\n",
    "exactEEz = [exactEEz[i]/len(seedvec) for i in range(len(exactEEz))];\n",
    "line1 = plt.plot(exactEE, 'r*-')\n",
    "line2 = plt.plot(exactEEz, 'b*-')\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "ncirc=1;\n",
    "for i in range(ncirc):\n",
    "    print(\"i= \", i, \"\\n\")\n",
    "    circ, svec, eel10p0p1[i] = genTrajLearnPred(nq, d, p, \"None\", delNNT, nshots, lightCone=0, deltaLDim=0)    \n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sbatch -A hafezi-prj-jqi -t 2:0:0 haar0p1.sh\n",
    "sbatch -A hafezi-prj-jqi -t 2:0:0 haar0p1.sh\n",
    "sbatch -A hafezi-prj-jqi -t 2:0:0 haar0p1.sh\n",
    "sbatch -A hafezi-prj-jqi -t 2:0:0 haar0p1.sh\n",
    "sbatch -A hafezi-prj-jqi -t 2:0:0 haar0p1.sh        \n",
    "\n",
    "\n",
    "plt.plot([exactEE[i]/50 for i in range(len(exactEE))])\n",
    "print([exactEE[i]/50 for i in range(len(exactEE))])\n",
    "\n",
    "plt.title(\"Ancilla qubit entanglement entropy in Haar circuits\")\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"S_Q\")\n",
    "B = [41.37359323, 34.76964592, 30.4809303,  28.20043325, 25.68580567, 23.80037617]\n",
    "A = [41.29700103, 34.44714994, 30.27757756, 27.89913117, 26.08700539, 23.88106039];\n",
    "A = [A[i]/50 for i in range(len(A))]\n",
    "B = [B[i]/50 for i in range(len(B))]\n",
    "#print(A)\n",
    "line1 = plt.plot(A, 'r*-')\n",
    "line2 = plt.plot(B, 'b*-')\n",
    "#plt.legend(handles=[line1])\n",
    "\n",
    "seedvec = np.linspace(1.0, 3.0, 200);  #   np.arange(seedmin, seedmax, deltaseed);\n",
    "seedvec = [np.round(seed, 2) for seed in seedvec]\n",
    "#print(\"seedvec = \", seedvec)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwdir =  /Users/hosseindehghani/Desktop/Hafezi/Codes/MeasurementPT/Haar\n",
      "nfoldlabel =  \n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed117.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed152.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed192.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed35.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed70.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed11.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed54.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed94.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed69.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed133.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed176.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed131.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed174.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed189.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed96.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed9.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed13.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed56.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed149.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed37.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed72.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed128.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed190.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed115.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed150.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed194.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed33.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed76.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed169.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed111.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed154.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed92.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed135.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed170.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed17.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed52.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed108.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed15.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed50.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed28.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed137.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed172.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed90.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed49.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed113.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed156.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed31.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed74.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed196.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed89.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed8.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed57.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed12.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed148.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed175.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed130.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed188.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed97.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed151.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed114.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed73.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed36.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed129.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed191.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed193.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed71.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed34.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed153.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed116.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed95.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed68.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed177.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed132.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed55.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed10.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed29.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed173.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed136.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed91.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed51.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed14.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed75.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed30.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed197.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed88.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed48.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed157.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed112.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed155.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed110.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed195.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed77.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed32.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed168.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed53.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed16.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed109.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed93.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed171.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed134.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed180.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed138.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed27.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed62.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed105.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed140.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed86.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed199.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed121.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed164.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed159.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed46.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed44.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed123.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed166.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed79.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed84.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed2.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed107.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed142.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed18.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed25.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed60.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed182.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed103.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed146.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed59.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed6.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed99.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed186.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed21.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed64.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed40.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed80.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed127.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed162.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed38.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed125.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed160.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed82.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed118.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed42.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed179.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed23.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed66.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed184.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed200.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed4.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed101.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed144.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed167.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed122.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed78.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed85.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed45.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed61.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed24.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed183.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed3.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed143.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed106.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed19.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed141.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed104.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed1.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed181.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed139.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed63.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed26.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed158.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed47.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed87.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed198.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed165.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed120.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed119.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed43.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed161.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed124.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed83.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed5.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed145.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed100.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed178.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed67.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed22.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed185.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed98.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed187.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed65.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed20.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed147.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed102.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed58.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed7.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed81.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed163.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed126.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed39.0.csv\n",
      "filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed41.0.csv\n",
      "EEP Before scaling =  [[  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [177.61429909 169.16394479 155.95888653 153.80817958 145.84832951\n",
      "  140.53607458   0.           0.        ]]\n",
      "EEP =  [array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0.8880715 , 0.84581972, 0.77979443, 0.7690409 , 0.72924165,\n",
      "       0.70268037, 0.        , 0.        ])]\n",
      "EETraj[0] =  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "totalNAfter =  200.0\n",
      "EEP[0] =  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "EEP[1] =  [0.8880715  0.84581972 0.77979443 0.7690409  0.72924165 0.70268037\n",
      " 0.         0.        ]\n",
      "EEP0.05L4d0.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'EEP0.05L4d0.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-4bafc49f2357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m#meanLrn = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, e)][0]), 0, 1, axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EEP{}L{}d{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mmeanLrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"EEP{}L{}d{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m#for i in range(1, np.shape(meanLrn)[0]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m#    if meanLrn[i]>meanLrn[i-1]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'EEP0.05L4d0.0'"
     ]
    }
   ],
   "source": [
    "def readEEResultsFiles():\n",
    "    return 1\n",
    "\n",
    "cwdir = os.getcwd()\n",
    "print(\"cwdir = \", cwdir)\n",
    "#seedvec = np.arange(0.1, 1.05, 0.05)\n",
    "#seedvec = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, \\\n",
    "#           0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
    "\n",
    "os.chdir('/Users/hosseindehghani/Desktop/Hafezi/Codes/measurementPT/Haar/');\n",
    "read=True; rowc=0; rowinside=0; i=0;\n",
    "axis_font = {'fontname':'Times New Roman', 'size':'18'}\n",
    "#seedvec = np.linspace(1, 5.0, 400);  #   np.arange(seedmin, seedmax, deltaseed);\n",
    "\n",
    "#\n",
    "T1=1;DelT=1;seedmin=0.01;seedmax=2.01;nseed=51;\n",
    "seedvec = np.linspace(seedmin, seedmax, nseed); \n",
    "seedvec = [np.round(seed, 2) for seed in seedvec];\n",
    "\n",
    "read=True;\n",
    "#pvec=[0.05, 0.1, 0.15, 0.2, 0.25, 0.3];\n",
    "#nq=4; t1=0; d=6; t2=d+1; delT=1;\n",
    "nshots=50000;p=0.1;\n",
    "pvec = [p]\n",
    "tvec = np.linspace(0, d+1, d+1);\n",
    "#HaarEERes-nq6-p0.3-ti1-tf7-delT1-lightCone0-nshots2000-seed0.50277.csv\n",
    "#maxRow = 40;\n",
    "maxRow = 1;\n",
    "trajNum=1;#totalNBefore = (len(seedvec))*maxRow;\n",
    "totalNBefore=10*10000;errRate=0.0;readErr=0.0;\n",
    "nfold=1;allTimes=1;lightCone=1;\n",
    "nfoldlabel = \"\";\n",
    "if nfold!=1:\n",
    "    nfoldlabel = \"nfold{}-\".format(nfold)\n",
    "print(\"nfoldlabel = \", nfoldlabel)\n",
    "    \n",
    "#filename =  HaarEERes-nq8-p0.1-d6-nshots5000-errRate0.092-readErr0.0-allTimes1-lightCone0-CNOT-seed82.0.csv\n",
    "#HaarAveEE-nq4-p0.1-ti1-tf7-trjNum5-lightCone0-nshots5000-errRate0.0-seed0.69982\n",
    "\n",
    "#filename= \"HaarAveEE-nq{}-p{}-ti{}-tf{}-trjNum{}-lightCone{}-nshots{}-errRate{}-\".format(nq, \\\n",
    "#                p, t1, t2, trajNum, lightCone, nshots, errRate);\n",
    "#filename = \"HaarEERes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes{}-lightCone{}-CNOT-\".format(nq, \\\n",
    "#                p, d, nshots, errRate, readErr, allTimes, lightCone)\n",
    "#filename = \"HaarEERes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes{}-lightCone{}-CNOT-{}remove0-\".format(nq,\\\n",
    "#                p, d, nshots, errRate, readErr, allTimes, lightCone, nfoldlabel)\n",
    "#print(\"filename = \", filename)\n",
    "#HaarEERes-nq8-p0.5-d6-nshots5000-errRate0.092-readErr0.0-allTimes1-lightCone1-CNOT-remove0-seed93.0.csv\n",
    "\n",
    "#HaarEERes-nq8-p0.5-d6-nshots5000-errRate0.092-readErr0.04-allTimes1-\\\n",
    "#lightCone0-CNOT-learnTi0Tf4-seed99.0.csv\n",
    "\n",
    "#errRate=readErr;\n",
    "#filename = \"HaarAveEE-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}-CNOT-seed\".format(nq, \\\n",
    "#                p, d, nshots, errRate, readErr)\n",
    "#HaarAveEE-nq8-p0.5-T6-nshots5000-errRate0.5-readErr0.0-seed98.0.csv\n",
    "#HaarAveEE-nq8-p0.1-T6-nshots5000-errRate0.1-readErr0.0-seed60.0.csv\n",
    "#print(\"filename = \", filename)\n",
    "d=6\n",
    "#print(\"filematches = \", filematches)\n",
    "#globals()[\"EETrajP{}L{}d{}\".format(p, nq, deltaT)]\n",
    "nq=4; t1=0; d=6; t2=d+1; delT=1;\n",
    "nshots=5000;p=0.1;\n",
    "for d in range(t2-1, t2):\n",
    "    errRate=readErr;    \n",
    "    counters = 0;\n",
    "    #filename = \"HaarAveEE-nq{}-p{}-T{}-nshots{}-errRate{}-readErr{}-CNOT-seed\".format(nq, p, d, nshots, errRate, 0.0)\n",
    "    #filename = \"HaarEERes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes1-lightCone1-CNOT-remove0-seed\".format(nq, p, d, nshots, errRate, readErr)\n",
    "    #filename = \"HaarEERes-nq{}-p{}-d{}-nshots{}-errRate{}-readErr{}-allTimes1-lightCone0-CNOT-seed\".format(nq, p, d, nshots, errRate, readErr)    \n",
    "    #filename = \"HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-NNmodelMLP-CNOT-remove0-seed\"\n",
    "    #filename = \"HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone1-CNOT-remove0-seed\"\n",
    "    #filename = \"HaarEERes-nq4-p0.1-d6-nshots5000-errRate0.0-readErr0.0-allTimes1-lightCone1-CNOT-remove0-seed\"\n",
    "    #filename = \"HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-NNmodelRNN-CNOT-seed\"\n",
    "    filename = \"HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-CNOT-seed\"\n",
    "    #print(\"filename = \", filename)    \n",
    "    filematches = [f for f in os.listdir() if f.startswith(filename)]    \n",
    "    deltaT = int(t2-t1+1)\n",
    "    globals()[\"EETrajP{}L{}d{}\".format(p, nq, errRate)] = np.zeros((2, totalNBefore, deltaT))\n",
    "    globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)] = np.zeros((2, len(filematches), deltaT))\n",
    "    globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)] = np.zeros((2, deltaT))    \n",
    "    globals()[\"errorp{}L{}d{}\".format(p, nq, errRate)] = np.zeros((2, deltaT))    \n",
    "    for s, filename in enumerate(filematches):                #print(\"s = \", s)\n",
    "        print(\"filename = \", filename)\n",
    "        rowinside=0;                \n",
    "        try:\n",
    "            with open(filename, 'r') as read_obj:\n",
    "                counters += 1;\n",
    "                csv_reader = csv.reader(read_obj, delimiter=' ');                #print(\"csv_reader = \", read_obj)            \n",
    "                for row in csv_reader:\n",
    "                    #if rowinside==0:                        \n",
    "                    #print(\"row = \", (row))\n",
    "                    rowinside+=1; #if s==52.0: #   print(\"len row = \", len(row))\n",
    "                    if rowinside>1000:\n",
    "                        break \n",
    "                    if nq==8 and p==0.5 and readErr==0.5 and float(row[5])<0.5: # This is because in the learning results without \n",
    "                        # proper regularization we were seeing purification for large readout error which is wrong.\n",
    "                        # For readErr=0.5 files include both the wrong results and the new correct results                        \n",
    "                        continue                    \n",
    "                    if nq==8 and row == len(row)*['0.0']:\n",
    "                        print(\"continue\")\n",
    "                    \"\"\"\n",
    "                    #continue\n",
    "                    #else:\n",
    "                    #if nq==8 and p==0.1 and (readErr==0.0 or readErr==0.04 or readErr==0.06):\n",
    "                        #print(\"p==0.1 and (readErr==0.0 or readErr==0.04 or readErr==0.06)\")\n",
    "                        #print(\"rowinside = \", rowinside)\n",
    "                        #if rowinside!=2:     \n",
    "                            #print(\"continue \\n\")\n",
    "                            #continue\n",
    "                    #if rowinside>=2*maxRow:\n",
    "                    #    continue   \n",
    "                    \"\"\";\n",
    "                    newrow=[]\n",
    "                    if True:                        \n",
    "                        for i in range(len(row)): # i loops over the time index of S_Q(t)                            \n",
    "                            newrow.append(float(row[i]))\n",
    "                            rowi = (float(row[i])) #print(\"row[i] = \", rowi) #print(\"rowinside = \", rowinside)#print(\"maxRow = \", maxRow)#print(\"s = \", s)\n",
    "                            if rowinside%2==0:\n",
    "                                globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][0, i] += rowi;                                \n",
    "                                globals()[\"EETrajP{}L{}d{}\".format(p, nq, errRate)][0, rowinside//2+maxRow*s, i] = rowi;\n",
    "                                globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)][0, s, i] += rowi; #print(globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][0, i])\n",
    "                            elif rowinside%2==1:\n",
    "                                globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][1, i] += rowi;\n",
    "                                globals()[\"EETrajP{}L{}d{}\".format(p, nq, errRate)][1, rowinside//2+maxRow*s, i] = rowi;\n",
    "                                globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)][1, s, i] += rowi;                   \n",
    "                        #print(\"globals = {}\".format(globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][1, :]))            \n",
    "                        #if rowinside==1:\n",
    "                        #    print(\"newrow = \", newrow)\n",
    "        except FileNotFoundError:\n",
    "            print(\"FileNotFoundError\")\n",
    "            continue;\n",
    "    #print(\"rowinside = \", rowinside)    \n",
    "    totalNAfter = (counters)*maxRow/2*rowinside;    \n",
    "    if nq==8 and readErr==0.5 and p==0.5:\n",
    "        totalNAfter = 100 #if readErr==0.06 and p==0.1: #    totalNAfter = 100        \n",
    "    #print(\"totalNAfter = \", totalNAfter)\n",
    "    #print(\"counters = \", counters)\n",
    "    print(\"EEP Before scaling = \", globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)])\n",
    "    globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)] = [globals()[\"EEP{}L{}d{}\".format(p, \\\n",
    "        nq, errRate)][i]/totalNAfter for i in range(len(globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)]))];\n",
    "    print(\"EEP = \", globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)])\n",
    "    globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)] = globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)]/rowinside; #print(\"EECircP = \", globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)][0, :, :])\n",
    "    globals()[\"stderrorp{}L{}d{}\".format(p, nq, errRate)] = np.divide(np.std(globals()[\"EECircP{}L{}d{}\".format(p, nq, errRate)], axis=1), 1)/sqrt((counters)) \n",
    "print(\"EETraj[0] = \", globals()[\"EETrajP{}L{}d{}\".format(p, nq, errRate)][0, :, :])\n",
    "\n",
    "print(\"totalNAfter = \", totalNAfter)\n",
    "print(\"EEP[0] = \", globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][0])\n",
    "print(\"EEP[1] = \", globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][1])\n",
    "#globals()[\"EEP{}L{}d{}\".format(p, nq, deltaT)][0] = globals()[\"EEP{}L{}d{}\".format(p, nq, deltaT)][0]*(1/totalNAfter)\n",
    "#meanLrn = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][0]), 0, 1, axis=0)\n",
    "#meanSim = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, errRate)][1]), 0, 1, axis=0)\n",
    "#print(\"meanLrn = \", meanLrn)\n",
    "#print(\"meanSim = \", meanSim)\n",
    "#print(\"meanLrn after = \",meanLrn)\n",
    "#plt.plot(meanLrn,'*-', label=\"Lrn\")\n",
    "#plt.plot(meanSim,'o-', label=\"Sim\")\n",
    "#plt.legend()\n",
    "#plt.ylim((0, 1.1))  \n",
    "#plt.xlabel(\"$t$\", **axis_font)\n",
    "#plt.ylabel(\"$S_{Q}(t)$\", **axis_font) \n",
    "#plt.show()\n",
    "\n",
    "\n",
    "colorvec=['b', 'r', 'k', 'c', 'm', 'g']\n",
    "i=0;\n",
    "ax = plt.subplot(1,1,1)\n",
    "#if readErr==0:\n",
    "#    forVector = [0.0, 0.1, 0.2, 0.5] # We loop over the coherent noise rates.\n",
    "#elif readErr==0:    \n",
    "\n",
    "#for s, errRate in enumerate([0.0, 0.1, 0.2, 0.5]):\n",
    "pvec = [0.05, 0.075, 0.1, 0.125, 0.15, 0.2]\n",
    "pvec = [0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "for p in pvec:\n",
    "    #for s, e in enumerate([0.0, 0.02, 0.04, 0.06, 0.08]):\n",
    "    #for s, e in enumerate([0.0, 0.04, 0.06, 0.5]):\n",
    "        e = 0.0\n",
    "        #for s, e in enumerate([0.0, 0.025, 0.05, 0.1, 0.2]):\n",
    "        #meanLrn = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, e)][0]), 0, 1, axis=0)\n",
    "        print(\"EEP{}L{}d{}\".format(p, nq, e))\n",
    "        meanLrn = globals()[\"EEP{}L{}d{}\".format(p, nq, e)][1]\n",
    "        #for i in range(1, np.shape(meanLrn)[0]):\n",
    "        #    if meanLrn[i]>meanLrn[i-1]:\n",
    "        #        meanLrn[i] = meanLrn[i-1]+np.random.normal(0, 0.01);\n",
    "        \n",
    "        #meanSim = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, e)][1]), 0, 1, axis=0)\n",
    "        meanLrn = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, e)][1]), 0, 1, axis=0)\n",
    "        print(\"meanLrn e{} = \".format(e), list(meanLrn))\n",
    "        if s==0:\n",
    "            if p==0.1:\n",
    "                if nq==8:                \n",
    "                    meanSim =  [1., 0.94099838, 0.8309909, 0.79211117, 0.75437732, 0.7273605,   0.70274331]            \n",
    "                if nq==6:\n",
    "                    meanSim = [1., 0.87085723, 0.81907381, 0.78802622, 0.73172007, 0.68784874, 0.6567073]\n",
    "            elif p==0.5:\n",
    "                if nq==6:\n",
    "                    meanSim = [1., 0.36891322, 0.2425357,  0.11832349, 0.06361765, 0.05581571, 0.01979116]\n",
    "                if nq==8:\n",
    "                    meanSim =  [1.,0.54707298, 0.30720127, 0.16641086, 0.10873754, 0.06543736, 0.03683359]\n",
    "                if nq==12:\n",
    "                    meanSim = [1, 0.63512703, 0.36515901, 0.1349761 , 0.08063291, 0.03567493, 0.02397183, 0.01689025]\n",
    "                    \n",
    "            plt.plot(meanSim,'o-', label=\"Sim without error, p={}\".format(p))    \n",
    "        #print(\"meanLrn = \", meanLrn)\n",
    "        plt.plot(meanLrn,'*-', label=\"Lrn, p={}, readout error ={}\".format(p, e))\n",
    "        if s==2 and nq==6:\n",
    "            plt.plot([1, 0.5864, 0.4499, 0.4439, 0.3816, 0.4237, 0.3691], 'o-.', label=\"Extrapolation at readout error={}\".format(0))\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.xlim((0, d))  \n",
    "        plt.ylim((0, 1.1))  \n",
    "        plt.xlabel(\"$t$\", **axis_font)\n",
    "        plt.ylabel(\"$S_{Q}(t)$\", **axis_font) \n",
    "plt.title(\"$N_q$ = {}, p={}; Coherent Error={}\".format(nq, p, 0))\n",
    "extrap = [1, 0.5914,    0.4621 ,   0.3946 ,   0.4148  ,  0.4333   , 0.4584]\n",
    "#plt.plot(extrap,'o--', label=\"Extrapolate, readout error = 0.0\")  \n",
    "if readErr==0: \n",
    "    plt.title(\"$N_q$ = {}, p={}, 0.5; Coherent Error\".format(nq, p))\n",
    "    #plt.savefig('haarNq{}P{}Coherent.png'.format(nq, p), dpi=300)\n",
    "elif errRate==0:\n",
    "    plt.title(\"$N_q$ = {}, p={}, Readout Error\".format(nq, p))\n",
    "    #plt.savefig('haarNq{}P{}Readout.png'.format(nq, p), dpi=300)\n",
    "#plt.savefig('haarNq{}P{}Readout.png'.format(nq, p), dpi=300)\n",
    "##plt.savefig('Infidel0p01-Nq{}P{}Readout0.04.png'.format(nq, p), dpi=300)    \n",
    "#plt.savefig('Haar-Nq{}P{}Coherent0p092Readout0-0p08.png'.format(nq, p), dpi=300)    \n",
    "#plt.savefig('Haar3Folded-Nq{}P{}Coherent0p092Readout0-0p08.png'.format(nq, p), dpi=300)    \n",
    "#plt.savefig('HaarFoldvsUnfold-Nq{}P{}Coherent0p092Readout0-0p08.png'.format(nq, p), dpi=300)    \n",
    "#plt.savefig('Haar-Nq{}P{}CoherentErr{}Readout0-0p08.png'.format(nq, p, 0.092), dpi=300)    \n",
    "#plt.savefig('PngResHaar-Nq{}P{}CoherentErr{}Readout0-0p06.png'.format(nq, p, 0.0), dpi=300)    \n",
    "#plt.savefig('PngResHaar-Nq{}P{}CoherentErr{}Readout0-0P5.png'.format(nq, p, errRate), dpi=300)    \n",
    "plt.show()\n",
    "\n",
    "for p in pvec:     \n",
    "    #meanLrn = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, deltaT)][0]), 0, 1, axis=0)\n",
    "    #print(\"meanLrn = \", meanLrn)\n",
    "    #meanSim = np.insert((globals()[\"EEP{}L{}d{}\".format(p, nq, deltaT)][1]), 0, 1, axis=0)\n",
    "    print(\"meanSim = \", meanSim)    \n",
    "    \n",
    "    line1 = ax.plot(tvec,meanLrn[:len(tvec)], '{}*-.'.format(colorvec[i]), label=\"p={}, Lrn\".format(p))\n",
    "    line2 = ax.plot(tvec,meanSim[:len(tvec)], '{}*-'.format(colorvec[i]), label=\"p={}, Sim\".format(p))\n",
    "    ax.legend()    \n",
    "    i+=1\n",
    "plt.xlabel(\"$t$\", **axis_font)\n",
    "plt.ylabel(\"$S_{Q}(t)$\", **axis_font) \n",
    "\n",
    "line1 = plt.plot(tvec,meanLrn, 'r*-.', label=\"p={}, Lrn\".format(p))\n",
    "line2 = plt.plot(tvec,meanSim, 'r*-', label=\"p={}, Sim\".format(p))\n",
    "\n",
    "plt.xlim((0, len(tvec)))   # set the xlim to left, right\n",
    "plt.ylim((0, 1))  \n",
    "plt.show();\n",
    "\n",
    "#meanSimP0p5 =  [1.,0.54707298, 0.30720127, 0.16641086, 0.10873754, 0.06543736, 0.03683359]\n",
    "#meanSimP0p1 =  [1., 0.94099838, 0.8309909, 0.79211117, 0.75437732, 0.7273605,   0.70274331]\n",
    "#\"\"\";\n",
    "\n",
    "#HaarAveEE-nq6-p0.5-T6-nshots5000-errRate0.0-readErr0.0-CNOT-seed99.0.csv\n",
    "#HaarAveEE-nq6-p0.5-T6-nshots5000-errRate0.0-readErr0.06-CNOT-seed\n",
    "\n",
    "#errRate=0; meanLrnerrRate0.0 =  [1.         0.72372074 0.51908128 0.44634388 0.42185422 0.42067098 0.37142978 0.]\n",
    "#errRate=0.092; meanLrnerrRate0.092 =  [1.         0.72055761 0.54786716 0.46762872 0.433558   0.40898006 0.43174232 0.]\n",
    "#errRate=0.2; meanLrnerrRate0.2 = EEP[0] =  [0.71138092 0.58338108 0.5297058  0.49734297 0.49993223 0.44914811 0.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Row0: Exact Sim: 50000\n",
    "#Row1: MLP 5000\n",
    "#Row2: MLP 50000\n",
    "#Row3: RNN 50000\n",
    "#Row4: Resnet\n",
    "\n",
    "EEP =  [[0.999001  , 0.94182724, 0.86614348, 0.78251159, 0.71477271, 0.66974889, 0.61513099], \\\n",
    "        [0.999, 0.96075637, 0.90992945, 0.83336612, 0.78083956, 0.77737226, 0.75113139], \\\n",
    "        [0.99, 0.93517465, 0.86678925, 0.8254159 , 0.76485937, 0.75053028, 0.72215812], \\\n",
    "       [0.99, 0.88098558, 0.83791975, 0.80177669, 0.74167419, 0.72229299, 0.7178976], \\\n",
    "       [0.99, 0.8880715 , 0.84581972, 0.77979443, 0.7690409 , 0.72924165, 0.70268037], \\\n",
    "       [0.99, 0.96075637, 0.90992945, 0.83336612, 0.78083956, 0.77737226, 0.75113139]]\n",
    "\n",
    "#filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-NNmodelRNN-CNOT-seed125.0.csv\n",
    "#newrow =  [0.20990735154862186, 0.22256952609481814, 0.2697570296621154, 0.21485555341929635, 0.2175425795973656, 0.2058353483339407]\n",
    "#filename =  HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone0-NNmodelMLP-CNOT-remove0-seed125.0.csv\n",
    "#newrow =  [0.18063728128767112, 0.2772538351069073, 0.2510307610953577, 0.1811480092422645, 0.19261599154584907, 0.2125006225251777]\n",
    "\n",
    "#HaarEERes-nq4-p0.1-d1-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone1-CNOT-remove0-seed\n",
    "#HaarEERes-nq4-p0.1-d6-nshots50000-errRate0.0-readErr0.0-allTimes1-lightCone1-CNOT-remove0-seed93.0.csv\n",
    "plt.legend()\n",
    "plt.plot(EEP[0][:7], label='Exact Simulation')\n",
    "plt.plot(EEP[1][:7], label='CNN 5000')\n",
    "plt.plot(EEP[2][:7], label='MLP 50000')\n",
    "plt.plot(EEP[3][:7], label='RNN 50000')\n",
    "plt.plot(EEP[4][:7], label='CNN 50000')\n",
    "#plt.legend(labels)\n",
    "plt.legend(['Exact Simulation', 'CNN 5000', 'MLP 50000', 'RNN 50000', 'CNN 50000'])\n",
    "plt.ylim(0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'axis_font' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fa2be126b260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$t$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxis_font\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"$S_{Q}(t)$\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maxis_font\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#plt.savefig('PngResHaarNq{}P{}Coherent0-0p092-0p2.png'.format(8, 0.5), dpi=300)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'axis_font' is not defined"
     ]
    }
   ],
   "source": [
    "#a = [101.00072966,  52.29773609,  27.62226895,  13.04872824,\\\n",
    "#   6.88478796,   3.20503109,   1.78903532 ,  2.63994507 ,  0.        ]\n",
    "#plt.plot(a)\n",
    "#plt.show()\n",
    "# Unfinished jobs for Nshots=20000:\n",
    "# HaarGenP0p5Nq8d5err0.092readerr0.0CNOTs22.0\n",
    "# HaarGenP0p5Nq8d5err0.092readerr0.0CNOTs23.0\n",
    "# HaarGenP0p5Nq8d6err0.092readerr0.0CNOTs98.0.sh\n",
    "# HaarGenP0p5Nq8d6err0.092readerr0.0CNOTs99.0.sh\n",
    "# HaarGenP0p5Nq8d6erfr0.092readerr0.0CNOTs100.0.sh\n",
    "\n",
    "\n",
    "meanSim =  [1.,0.54707298, 0.30720127, 0.16641086, 0.10873754, 0.06543736, 0.03683359]\n",
    "meanLrne0p0 =  [1., 0.62138638, 0.35985115, 0.29748807, 0.25038582, 0.13885727, 0.05237227, 0.]\n",
    "meanLrne0p04 =  [1., 0.7492521, 0.60484457, 0.52790164, 0.39025323, 0.18250812, 0.06919619, 0.]\n",
    "meanLrnnfold3read0p0 =  [1., 0.6318991, 0.40676883, 0.30829612, 0.23940164, 0.11686884, 0.04499042, 0.]\n",
    "meanLrnnfold3read0p04 =  [1., 0.75962544, 0.61058861, 0.52903914, 0.37157307, 0.15139477, 0.06118004, 0.]\n",
    "e = 0.092\n",
    "\n",
    "#errRate=0; \n",
    "meanLrnerrRate0p0 =  [1., 0.72372074, 0.51908128, 0.44634388, 0.42185422, 0.42067098, 0.37142978, 0.]\n",
    "#errRate=0.092; \n",
    "meanLrnerrRate0p092 =  [1., 0.72055761, 0.54786716, 0.46762872, 0.433558, 0.40898006, 0.43174232, 0.]\n",
    "#errRate=0.2; \n",
    "meanLrnerrRate0p2 = [1, 0.71138092, 0.58338108, 0.5297058, 0.49734297, 0.49993223, 0.44914811, 0.]\n",
    "\n",
    "#plt.plot(meanSim,'o-', label=\"Sim without error, p={}\".format(p))    \n",
    "#plt.plot(meanLrne0p0,'o-', label=\"Lrn, p={}, readout error = {}\".format(p, 0))\n",
    "#plt.plot(meanLrne0p04,'o-', label=\"Lrn, p={}, readout error = {}\".format(p, 0.04))\n",
    "#plt.plot(meanLrnnfold3read0p0,'*-', label=\"Lrn, p={}, 3fold, readout error = {}\".format(p, 0))\n",
    "#plt.plot(meanLrnnfold3read0p04,'*-', label=\"Lrn, p={}, 3fold, readout error = {}\".format(p, 0.04))\n",
    "#errRate=0; meanLrnerrRate0p0 =  [1., 0.72372074, 0.51908128, 0.44634388, 0.42185422, 0.42067098, 0.37142978, 0.]\n",
    "#errRate=0.092; meanLrnerrRate0p092 =  [1., 0.72055761, 0.54786716, 0.46762872, 0.433558, 0.40898006, 0.43174232, 0.]\n",
    "#errRate=0.2; meanLrnerrRate0p2 = [1, 0.71138092, 0.58338108, 0.5297058, 0.49734297,  0.49993223, 0.44914811, 0.]\n",
    "plt.plot(meanLrnerrRate0p0,'o-', label=\"Lrn, p={}, errRate = {}\".format(p, 0 ))      \n",
    "plt.plot(meanLrnerrRate0p092,'o-', label=\"Lrn, p={}, errRate = {}\".format(p, 0.092))\n",
    "plt.plot(meanLrnerrRate0p2,'o-', label=\"Lrn, p={}, errRate = {}\".format(p, 0.2))\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim((0, d))  \n",
    "plt.ylim((0, 1.1))  \n",
    "plt.xlabel(\"$t$\", **axis_font)\n",
    "plt.ylabel(\"$S_{Q}(t)$\", **axis_font) \n",
    "#plt.savefig('PngResHaarNq{}P{}Coherent0-0p092-0p2.png'.format(8, 0.5), dpi=300)\n",
    "plt.show()\n",
    "#meanLrn =  [1.         0.8617612  0.94479149 0.83807546 0.87953867 0.94432613\n",
    "# 0.89862249 0.        ]\n",
    "#line3 = plt.plot(2*globals()[\"EECircP{}L{}\".format(p, nq)][0, 101, :],'b' )\n",
    "#line3 = plt.plot(2*globals()[\"EECircP{}L{}\".format(p, nq)][1, 101, :],'b.-' )\n",
    "#line3 = plt.plot(2*globals()[\"EECircP{}L{}\".format(p, nq)][0, 201, :], 'r' )\n",
    "#line3 = plt.plot(2*globals()[\"EECircP{}L{}\".format(p, nq)][1, 201, :],'r.-' )\n",
    "#line3 = plt.plot(globals()[\"EECircP{}L{}\".format(p, nq)][0, 301, :] )\n",
    "#line3 = plt.plot(globals()[\"EECircP{}L{}\".format(p, nq)][1, 1, :] )\n",
    "\n",
    "#line3 = plt.plot(globals()[\"EECircP{}L{}\".format(p, nq)][1, 301, :] )\n",
    "\n",
    "#line3 = plt.plot(globals()[\"EECircP{}L{}\".format(p, nq)][1, 2, :] )\n",
    "#\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#HaarEERes-nq8-p0.1-ti2-tf9-delT1-lightCone0-nshots5000-seed1.0.csv\n",
    "##HaarEERes-nq8-p0.1-ti2-tf9-delT1-lightCone0-nshots5000-seed1.01.csv\n",
    "p=0.1;\n",
    "#print(globals()[\"EECircP{}L{}\".format(0.1, nq)][0, :, 3])\n",
    "#mean0p1 = np.mean(globals()[\"EECircP{}L{}\".format(0.1, nq)], axis=1);\n",
    "#mean0p3 = np.mean(globals()[\"EECircP{}L{}\".format(0.3, nq)], axis=1);\n",
    "mean0p1 = np.zeros((2, 8))\n",
    "mean0p1[0, :] = np.insert((globals()[\"EEP{}L{}\".format(p, nq)][0]), 0, 1, axis=0)\n",
    "mean0p1[1, :] = np.insert((globals()[\"EEP{}L{}\".format(p, nq)][1]), 0, 1, axis=0)\n",
    "p=0.3;\n",
    "#mean0p1 = np.insert(mean0p1, 0, 1, axis=1)\n",
    "#mean0p3 = np.insert(mean0p3, 0, 1, axis=1)\n",
    "mean0p3 = np.zeros((2, 8))\n",
    "mean0p3[0, :] = np.insert((globals()[\"EEP{}L{}\".format(p, nq)][0]), 0, 1, axis=0)\n",
    "mean0p3[1, :] = np.insert((globals()[\"EEP{}L{}\".format(p, nq)][1]), 0, 1, axis=0)\n",
    "\n",
    "tvec=[0, 1, 2, 3, 4, 5, 6, 7];\n",
    "print(\"mean0p1 = \", mean0p1);\n",
    "print(\"mean0p3 = \", mean0p3);\n",
    "\n",
    "\n",
    "\n",
    "varp0p1 = np.divide(np.var(globals()[\"EECircP{}L{}\".format(0.1, nq)], axis=1), 1)\n",
    "print(\"varp0p1 = \", varp0p1)\n",
    "varp0p3 = np.divide(np.var(globals()[\"EECircP{}L{}\".format(0.3, nq)], axis=1), 1)\n",
    "print(\"varp0p3 = \", varp0p3)\n",
    "\n",
    "print(\"errorp0p1 = \", errorp0p1)\n",
    "print(\"errorp0p3 = \", errorp0p3)\n",
    "\n",
    "line1, =plt.plot(tvec,(mean0p1[0, :]), 'r*-.', label=\"p=0.1, Lrn\")\n",
    "\n",
    "line2, =plt.plot(tvec,(mean0p1[1, :]), 'r*-', label=\"p=0.1, Exact\")\n",
    "\n",
    "line3, =plt.plot(tvec,(mean0p3[0, :]), 'b*-.', label=\"p=0.3, Lrn\")\n",
    "\n",
    "line4, =plt.plot(tvec,(mean0p3[1, :]), 'b*-', label=\"p=0.3, Exact\")\n",
    "\n",
    "axis_font = {'fontname':'Times New Roman', 'size':'18'}\n",
    "print(globals()[\"EECircP{}L{}\".format(0.1, nq)][0, :, 3])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "mean0p1 = np.mean(globals()[\"EECircP{}L{}\".format(0.1, nq)], axis=1);\n",
    "mean0p1 = np.insert(mean0p1, 0, 1, axis=1)\n",
    "mean0p3 = np.insert(mean0p3, 0, 1, axis=1)\n",
    "#print(\"mean0p1 = \", mean0p1)\n",
    "#print(\"mean0p3 = \", mean0p3)\n",
    "\n",
    "errorp0p1 = np.divide(np.std(globals()[\"EECircP{}L{}\".format(0.1, nq)], axis=1), 1)/sqrt(18)\n",
    "\n",
    "errorp0p3 = np.divide(np.std(globals()[\"EECircP{}L{}\".format(0.3, nq)], axis=1), 1)/sqrt(18)\n",
    "errorp0p1 = np.insert(errorp0p1, 0, 0, axis=1)\n",
    "errorp0p3 = np.insert(errorp0p3, 0, 0, axis=1)\n",
    "\n",
    "\n",
    "varp0p1 = np.divide(np.var(globals()[\"EECircP{}L{}\".format(0.1, nq)], axis=1), 1)\n",
    "print(\"varp0p1 = \", varp0p1)\n",
    "varp0p3 = np.divide(np.var(globals()[\"EECircP{}L{}\".format(0.3, nq)], axis=1), 1)\n",
    "print(\"varp0p3 = \", varp0p3)\n",
    "\n",
    "print(\"errorp0p1 = \", errorp0p1)\n",
    "print(\"errorp0p3 = \", errorp0p3)\n",
    "line1, =plt.plot(tvec,(mean0p1[0, :]), 'r*-.', label=\"p=0.1, Lrn\")\n",
    "\n",
    "line2, =plt.plot(tvec,(mean0p1[1, :]), 'r*-', label=\"p=0.1, Exact\")\n",
    "\n",
    "line3, =plt.plot(tvec,(mean0p3[0, :]), 'b*-.', label=\"p=0.3, Lrn\")\n",
    "\n",
    "line4, =plt.plot(tvec,(mean0p3[1, :]), 'b*-', label=\"p=0.3, Exact\")\n",
    "\n",
    "axis_font = {'fontname':'Times New Roman', 'size':'18'}\n",
    "plt.xlabel(\"$t$\", **axis_font)\n",
    "plt.ylabel(\"$S_{Q}(t)$\", **axis_font)\n",
    "\n",
    "\n",
    "alterrorp0p1 = np.divide(np.std(globals()[\"EETrajP{}L{}\".format(0.1, nq)], axis=1), 1)/sqrt(19*100)\n",
    "\n",
    "alterrorp0p3 = np.divide(np.std(globals()[\"EETrajP{}L{}\".format(0.3, nq)], axis=1), 1)/sqrt(19*100)\n",
    "alterrorp0p1 = np.insert(alterrorp0p1, 0, 0, axis=1)\n",
    "alterrorp0p3 = np.insert(alterrorp0p3, 0, 0, axis=1)\n",
    "\n",
    "print(alterrorp0p1)\n",
    "print(alterrorp0p3)\n",
    "\"\"\";\n",
    "#plt.xlabel(\"$t$\", **axis_font)\n",
    "#plt.ylabel(\"$S_{Q}(t)$\", **axis_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "seedmin=0.1; seedmax=1.; deltaseed=0.05\n",
    "seedvec = np.arange(seedmin, seedmax, deltaseed)\n",
    "print(seedvec)\n",
    "tvec=[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "globals()[\"EEP{}L{}\".format(0.3, nq)][0] = [1, 0.75293879, 0.62024741, 0.54135486, 0.40050479, 0.29309889,\n",
    "       0.16049759, 0.11497998, 0.07690033]\n",
    "globals()[\"EEP{}L{}\".format(0.3, nq)][1] = [1, 0.70888042, 0.50036238, 0.37233101, 0.29013355, 0.26122443,\n",
    "       0.22418904, 0.20339315, 0.17588979]\n",
    "\n",
    "print(globals()[\"EEP{}L{}\".format(0.1, nq)][0])\n",
    "print(globals()[\"EEP{}L{}\".format(0.1, nq)][1])\n",
    "globals()[\"EEP{}L{}\".format(0.1, nq)][0] = [1, 0.81606839, 0.76203789, 0.73086339,\\\n",
    "                                            0.68472011, 0.67315307, 0.66952763, \\\n",
    "                                            0.66044189, 0.64522611]\n",
    "globals()[\"EEP{}L{}\".format(0.1, nq)][1] = [1, 0.81684441, 0.70931065, 0.63492464,\\\n",
    "                                            0.5884308,  0.56727987, 0.56597411,\\\n",
    "                                            0.55315286, 0.55274394]\n",
    "\n",
    "line1, =plt.plot(tvec,(globals()[\"EEP{}L{}\".format(0.3, nq)][0]), 'r*-.', label=\"p=0.3, Lrn\")\n",
    "#line2, =plt.plot(pvec,(l12), 'b*-', label=\"L=12\")\n",
    "line2, =plt.plot(tvec,(globals()[\"EEP{}L{}\".format(0.3, nq)][1]), 'r*-', label=\"p=0.3, Exact\")\n",
    "\n",
    "line3, =plt.plot(tvec,(globals()[\"EEP{}L{}\".format(0.1, nq)][0]), 'b*-.', label=\"p=0.1, Lrn\")\n",
    "#line2, =plt.plot(pvec,(l12), 'b*-', label=\"L=12\")\n",
    "line4, =plt.plot(tvec,(globals()[\"EEP{}L{}\".format(0.1, nq)][1]), 'b*-', label=\"p=0.1, Exact\")\n",
    "axis_font = {'fontname':'Times New Roman', 'size':'18'}\n",
    "plt.xlabel(\"$t$\", **axis_font)\n",
    "plt.ylabel(\"$S_{Q}(t)$\", **axis_font)\n",
    "#plt.title(\"$N^{Max}_{Samp}=5000$\", **title_font)\n",
    "#plt.legend(loc='upper right', numpoints=1)\n",
    "\n",
    "#C = [43.71313058, 38.22046306, 35.99624635, 34.00732185, 32.4463036,  31.4076126 ]\n",
    "\n",
    "#C = [C[i]/50 for i in range(len(B))]\n",
    "#line3, =plt.plot(C, 'm*-')\n",
    "plt.legend(handles=[line1, line2, line3, line4])\n",
    "plt.savefig('S_Q-ExactVsLrn-L8-p0p1-p0p3.png', dpi=300)  \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    find1 = \"julia JuliaCliffordMainModulesCreateMeasure.jl 32 .3 6 10000 10000 false 10 20 121 false true false\"\n",
    "    \n",
    "    find2 = \"#SBATCH -t 0:01:00\"\n",
    "    replace2 = \"#SBATCH -t {}:{}:00\".format(hour, minutes)\n",
    "    \n",
    "    filePattern = \"*.sh\"\n",
    "    csvLabel=\"false\"\n",
    "    v=\"false\"\n",
    "    severalJob = \"false\";\n",
    "    countArr=[]\n",
    "    counter = 0;\n",
    "    counterLoop = 0;\n",
    "    counterArr = [];\n",
    "    cIndArrCounter = 0;\n",
    "\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):        \n",
    "            \n",
    "            if PT==None:\n",
    "                if '{}P{}L{}-'.format(fileLabel, prob, L) in filename:\n",
    "                    #print(filename)\n",
    "                    countJL = filename.replace('{}P{}L{}-'.format(fileLabel, prob, L),'')\n",
    "                    count = countJL.replace('.sh','')\n",
    "                    #print(\"count = \", count)\n",
    "                    try:\n",
    "                        count = int(float(count))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    #print(\"count = \", count)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                #print(\"elif PT==None\")\n",
    "                if cIndArr[count-1]==0:\n",
    "                    #print(\"cIndArr[count]==0\")\n",
    "                    continue\n",
    "                if count>maxCount:\n",
    "                    continue\n",
    "                    \n",
    "                if cIndArr[count-1]>0 and cIndArr[count-1]<=T and cIndArr[count-1]<maxCount:                    \n",
    "                    cIndArrCounter += 1\n",
    "                    \n",
    "    #print(\"cIndArrCounter = \", cIndArrCounter)\n",
    "    \n",
    "                    \n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        for filename in fnmatch.filter(files, filePattern):            \n",
    "            if PT==None:\n",
    "                #print(\"PT==None\")\n",
    "                if '{}P{}L{}-'.format(fileLabel, prob, L) in filename:\n",
    "                    #print(filename)\n",
    "                    countJL = filename.replace('{}P{}L{}-'.format(fileLabel, prob, L),'')\n",
    "                    count = countJL.replace('.sh','')\n",
    "                    #print(\"count = \", count)\n",
    "                    try:\n",
    "                        count = int(float(count))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    #print(\"count = \", count)\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            if PT!=None:\n",
    "                if count in cIndArr:                \n",
    "                    if count in countArr:\n",
    "                        continue\n",
    "                    else:\n",
    "                        countArr.append(count)\n",
    "            elif PT==None:\n",
    "                #print(\"elif PT==None\")\n",
    "                if cIndArr[count-1]==0:\n",
    "                    #print(\"cIndArr[count]==0\")\n",
    "                    continue\n",
    "                if count>maxCount:\n",
    "                    continue\n",
    "                    \n",
    "            filepath = os.path.join(path, filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()                \n",
    "            \n",
    "            replace1 = \"julia --threads 20 JuliaQCliffordCM.jl {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} \".format(L, \n",
    "                        p, T, evolutionTime, Scramble, Nsamp, Ncircuit, evolutionTime, Nbatch, NpureT, \n",
    "                        NcircPT, count, severalJob, csvLabel, v, intNew)\n",
    "            \n",
    "            if counter%Ncounter==0:\n",
    "                counter1 = count\n",
    "            \n",
    "            if counter%(Ncounter-1)==0:\n",
    "                counter25 = count\n",
    "                counterLoop += 1;\n",
    "                            \n",
    "            if counter == cIndArrCounter-1:\n",
    "                counter25 = count\n",
    "                    \n",
    "            counterArr.append(count);            \n",
    "            if counter%Ncounter==Ncounter-1 and counter!=cIndArrCounter-1:\n",
    "                try:            \n",
    "                    shutil.copy2('/Users/hosseindehghani/Desktop/Hafezi/Codes/measureRec2.sh',\n",
    "                        '{}/SHFilesFromTo/{}P{}L{}-{}to{}.sh'.format(directorySH, fileLabel,\n",
    "                         prob, L, counter1, counter25))\n",
    "                    a=2;\n",
    "                except shutil.SameFileError:\n",
    "                    print(\"Source and destination represents the same file.\")    \n",
    "                except PermissionError:\n",
    "                    print(\"Permission denied.\")             \n",
    "                except:\n",
    "                    print(\"Error occurred while copying file.\")                    \n",
    "                print('sbatch -A hafezi-prj-aac -t {}:0:0 {}P{}L{}-{}to{}.sh'.format(hour, fileLabel,\n",
    "                         prob, L, counter1, counter25))                    \n",
    "                \n",
    "                fileOpen = open('{}/SHFilesFromTo/{}P{}L{}-{}to{}.sh'.format(directorySH, \n",
    "                        fileLabel, prob, L, counter1, counter25), \"a\")\n",
    "                fileOpen.write(stringMeasure)     \n",
    "                    \n",
    "                for n in range(Ncounter):\n",
    "                    if True:\n",
    "                        replace1 = \"julia --threads 20 JuliaQCliffordCM.jl {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} \".format(L, \n",
    "                            p, T, evolutionTime, Scramble, Nsamp, Ncircuit, evolutionTime, Nbatch, NpureT,\n",
    "                            NcircPT, counterArr[-Ncounter+n], severalJob, csvLabel, v, intNew)\n",
    "                        fileOpen.write(\"\\n\")\n",
    "                        fileOpen.write(replace1)\n",
    "            if counter==cIndArrCounter-1:\n",
    "                fileOpen = open('{}/SHFilesFromTo/{}P{}L{}-{}to{}.sh'.format(directorySH, \n",
    "                        fileLabel, prob, L, counter1, counter25), \"a\")\n",
    "                fileOpen.write(stringMeasure)     \n",
    "                \n",
    "                for n in range((cIndArrCounter-1)%Ncounter+1):\n",
    "                    if True:\n",
    "                        replace1 = \"julia --threads 20 JuliaQCliffordCM.jl {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} \".format(L, \n",
    "                            p, T, evolutionTime, Scramble, Nsamp, Ncircuit, evolutionTime, Nbatch, NpureT,\n",
    "                            NcircPT, counterArr[-Ncounter+n], severalJob, csvLabel, v, intNew)\n",
    "                        fileOpen.write(\"\\n\")\n",
    "                        fileOpen.write(replace1)\n",
    "            counter += 1  \n",
    "            s = s.replace(find1, replace1)\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read()\n",
    "                s = s.replace(find2, replace2.format(count))\n",
    "\n",
    "            with open(filepath, \"w\") as f:\n",
    "                f.write(s)  \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nq, d, p, circ, nshots, errRate, readErr, gate, nfold, allTimes, realT, learnT1, nnmodel, \\\n",
    "    ifremove0, lightCone = 6, d, 0.5, 1, 5000, 0.092, 0.04, 1, nfold, 1, 0, 0, 0, 1, 1\n",
    "if gate==0:\n",
    "        gatelabel = \"\"\n",
    "elif gate==1:\n",
    "        gatelabel = \"CNOT\"\n",
    "elif gate==2:\n",
    "        gatelabel = \"iSwap\"\n",
    "\n",
    "filePattern = '*.csv';\n",
    "\n",
    "direc = \"/users/hosseindehghani/desktop/hafezi/Codes/measurementPT/Haar/\"\n",
    "for path, dirs, files in os.walk(os.path.abspath(direc)):\n",
    "    #print(\"files = \", files)\n",
    "    for filename in fnmatch.filter(files, filePattern):      \n",
    "        for T in range(1, 7):\n",
    "            for XYZ in [\"X\", \"Y\", \"Z\"]:\n",
    "                string = 'MeasureRes{}-nq6-p{}-T{}-nshots5000-errRate0.092-readErr0.04-CNOT-seed'.format(XYZ, p, T)\n",
    "                modifiedstring = 'MeasureRes{}-nq6-p{}-T{}-nshots5000-errRate0.092-readErr0.0-CNOT-seed'.format(XYZ, p, T)\n",
    "                if string in filename:\n",
    "                    seedcsv = filename.replace(string, '')            \n",
    "                    seed = float(seedcsv.replace('.csv',''))\n",
    "                    modifiedfile = modifiedstring+\"{}\".format(seed)+\".csv\"\n",
    "                    print(\"seed = \", seed)\n",
    "                    print(\"modifiedfile = \", modifiedfile)\n",
    "                    shutil.copy2(\"/users/hosseindehghani/dessktop/hafezi/Codes/measurementPT/Haar/{}\".format(filename), \\\n",
    "                             \"/users/hosseindehghani/desktop/hafezi/Codes/measurementPT/Haar/{}\".format(modifiedfile))\n",
    "            \n",
    "\"\"\";            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMeasureSHFiles(nq, d, p, circ, nshots, errRate, readErr, gate, nfold, \\\n",
    "        ifremove0, lightCone, allTimes, realT, learnT1, nnmodel, seedmin, seedmax, nseed, \\\n",
    "        fileLabel, account, hour, minutes, nproc, directory, NTest=None):    \n",
    "    #print(\"nq = \", nq)\n",
    "    nproc=1;\n",
    "    DecimalP = str(p).replace('0.','');\n",
    "    prob = \"0p{}\".format(DecimalP);\n",
    "    rowc=0;\n",
    "    os.chdir(directory);\n",
    "    cwdir = os.getcwd();\n",
    "    print(cwdir);\n",
    "    seedvec = np.linspace(seedmin, seedmax, nseed);  #   np.arange(seedmin, seedmax, deltaseed);\n",
    "    seedvec = [np.round(seed, 2) for seed in seedvec];\n",
    "    \n",
    "    #print(\"seedvec = \", seedvec);\n",
    "    #filepath = os.path.join('/Users/hosseindehghani/Desktop/Hafezi/Codes/Haar/', 'haar.sh') \n",
    "    print(f\"allTimes = {allTimes}\")\n",
    "    if nfold==1:\n",
    "        nfoldlabel = \"\"\n",
    "    else:\n",
    "        nfoldlabel = \"Nfold{}\".format(nfold)\n",
    "    \n",
    "    if gate==0:\n",
    "        gatelabel = \"\"\n",
    "    elif gate==1:\n",
    "        gatelabel = \"CNOT\"\n",
    "    elif gate==2:\n",
    "        gatelabel = \"iSwap\"\n",
    "        \n",
    "    for s in range(len(seedvec)):\n",
    "        seed = seedvec[s];\n",
    "        #print(\"seed = \", seed)\n",
    "        #n = int(seed);\n",
    "        if seed!=0:\n",
    "            try:\n",
    "                #shutil.copy2('/Users/hosseindehghani/Desktop/Hafezi/Codes/MeasurementPT/Haar/HaarGen0.sh',\n",
    "                #    '{}/{}P{}Nq{}d{}err{}s{}.sh'.format(directory, fileLabel, prob, nq, d, errRate, seed));           \n",
    "                #print('{}/{}P{}Nq{}d{}err{}readerr{}{}{}Ns{}s{}.sh'.format(directory, fileLabel, prob, nq, d, \\\n",
    "                #    errRate, readErr, gatelabel, nfoldlabel, nshots, seed))\n",
    "                shutil.copy2('/Users/hosseindehghani/Desktop/Hafezi/Codes/MeasurementPT/Haar/{}0.sh'.format(\\\n",
    "                    fileLabel), '{}/{}P{}Nq{}d{}err{}readerr{}{}{}Ns{}NN{}s{}.sh'.format(directory, fileLabel, \\\n",
    "                    prob, nq, d, errRate, readErr, gatelabel, nfoldlabel, nshots, nnmodel, seed));\n",
    "            except shutil.SameFileError:\n",
    "                print(\"Source and destination represents the same file.\")\n",
    "            except PermissionError:\n",
    "                print(\"Permission denied.\")\n",
    "            #except:\n",
    "            #    print(\"Error occurred while copying file.\")                        =\n",
    "    count = 0;\n",
    "    filePattern = '*.sh';\n",
    "    for path, dirs, files in os.walk(os.path.abspath(directory)):\n",
    "        #print(\"files = \", files)\n",
    "        for filename in fnmatch.filter(files, filePattern):\n",
    "            #print('{}P{}Nq{}d{}err{}readerr{}{}{}Ns{}s'.format(fileLabel, prob, nq, d, errRate, readErr, \\\n",
    "            #                            gatelabel, nfoldlabel, nshots))\n",
    "            if '{}P{}Nq{}d{}err{}readerr{}{}{}Ns{}NN{}s'.format(fileLabel, prob, nq, d, errRate, readErr, \\\n",
    "                                        gatelabel, nfoldlabel, nshots, nnmodel) in filename:\n",
    "                seedSH = filename.replace('{}P{}Nq{}d{}err{}readerr{}{}{}Ns{}NN{}s'.format(fileLabel, prob, nq, d, \\\n",
    "                                        errRate, readErr, gatelabel, nfoldlabel, nshots, nnmodel),'')\n",
    "                seed = seedSH.replace('.sh','')\n",
    "                #print(\"seed = \", seed)\n",
    "            else:\n",
    "                continue\n",
    "            filepath = os.path.join(path, filename);\n",
    "            print(\"filename = \", filename)\n",
    "            with open(filepath) as f:\n",
    "                s = f.read();\n",
    "                find1 = \"#SBATCH -t 02:00:00\"\n",
    "                replace1 = \"#SBATCH -t {}:{}:00\".format(hour, minutes)\n",
    "                #print(\"replace1 = \", replace1)\n",
    "                #HaarRandomHPCNewNoMeasure.py\n",
    "                if fileLabel==\"HaarGen\":\n",
    "                    find2 = \"python HaarRandomHPCNew.py 8 6 .5 1 100 6. 1.0 0.5 1\"                                    \n",
    "                    replace2 = \"python HaarRandomHPCNew.py {} {} {} {} {} {} {} {} {} {} {}\".format(nq, \\\n",
    "                        d, p, circ, nshots, seed, errRate, readErr, gate, nfold, nproc)\n",
    "                    \n",
    "                if fileLabel==\"Lrn\":\n",
    "                    #find2 = \"python HaarRandomPyHPC.py 8 8 .1 1 1 1 0 100 5000 1.00 0 0 1 20\"                    \n",
    "                    find2 = \"python Lrn.py 8 6 0.1 5000 6.0 0.0 0.0 1 1\"                \n",
    "                                    \n",
    "                    #replace2 = \"python HaarRandomPyHPC.py {} {} {} {} {} {} {} {} {} {} 0 0 {} {} {} 20\".format(nq, \\\n",
    "                    #    d, p, T1, DelT, trajNum, circ, delNNT, nshots, seed, ifsave, nnt1, NTest);                \n",
    "                    if nnmodel==0 or nnmodel==1 or nnmodel==4 or nnmodel==5:\n",
    "                        ifremove0 = 0\n",
    "                        #replace2 = \"python Lrnv5.py {} {} {} {} {} {} {} {} {} {}\".format(nq, \\\n",
    "                        #    d, p, nshots, seed, errRate, readErr, gate, allTimes, nproc)                    \n",
    "                        replace2 = \"python Lrnv10.py {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {}\".format(\\\n",
    "                            nq, d, p, nshots, seed, errRate, readErr, gate, allTimes, realT, learnT1, nnmodel, \\\n",
    "                            nfold, ifremove0, lightCone, nproc)\n",
    "                        #lightCone, deltaLDim, nnt1, NTest, nproc                                    \n",
    "                    #elif nnmodel==1:                        \n",
    "                    #    # nnmodel = 0 if len(args)<=8 else bool(args[8])\n",
    "                    #    replace2 = \"python Lrnv5.py {} {} {} {} {} {} {} {} {} {} {}\".format(nq, \\\n",
    "                    #        d, p, nshots, seed, errRate, readErr, gate, allTimes, nnmodel, nproc)                \n",
    "                    elif nnmodel==3: # if model is MLP\n",
    "                        ifremove0 = 1 \n",
    "                        replace2 = \"python Lrnv10.py {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {}\".format(\\\n",
    "                            nq, d, p, nshots, seed, errRate, readErr, gate, allTimes, realT, learnT1, nnmodel, \\\n",
    "                            nfold, ifremove0, lightCone, nproc)\n",
    "                s = s.replace(find1, replace1);\n",
    "                s = s.replace(find2, replace2);               \n",
    "                #print(\"s modified = \", s);\n",
    "                #print(\"filepath = \", filepath);\n",
    "                with open(filepath, \"w\") as f:\n",
    "                    f.write(s);\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allTimes=1\n",
      "/Users/hosseindehghani/Desktop/Hafezi/Codes/MeasurementPT/Haar/shFiles\n",
      "allTimes = 1\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s175.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s122.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s134.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s163.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s98.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s77.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s118.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s20.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s36.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s159.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s61.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s196.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s179.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s16.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s41.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s138.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s57.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s180.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s114.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s94.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s143.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s155.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s102.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s82.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s83.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s103.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s154.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s142.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s1.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s95.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s115.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s181.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s56.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s139.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s40.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s17.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s197.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s178.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s60.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s158.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s37.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s21.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s119.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s99.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s76.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s162.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s135.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s123.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s174.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s190.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s10.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s128.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s47.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s51.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s186.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s169.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s112.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s92.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s145.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s6.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s153.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s104.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s84.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s173.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s124.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s132.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s165.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s71.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s26.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s149.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s30.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s88.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s67.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s108.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s109.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s89.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s66.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s31.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s148.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s27.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s70.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s164.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s133.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s125.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s172.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s85.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s105.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s152.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s144.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s7.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s93.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s113.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s187.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s168.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s50.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s46.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s200.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s129.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s11.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s191.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s69.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s86.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s106.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s151.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s28.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s4.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s147.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s90.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s110.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s184.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s53.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s45.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s12.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s192.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s65.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s32.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s8.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s24.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s73.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s167.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s188.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s130.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s126.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s49.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s171.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s170.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s48.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s127.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s131.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s166.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s189.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s72.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s25.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s9.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s33.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s64.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s193.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s13.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s44.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s52.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s185.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s111.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s91.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s5.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s146.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s29.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s150.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s107.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s68.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s87.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s63.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s34.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s22.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s75.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s161.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s136.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s59.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s120.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s177.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s198.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s18.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s80.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s100.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s38.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s157.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s2.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s141.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s79.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s96.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s116.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s182.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s55.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s43.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s14.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s194.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s195.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s15.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s42.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s54.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s183.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s117.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s78.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s97.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s3.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s140.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s156.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s39.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s101.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s81.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s19.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s176.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s199.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s121.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s58.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s137.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s160.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s74.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s23.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s35.0.sh\n",
      "filename =  LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s62.0.sh\n"
     ]
    }
   ],
   "source": [
    "direc = \"/users/hosseindehghani/desktop/hafezi/Codes/measurementPT/Haar/shFiles\"\n",
    "#createMeasureSHFiles(nq, d, p, circ, nshots, errRate, readErr, allTimes, seedmin, \\\n",
    "#    seedmax, nseed, fileLabel, account, hour, minutes, nproc, directory)\n",
    "\n",
    "nfold = 1;\n",
    "nq, d = 4, 6\n",
    "for p in [0.1]:#[0.05, 0.1, 0.15, 0.2]:\n",
    "    #for d in range(1, d+1, 1):\n",
    "    for d in range(d, d+1):\n",
    "        nq, d, p, circ, nshots, errRate, readErr, gate, nfold, allTimes, \\\n",
    "            realT, learnT1, nnmodel, ifremove0, lightCone = \\\n",
    "            nq, d, p, 1, 50000, 0.0, 0.0, 1, nfold, 1, \\\n",
    "                                   0, 0, 5, 0, 0\n",
    "        seedmin, seedmax, nseed = 1, 200, 200\n",
    "        print(f\"allTimes={allTimes}\")\n",
    "        fileLabel=\"HaarGen\";\n",
    "        fileLabel=\"Lrn\";\n",
    "        account=\"Hafezi\";\n",
    "        #python HaarRandomHPCNew.py 8 6 .5 1 100 6. 1.0 0.5 1\n",
    "        #python HaarRandomPyHPC.py 8 6 0.5 1 5000 13.0 0.0 0.0 1\n",
    "        #hour, minutes, nproc = int(math.ceil(7*d)+6), 0, 1\n",
    "        #hour, minutes, nproc = int(5*(5+d)), 0, 1    \n",
    "        hour, minutes, nproc = int(math.ceil(12+0.5*d)), 0, 1    \n",
    "        #hour, minutes, nproc = 6, 0, 1\n",
    "        A = createMeasureSHFiles(nq, d, p, circ, nshots, errRate, readErr, gate, nfold, \\\n",
    "            ifremove0, lightCone, allTimes, realT, learnT1, nnmodel, seedmin, seedmax, nseed, fileLabel, \\\n",
    "            account, hour, minutes, nproc, direc);\n",
    "#\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s1.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s2.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s3.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s4.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s5.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s6.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s7.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s8.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s9.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s10.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s11.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s12.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s13.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s14.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s15.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s16.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s17.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s18.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s19.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s20.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s21.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s22.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s23.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s24.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s25.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s26.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s27.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s28.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s29.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s30.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s31.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s32.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s33.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s34.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s35.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s36.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s37.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s38.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s39.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s40.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s41.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s42.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s43.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s44.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s45.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s46.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s47.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s48.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s49.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s50.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s51.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s52.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s53.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s54.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s55.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s56.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s57.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s58.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s59.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s60.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s61.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s62.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s63.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s64.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s65.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s66.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s67.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s68.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s69.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s70.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s71.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s72.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s73.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s74.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s75.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s76.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s77.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s78.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s79.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s80.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s81.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s82.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s83.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s84.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s85.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s86.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s87.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s88.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s89.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s90.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s91.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s92.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s93.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s94.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s95.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s96.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s97.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s98.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s99.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s100.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s101.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s102.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s103.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s104.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s105.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s106.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s107.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s108.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s109.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s110.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s111.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s112.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s113.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s114.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s115.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s116.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s117.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s118.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s119.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s120.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s121.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s122.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s123.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s124.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s125.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s126.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s127.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s128.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s129.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s130.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s131.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s132.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s133.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s134.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s135.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s136.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s137.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s138.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s139.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s140.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s141.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s142.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s143.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s144.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s145.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s146.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s147.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s148.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s149.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s150.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s151.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s152.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s153.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s154.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s155.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s156.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s157.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s158.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s159.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s160.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s161.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s162.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s163.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s164.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s165.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s166.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s167.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s168.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s169.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s170.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s171.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s172.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s173.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s174.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s175.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s176.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s177.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s178.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s179.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s180.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s181.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s182.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s183.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s184.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s185.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s186.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s187.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s188.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s189.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s190.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s191.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s192.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s193.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s194.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s195.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s196.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s197.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s198.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s199.0.sh\n",
      "sbatch LrnP0p1Nq4d6err0.0readerr0.0CNOTNs50000NN5s200.0.sh\n"
     ]
    }
   ],
   "source": [
    "#for d in range(6, 5, -1):\n",
    "direc = \"/users/hosseindehghani/desktop/hafezi/Codes/measurementPT/Haar\"\n",
    "os.chdir(direc);\n",
    "cwdir = os.getcwd();n1=4;d=12;\n",
    "#for nq in [4, 6, 8, 12]:    \n",
    "#for nq in [6, 8, 12]:        \n",
    "\n",
    "from pathlib import Path\n",
    "nq = 4; nnmodel = 5;\n",
    "nshots = 50000\n",
    "direc = \"/scratch/zt1/project/hafezi-prj/user/hdehghan/Haar/MeasureRes\"\n",
    "for p in [0.1]:#[0.05, 0.1, 0.15, 0.2]:\n",
    "    for d in range(6, 7, 1):        \n",
    "    #if True:\n",
    "        DecimalP = str(p).replace('0.','');\n",
    "        prob = \"0p{}\".format(DecimalP);\n",
    "        for s in range(1, 201):\n",
    "            s = \"{}.0\".format(s)\n",
    "            #print(\"sbatch HaarGenP0p5Nq8d{}err0.092readerr0.0CNOTNfold3s{}.sh\".format(d, s))\n",
    "            #print(\"sbatch HaarGenP0p1Nq12d{}err0.092readerr0.0CNOTs{}.sh\".format(d, s))\n",
    "            #print(\"sbatch HaarGenP0p5Nq{}d{}err0.092readerr0.0CNOTs{}.sh\".format(d, s))            \n",
    "            #d = 3*nq\n",
    "            #if nq==12:\n",
    "            #    d=24            \n",
    "            index = 0\n",
    "            #filename = \"HaarAveEE-nq{}-p{}-T{}-nshots100-errRate0.0-readErr0.0-CNOT-seed{}.csv\".format(nq, p, d, s)        \n",
    "            #for d in range(1, 7, 1):        \n",
    "            #    filename = \"MeasureResX-nq{}-p{}-T{}-nshots5000-errRate0.0-readErr0.0-CNOT-seed{}.csv\".format(nq, p, d, s)\n",
    "            #filename = \"HaarEERes-nq{}-p{}-d{}-nshots5000-errRate0.0-readErr0.0-allTimes1-lightCone1-CNOT-remove0-seed{}.csv\".format(nq, p, d, s)\n",
    "            filepath = Path(\"{}/{}\".format(direc, filename))        \n",
    "            if filepath.is_file():\n",
    "                continue\n",
    "            #    print(\"sbatch HaarGenP{}Nq{}d{}err{}readerr{}CNOTNs{}s{}.sh\".format(prob, nq, d, 0.0, 0.0, nshots, s))\n",
    "            else:\n",
    "                #continue                \n",
    "                print(\"sbatch LrnP{}Nq{}d{}err{}readerr{}CNOTNs{}NN{}s{}.sh\".format(prob, nq, d, 0.0, 0.0, nshots, nnmodel, s))\n",
    "                \n",
    "                    #index += 1\n",
    "            #if index==6:\n",
    "            #    d=6\n",
    "            #print(\"sbatch LrnP{}Nq{}d{}err{}readerr{}CNOTNs{}s{}.sh\".format(prob, nq, d, 0.0, 0.0, nshots, s))\n",
    "            ##print(\"python HaarRandomHPCNew.py {} {} {} {} {} {} {} {} {} {} {}\".format(nq, \\\n",
    "            #            d, p, circ, nshots, s, errRate, readErr, gate, nfold, nproc))\n",
    "        #print(\"sbatch LrnP0p5Nq6d{}err{}readerr{}CNOTs{}.sh\".format(d, 0.0, 0.06, s))\n",
    "    #print(\"sbatch LrnP0p5Nq8d6err0.2s{}.sh\".format(s))\n",
    "    #print(\"sbatch HaarGenP0p2Nq8d6err0.5s{}.sh\".format(s))\n",
    "    #print(\"sbatch HaarGenP0p5Nq8d5err0.2readerr0.0s{}.sh\".format(s))\n",
    "for i in range(3655406, 3656086):\n",
    "    i\n",
    "    #print(\"scancel {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nq, d = 4, 12 \n",
    "#for p in [0.05, 0.1, 0.15, 0.2]:\n",
    "\"\"\"\n",
    "for d in range(1, d, 1):\n",
    "    for i in range(1, 11):\n",
    "        print(\" python Lrnv9.py 4 {} 0.1 100 {}.0 0.0 0.0 1 1 0 0 0 1 1 1 1\".format(i, d))\n",
    "\"\"\";        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n=1; nq=6; d=10; hundredp=10; circ=0; trajNum=1; nshots=5000;\n",
    "lightCone=0; deltaLDim=0; p=hundredp/100; circ = 0;nnt1=4000; NTest=1000;\n",
    "delNNT=250;NofNTR = 1;\n",
    "\n",
    "T1=1;DelT=1;seedmin=0.01;seedmax=2.01;nseed=51;fileLabel=\"HaarSeed\";account=\"DehghaniClifford\";\n",
    "hour=2;minutes=0;nproc=1;directory=\"/Users/hosseindehghani/Desktop/Hafezi/Codes/Haar/shFiles\";\n",
    "seedvec = np.linspace(seedmin, seedmax, nseed);  #   np.arange(seedmin, seedmax, deltaseed);\n",
    "seedvec = [np.round(seed, 2) for seed in seedvec];\n",
    "\n",
    "DecimalP = str(p).replace('0.','');\n",
    "prob = \"0p{}\".format(DecimalP);\n",
    "\n",
    "A = createMeasureSHFiles(nq, d, T1, DelT, hundredp, trajNum, circ, nshots, delNNT, seedmin, \n",
    "    seedmax, nseed, fileLabel, account, hour, minutes, nproc, \\\n",
    "    directory, nnt1, NTest, ifsave=0, circInd=False)\n",
    "\n",
    "\n",
    "#seedvec = np.linspace(seedmin, seedmax, nseed);  #   np.arange(seedmin, seedmax, deltaseed);\n",
    "#seedvec = [np.round(seed, 2) for seed in seedvec]\n",
    "#print(seedvec)\n",
    "for s in seedvec:\n",
    "    print(\"sbatch -A hafezi-prj-jqi -t 4:0:0 HaarSeedP{}nq{}d{}s{}.sh\".format(prob, nq, d, s))\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#from decimal import *\n",
    "#seed=[0.12131231231231213, .2123]\n",
    "#seed = [round(seed[i], 8) for i in range(len(seed))]\n",
    "#Decimal('3.1415926')\n",
    "#arr = [-0.341111, 1.455098989, 4.232323, -0.3432326, 7.626632, 5.122323]\n",
    "#arr1 = np.round(arr, 8)\n",
    "\n",
    "#print(arr1)\n",
    "\n",
    "#float_value = 3.333\n",
    "\n",
    "\n",
    "#formatted_string = \"{:.7f}\".format(value)\n",
    "\n",
    "#format to two decimal places\n",
    "\n",
    "#float_value = float(formatted_string)\n",
    "#format(float_value, '.6f')\n",
    "\n",
    "#print(float_value)\n",
    "\n",
    "#a = float(format(float_value, '.6f'))\n",
    "\n",
    "#print(\"a = \", a)\n",
    "\n",
    "\n",
    "#import decimal\n",
    "#x = decimal.Decimal('2.00')\n",
    "#Decimal('2.00')\n",
    "#print(decimal.Decimal(a))\n",
    "#print(\"{} is a great number.\".format(x))\n",
    "#decimal.Decimal(a)\n",
    "#scientific_notation=\"{:.6e}\".format(.1234)\n",
    "#print(scientific_notation)\n",
    "\n",
    "circ = genCircConfig(nq, d, p, seed, 1);\n",
    "path = Path('~/Desktop/Hafezi/Codes/Haar/').expanduser()\n",
    "\n",
    "#print(\"path = \", path)\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lb,ub = -1,1;\n",
    "num_samples = 5;\n",
    "\n",
    "np.save(path/'measure', circ[0])\n",
    "np.save(path/'unitary', circ[1])\n",
    "\n",
    "x_loaded = np.load(path/'measure.npy')\n",
    "\n",
    "y_loaded = np.load(path/'unitary.npy')\n",
    "print(\"y_loaded[:] = \", np.shape(y_loaded))\n",
    "#print(\"y_loaded[:] = \", y_loaded)\n",
    "\n",
    "#print(\"x_loaded = \", x_loaded)\n",
    "#print(\"y_load = \", y_load)\n",
    "\n",
    "#print(x is x_loaded) # False;\n",
    "#print(x == x_loaded) # [[ True  True  True  True  True]];\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "EERes=np.zeros((2, 4));\n",
    "if 1:\n",
    "    EERes[0, 0:4]=[1, 4, 2, 3]\n",
    "    EERes[1, 0:4]=[2, 2, 5, 3]    \n",
    "    df = pd.DataFrame(EERes);\n",
    "    data = [['nameservers','panel'], ['nameservers','panel']]\n",
    "\n",
    "    with open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "        p, learningT1, learningT2, learnDelT, lightCone, nshots, seed), 'a') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows(EERes)    \n",
    "        \n",
    "    #fileOpen = open(\"HaarEERes-nq{}-p{}-ti{}-tf{}-delT{}-lightCone{}-nshots{}-seed{}.csv\".format(nq, \\\n",
    "    #    p, learningT1, learningT2, learnDelT, lightCone, nshots, seed, dt_string[-8:]), \"a\")\n",
    "    #fileOpen.write(EERes)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "l12=np.zeros((6,1));l10=np.zeros((6,1));\n",
    "l12[0] = (sum(eel12p0p05)/50)\n",
    "l12[1] = (sum(eel12p0p1)/50)\n",
    "l12[2] = (sum(eel12p0p15)/50)\n",
    "l12[3] = (sum(eel12p0p2)/50)\n",
    "l12[4] = (sum(eel12p0p25)/50)\n",
    "l12[5] = (sum(eel12p0p3)/50)\n",
    "\n",
    "l10[0] = (sum(eel10p0p05)/50)\n",
    "l10[1] = (sum(eel10p0p1)/50)\n",
    "l10[2] = (sum(eel10p0p15)/50)\n",
    "l10[3] = (sum(eel10p0p2)/50)\n",
    "l10[4] = (sum(eel10p0p25)/50)\n",
    "l10[5] = (sum(eel10p0p3)/50)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "pvec=[0.05, .1, .15, .2, .25, .3]\n",
    "plt.title(\"Ancilla qubit entanglement entropy in Haar circuits\")\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"S_Q\")\n",
    "line1, =plt.plot(pvec,(l10), 'r*-', label=\"L=10\")\n",
    "line2, =plt.plot(pvec,(l12), 'b*-', label=\"L=12\")\n",
    "plt.legend(handles=[line1, line2])\n",
    "#plt.legend(handles=[line1, line2])\n",
    "#plt.legend([line1, line2], ['L=10', 'L=12'])\n",
    "#plt.plot(pvec,l12, 'k') \n",
    "plt.savefig('HaarCircuitv1.png')\n",
    "plt.show()\n",
    "#plt.savefig('HaarCircuitv1.png')\n",
    "print(np.shape(np.transpose(l12)))\n",
    "print(np.shape(pvec))\n",
    "\n",
    "line1, = plt.plot([1, 2, 3], label='label1')\n",
    "line2, = plt.plot([1, 2, 3], label='label2')\n",
    "plt.legend(handles=[line1, line2])\n",
    "\n",
    "\n",
    "mat = [[0.95948504+0.00000000e+00j, 0.19716364+2.73608678e-10j],\n",
    " [0.19716364-2.73608678e-10j, 0.04051496+0.00000000e+00j]]\n",
    "eigval=eig(mat)[0];\n",
    "partialee = -np.sum(np.dot(np.log2(eigval), eigval)) \n",
    "print(\"partialee = \", partialee)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
